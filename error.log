cov-init develop-inst-noop: /Users/jh186076/Documents/03_Privat/sqlfluff
cov-init installed: bench-it==1.0.1,click==7.1.1,colorama==0.4.3,configparser==5.0.0,coverage==5.1,diff-cover==2.6.1,importlib-metadata==1.6.0,inflect==4.1.0,Jinja2==2.11.2,jinja2-pluralize==0.3.0,MarkupSafe==1.1.1,oyaml==0.9,pluggy==0.13.1,Pygments==2.6.1,PyYAML==5.3.1,six==1.14.0,-e git+https://github.com/Katzmann1983/sqlfluff.git@47c6bd2839ba731a7856a926801a7b4ab4126dd4#egg=sqlfluff,zipp==3.1.0
cov-init run-test-pre: PYTHONHASHSEED='3219088205'
cov-init run-test: commands[0] | coverage erase
py37 develop-inst-noop: /Users/jh186076/Documents/03_Privat/sqlfluff
py37 installed: attrs==19.3.0,bench-it==1.0.1,certifi==2020.4.5.1,chardet==3.0.4,click==7.1.1,colorama==0.4.3,configparser==5.0.0,coverage==5.1,diff-cover==2.6.1,idna==2.9,importlib-metadata==1.6.0,inflect==4.1.0,Jinja2==2.11.2,jinja2-pluralize==0.3.0,MarkupSafe==1.1.1,more-itertools==8.2.0,oyaml==0.9,packaging==20.3,pluggy==0.13.1,py==1.8.1,Pygments==2.6.1,pyparsing==2.4.7,pytest==5.4.1,pytest-cov==2.8.1,PyYAML==5.3.1,requests==2.23.0,six==1.14.0,-e git+https://github.com/Katzmann1983/sqlfluff.git@47c6bd2839ba731a7856a926801a7b4ab4126dd4#egg=sqlfluff,urllib3==1.25.9,wcwidth==0.1.9,zipp==3.1.0
py37 run-test-pre: PYTHONHASHSEED='3219088205'
py37 run-test: commands[0] | python util.py clean-tests
Removed '.test-reports'...
Created '.test-reports'
py37 run-test: commands[1] | pytest -vv --cov --cov-report=xml --junitxml=.test-reports/junit.xml
============================= test session starts ==============================
platform darwin -- Python 3.7.2, pytest-5.4.1, py-1.8.1, pluggy-0.13.1 -- /Users/jh186076/Documents/03_Privat/sqlfluff/.tox/py37/bin/python
cachedir: .tox/py37/.pytest_cache
rootdir: /Users/jh186076/Documents/03_Privat/sqlfluff, inifile: tox.ini, testpaths: test
plugins: cov-2.8.1
collecting ... collected 343 items

test/cli_commands_test.py::test__cli__command_directed PASSED            [  0%]
test/cli_commands_test.py::test__cli__command_dialect PASSED             [  0%]
test/cli_commands_test.py::test__cli__command_lint_stdin[command0] PASSED [  0%]
test/cli_commands_test.py::test__cli__command_lint_stdin[command1] PASSED [  1%]
test/cli_commands_test.py::test__cli__command_lint_stdin[command2] PASSED [  1%]
test/cli_commands_test.py::test__cli__command_lint_stdin[command3] PASSED [  1%]
test/cli_commands_test.py::test__cli__command_lint_parse[command0] PASSED [  2%]
test/cli_commands_test.py::test__cli__command_lint_parse[command1] PASSED [  2%]
test/cli_commands_test.py::test__cli__command_lint_parse[command2] PASSED [  2%]
test/cli_commands_test.py::test__cli__command_lint_parse[command3] PASSED [  2%]
test/cli_commands_test.py::test__cli__command_lint_parse[command4] PASSED [  3%]
test/cli_commands_test.py::test__cli__command_lint_parse[command5] PASSED [  3%]
test/cli_commands_test.py::test__cli__command_lint_parse[command6] PASSED [  3%]
test/cli_commands_test.py::test__cli__command_lint_parse[command7] PASSED [  4%]
test/cli_commands_test.py::test__cli__command_lint_parse[command8] PASSED [  4%]
test/cli_commands_test.py::test__cli__command_lint_parse[command9] PASSED [  4%]
test/cli_commands_test.py::test__cli__command_lint_parse[command10] PASSED [  4%]
test/cli_commands_test.py::test__cli__command_lint_parse[command11] PASSED [  5%]
test/cli_commands_test.py::test__cli__command_lint_parse[command12] PASSED [  5%]
test/cli_commands_test.py::test__cli__command_lint_parse[command13] PASSED [  5%]
test/cli_commands_test.py::test__cli__command_lint_parse[command14] PASSED [  6%]
test/cli_commands_test.py::test__cli__command_lint_parse[command15] PASSED [  6%]
test/cli_commands_test.py::test__cli__command_lint_parse[command16] PASSED [  6%]
test/cli_commands_test.py::test__cli__command_versioning PASSED          [  6%]
test/cli_commands_test.py::test__cli__command_version PASSED             [  7%]
test/cli_commands_test.py::test__cli__command_rules PASSED               [  7%]
test/cli_commands_test.py::test__cli__command__fix[L001-test/fixtures/linter/indentation_errors.sql] PASSED [  7%]
test/cli_commands_test.py::test__cli__command__fix[L008-test/fixtures/linter/whitespace_errors.sql] PASSED [  8%]
test/cli_commands_test.py::test__cli__command__fix[L008-test/fixtures/linter/indentation_errors.sql] PASSED [  8%]
test/cli_commands_test.py::test__cli__command__fix[L003-test/fixtures/linter/indentation_error_hard.sql] PASSED [  8%]
test/cli_commands_test.py::test__cli__command__fix_fail[L004-test/fixtures/linter/indentation_errors.sql] PASSED [  9%]
test/cli_commands_test.py::test__cli__command_fix_stdin PASSED           [  9%]
test/cli_commands_test.py::test__cli__command__fix_no_force[L001-test/fixtures/linter/indentation_errors.sql-y-0] PASSED [  9%]
test/cli_commands_test.py::test__cli__command__fix_no_force[L001-test/fixtures/linter/indentation_errors.sql-n-65] PASSED [  9%]
test/cli_commands_test.py::test__cli__command_parse_serialize_from_stdin[yaml] PASSED [ 10%]
test/cli_commands_test.py::test__cli__command_parse_serialize_from_stdin[json] PASSED [ 10%]
test/cli_commands_test.py::test__cli__command_lint_serialize_from_stdin[select * from tbl-expected0-0-yaml] PASSED [ 10%]
test/cli_commands_test.py::test__cli__command_lint_serialize_from_stdin[select * from tbl-expected0-0-json] PASSED [ 11%]
test/cli_commands_test.py::test__cli__command_lint_serialize_from_stdin[SElect * from tbl-expected1-65-yaml] PASSED [ 11%]
test/cli_commands_test.py::test__cli__command_lint_serialize_from_stdin[SElect * from tbl-expected1-65-json] PASSED [ 11%]
test/cli_commands_test.py::test__cli__command_lint_serialize_multiple_files[yaml] PASSED [ 11%]
test/cli_commands_test.py::test__cli__command_lint_serialize_multiple_files[json] PASSED [ 12%]
test/cli_commands_test.py::test___main___help PASSED                     [ 12%]
test/cli_formatters_test.py::test__cli__formatters__filename_nocol PASSED [ 12%]
test/cli_formatters_test.py::test__cli__formatters__filename_col PASSED  [ 13%]
test/cli_formatters_test.py::test__cli__formatters__violation PASSED     [ 13%]
test/cli_formatters_test.py::test__cli__formatters__violations PASSED    [ 13%]
test/cli_helpers_test.py::test__cli__helpers__colorize PASSED            [ 13%]
test/cli_helpers_test.py::test__cli__helpers__cli_table PASSED           [ 14%]
test/cli_helpers_test.py::test__cli__helpers__wrap_elem[abc-5-res0] PASSED [ 14%]
test/cli_helpers_test.py::test__cli__helpers__wrap_elem[how now brown cow-10-res1] PASSED [ 14%]
test/cli_helpers_test.py::test__cli__helpers__wrap_elem[A hippopotamus came for tea-10-res2] PASSED [ 15%]
test/cli_helpers_test.py::test__cli__helpers__wrap_elem[A hippopotamus\ncame for tea-10-res3] PASSED [ 15%]
test/cli_helpers_test.py::test__cli__helpers__wrap_field_a PASSED        [ 15%]
test/cli_helpers_test.py::test__cli__helpers__wrap_field_b PASSED        [ 16%]
test/cli_helpers_test.py::test__cli__helpers__wrap_field_c PASSED        [ 16%]
test/cli_helpers_test.py::test__cli__helpers__pad_line PASSED            [ 16%]
test/config_test.py::test__config__nested_combine PASSED                 [ 16%]
test/config_test.py::test__config__dict_diff PASSED                      [ 17%]
test/config_test.py::test__config__load_file_dir PASSED                  [ 17%]
test/config_test.py::test__config__load_file_f PASSED                    [ 17%]
test/config_test.py::test__config__load_nested PASSED                    [ 18%]
test/config_test.py::test__config__nested_config_tests PASSED            [ 18%]
test/dialects_ansi_test.py::test__dialect__ansi__file_from_raw[a b-res0] PASSED [ 18%]
test/dialects_ansi_test.py::test__dialect__ansi__file_from_raw[b.c-res1] PASSED [ 18%]
test/dialects_ansi_test.py::test__dialect__ansi__file_from_raw[abc \n \t def  ;blah-res2] PASSED [ 19%]
test/dialects_ansi_test.py::test__dialect__ansi_specific_segment_parses[SelectKeywordSegment-select] PASSED [ 19%]
test/dialects_ansi_test.py::test__dialect__ansi_specific_segment_parses[NakedIdentifierSegment-online_sales] PASSED [ 19%]
test/dialects_ansi_test.py::test__dialect__ansi_specific_segment_parses[NumericLiteralSegment-1000.0] PASSED [ 20%]
test/dialects_ansi_test.py::test__dialect__ansi_specific_segment_parses[ExpressionSegment-online_sales / 1000.0] PASSED [ 20%]
test/dialects_ansi_test.py::test__dialect__ansi_specific_segment_parses[IntervalExpressionSegment-INTERVAL 1 YEAR] PASSED [ 20%]
test/dialects_ansi_test.py::test__dialect__ansi_specific_segment_parses[ExpressionSegment-CASE WHEN id = 1 THEN 'nothing' ELSE 'test' END] PASSED [ 20%]
test/dialects_ansi_test.py::test__dialect__ansi_specific_segment_parses[ExpressionSegment-CASE WHEN id = 1 THEN CASE WHEN true THEN 'something' ELSE 'nothing' END ELSE 'test' END] PASSED [ 21%]
test/dialects_ansi_test.py::test__dialect__ansi_specific_segment_parses[ExpressionSegment-CAST(ROUND(online_sales / 1000.0) AS varchar)] PASSED [ 21%]
test/dialects_ansi_test.py::test__dialect__ansi_specific_segment_parses[ExpressionSegment-name NOT LIKE '%y'] PASSED [ 21%]
test/dialects_ansi_test.py::test__dialect__ansi_specific_segment_parses[SelectTargetElementSegment-MIN (test.id) AS min_test_id] PASSED [ 22%]
test/dialects_ansi_test.py::test__dialect__ansi_specific_segment_parses[ExpressionSegment-DATE_ADD(CURRENT_DATE('America/New_York'), INTERVAL 1 year)] PASSED [ 22%]
test/dialects_ansi_test.py::test__dialect__ansi_specific_segment_parses[ExpressionSegment-my_array[1]] PASSED [ 22%]
test/dialects_ansi_test.py::test__dialect__ansi_specific_segment_parses[ExpressionSegment-my_array[OFFSET(1)]] PASSED [ 23%]
test/dialects_ansi_test.py::test__dialect__ansi_specific_segment_parses[ExpressionSegment-my_array[5:8]] PASSED [ 23%]
test/dialects_ansi_test.py::test__dialect__ansi_specific_segment_parses[ExpressionSegment-4 + my_array[OFFSET(1)]] PASSED [ 23%]
test/dialects_ansi_test.py::test__dialect__ansi_specific_segment_parses[ExpressionSegment-bits[OFFSET(0)] + 7] PASSED [ 23%]
test/dialects_ansi_test.py::test__dialect__ansi_specific_segment_parses[SelectTargetElementSegment-(count_18_24 * bits[OFFSET(0)]) / audience_size AS relative_abundance] PASSED [ 24%]
test/dialects_ansi_test.py::test__dialect__ansi_specific_segment_parses[ExpressionSegment-count_18_24 * bits[OFFSET(0)] + count_25_34] PASSED [ 24%]
test/dialects_ansi_test.py::test__dialect__ansi_specific_segment_parses[SelectTargetElementSegment-(count_18_24 * bits[OFFSET(0)] + count_25_34) / audience_size AS relative_abundance] PASSED [ 24%]
test/dialects_ansi_test.py::test__dialect__ansi_specific_segment_parses[SelectStatementSegment-SELECT t.val/t.id FROM test WHERE id*1.0/id > 0.8] PASSED [ 25%]
test/dialects_ansi_test.py::test__dialect__ansi_specific_segment_parses[SelectTargetElementSegment-t.val/t.id] PASSED [ 25%]
test/dialects_ansi_test.py::test__dialect__ansi_specific_segment_parses[SelectTargetElementSegment-CAST(num AS INT64)] PASSED [ 25%]
test/dialects_ansi_test.py::test__dialect__ansi_specific_segment_parses[SelectTargetElementSegment-CAST(num AS numeric(8,4))] PASSED [ 25%]
test/dialects_ansi_test.py::test__dialect__ansi_specific_segment_parses[SelectTargetElementSegment-a.*] PASSED [ 26%]
test/dialects_ansi_test.py::test__dialect__ansi_specific_segment_parses[SelectTargetElementSegment-a.b.*] PASSED [ 26%]
test/dialects_ansi_test.py::test__dialect__ansi_specific_segment_parses[SelectTargetElementSegment-a.b.c.*] PASSED [ 26%]
test/dialects_ansi_test.py::test__dialect__ansi_specific_segment_parses[ObjectReferenceSegment-a..c.*] PASSED [ 27%]
test/dialects_test.py::test__dialect__base_file_parse[teradata-select_stmt.sql] FAILED [ 27%]
test/dialects_test.py::test__dialect__base_file_parse[teradata-create_table_stmt_3.sql] FAILED [ 27%]
test/dialects_test.py::test__dialect__base_file_parse[teradata-create_table_stmt_2.sql] FAILED [ 27%]
test/dialects_test.py::test__dialect__base_file_parse[teradata-create_table_stmt.sql] FAILED [ 28%]
test/dialects_test.py::test__dialect__base_file_parse[teradata-bteq_stmt.sql] FAILED [ 28%]
test/dialects_test.py::test__dialect__base_file_parse[teradata-collect_stats.sql] FAILED [ 28%]
test/dialects_test.py::test__dialect__base_file_parse[teradata-update_from.sql] FAILED [ 29%]
test/dialects_test.py::test__dialect__base_file_parse[teradata-select_stmt_cast.sql] FAILED [ 29%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-select_i.sql] PASSED [ 29%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-commit_work.sql] PASSED [ 30%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-rollback_and_no_chain.sql] PASSED [ 30%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-functions_b.sql] PASSED [ 30%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-select_h.sql] PASSED [ 30%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-grant_select_update_insert_on_mytable_to_public.sql] PASSED [ 31%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-select_j.sql] PASSED [ 31%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-functions_a.sql] PASSED [ 31%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-select_simple_h.sql] PASSED [ 32%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-select_o.sql] PASSED [ 32%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-multi_statement_c.sql] PASSED [ 32%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-multi_statement_b.sql] PASSED [ 32%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-drop_view_a_restrict.sql] PASSED [ 33%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-select_n.sql] PASSED [ 33%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-select_simple_i.sql] PASSED [ 33%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-select_simple_k.sql] PASSED [ 34%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-select_l.sql] PASSED [ 34%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-multi_statement_a.sql] PASSED [ 34%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-create_table_varchar.sql] PASSED [ 34%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-grant_select_on_mytable_to_public_with_grant_option.sql] PASSED [ 35%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-create_table_table_comment.sql] PASSED [ 35%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-select_m.sql] PASSED [ 35%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-select_simple_j.sql] PASSED [ 36%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-create_table_a_c1_c2.sql] PASSED [ 36%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-grant_all_privileges_on_mytable_to_role.sql] PASSED [ 36%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-create_table_a_column_constraints.sql] PASSED [ 37%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-grant_select_col1_col2_update_col1_on_mytable_to_public.sql] PASSED [ 37%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-arithmetic_a.sql] PASSED [ 37%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-create_view_a.sql] PASSED [ 37%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-drop_table_a_cascade.sql] PASSED [ 38%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-drop_table_a_restrict.sql] PASSED [ 38%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-drop_table_a.sql] PASSED [ 38%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-table_expression.sql] PASSED [ 39%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-revoke_select_on_table_a_from_group_b.sql] PASSED [ 39%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-rollback_work_and_no_chain.sql] PASSED [ 39%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-commit_and_no_chain.sql] PASSED [ 39%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-grant_all_on_table_mytable_to_role.sql] PASSED [ 40%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-drop_table_if_exists_a.sql] PASSED [ 40%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-commit_work_and_no_chain.sql] PASSED [ 40%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-grant_select_on_mytable_to_public.sql] PASSED [ 41%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-create_table_auto_increment.sql] PASSED [ 41%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-update.sql] PASSED [ 41%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-select_with_b.sql] PASSED [ 41%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-create_table_column_comment.sql] PASSED [ 42%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-delete_from.sql] PASSED [ 42%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-insert_a.sql] PASSED [ 42%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-create_table_as.sql] PASSED [ 43%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-select_with_a.sql] PASSED [ 43%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-select_simple_g.sql] PASSED [ 43%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-select_a.sql] PASSED [ 44%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-select_simple_f.sql] PASSED [ 44%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-grant_update_on_all_tables_in_schema_a_to_public.sql] PASSED [ 44%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-select_simple_d.sql] PASSED [ 44%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-grant_all_on_mytable_to_role.sql] PASSED [ 45%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-select_c.sql] PASSED [ 45%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-select_t.sql] PASSED [ 45%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-create_table_a_pk_unique_fk_constraints.sql] PASSED [ 46%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-select_b.sql] PASSED [ 46%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-select_simple_e.sql] PASSED [ 46%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-commit.sql] PASSED [ 46%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-select_simple_a.sql] PASSED [ 47%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-drop_view_a.sql] PASSED [ 47%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-select_q.sql] PASSED [ 47%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-select_f.sql] PASSED [ 48%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-rollback_work.sql] PASSED [ 48%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-select_g.sql] PASSED [ 48%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-select_p.sql] PASSED [ 48%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-drop_view_a_cascade.sql] PASSED [ 49%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-select_simple_b.sql] PASSED [ 49%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-select_r.sql] PASSED [ 49%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-select_e.sql] PASSED [ 50%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-rollback.sql] PASSED [ 50%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-select_d.sql] PASSED [ 50%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-select_s.sql] PASSED [ 51%]
test/dialects_test.py::test__dialect__base_file_parse[ansi-select_simple_c.sql] PASSED [ 51%]
test/dialects_test.py::test__dialect__base_file_parse[bigquery-interval_function.sql] FAILED [ 51%]
test/dialects_test.py::test__dialect__base_file_parse[bigquery-string_literals.sql] FAILED [ 51%]
test/dialects_test.py::test__dialect__base_file_parse[bigquery-select_quoting.sql] FAILED [ 52%]
test/dialects_test.py::test__dialect__base_file_parse[bigquery-select_example.sql] FAILED [ 52%]
test/dialects_test.py::test__dialect__base_parse_struct[ansi-multi_statement_a.sql-False-multi_statement_a_nc.yml] PASSED [ 52%]
test/dialects_test.py::test__dialect__base_parse_struct[ansi-select_simple_j.sql-True-select_simple_j.yml] PASSED [ 53%]
test/dialects_test.py::test__dialect__base_parse_struct[ansi-select_with_a.sql-True-select_with_a.yml] PASSED [ 53%]
test/dialects_test.py::test__dialect__base_parse_struct[ansi-select_a.sql-True-select_a.yml] PASSED [ 53%]
test/dialects_test.py::test__dialect__base_parse_struct[ansi-select_simple_e.sql-True-select_simple_e.yml] PASSED [ 53%]
test/dialects_test.py::test__dialect__base_parse_struct[ansi-select_simple_e.sql-False-select_simple_e_nc.yml] PASSED [ 54%]
test/dialects_test.py::test__dialect__base_parse_struct[ansi-select_simple_a.sql-True-select_simple_a.yml] PASSED [ 54%]
test/dialects_test.py::test__dialect__base_parse_struct[ansi-select_simple_b.sql-True-select_simple_b.yml] PASSED [ 54%]
test/dialects_test.py::test__dialect__base_parse_struct[ansi-select_e.sql-True-select_e.yml] PASSED [ 55%]
test/diff_quality_plugin_test.py::test_diff_quality_plugin[test/fixtures/linter/indentation_errors.sql-expected_violations_lines0] PASSED [ 55%]
test/diff_quality_plugin_test.py::test_diff_quality_plugin[test/fixtures/linter/parse_error.sql-expected_violations_lines1] PASSED [ 55%]
test/linter_test.py::test__linter__path_from_paths__dir PASSED           [ 55%]
test/linter_test.py::test__linter__path_from_paths__file PASSED          [ 56%]
test/linter_test.py::test__linter__path_from_paths__dot PASSED           [ 56%]
test/linter_test.py::test__linter__lint_string_vs_file[test/fixtures/linter/indentation_errors.sql] PASSED [ 56%]
test/linter_test.py::test__linter__lint_string_vs_file[test/fixtures/linter/whitespace_errors.sql] PASSED [ 57%]
test/linter_test.py::test__linter__linting_result__sum_dicts PASSED      [ 57%]
test/linter_test.py::test__linter__linting_result__combine_dicts PASSED  [ 57%]
test/parser_grammar_test.py::test__parser__grammar__base__code_only_sensitive_match PASSED [ 58%]
test/parser_grammar_test.py::test__parser__grammar__base__trim_non_code PASSED [ 58%]
test/parser_grammar_test.py::test__parser__grammar__base__look_ahead_match PASSED [ 58%]
test/parser_grammar_test.py::test__parser__grammar__base__bracket_sensitive_look_ahead_match PASSED [ 58%]
test/parser_grammar_test.py::test__parser__grammar_oneof[True] PASSED    [ 59%]
test/parser_grammar_test.py::test__parser__grammar_oneof[False] PASSED   [ 59%]
test/parser_grammar_test.py::test__parser__grammar_startswith_a PASSED   [ 59%]
test/parser_grammar_test.py::test__parser__grammar_startswith_b PASSED   [ 60%]
test/parser_grammar_test.py::test__parser__grammar_sequence PASSED       [ 60%]
test/parser_grammar_test.py::test__parser__grammar_sequence_nested PASSED [ 60%]
test/parser_grammar_test.py::test__parser__grammar_delimited PASSED      [ 60%]
test/parser_grammar_test.py::test__parser__grammar_delimited_not_code_only PASSED [ 61%]
test/parser_grammar_test.py::test__parser__grammar_greedyuntil PASSED    [ 61%]
test/parser_grammar_test.py::test__parser__grammar_greedyuntil_bracketed PASSED [ 61%]
test/parser_grammar_test.py::test__parser__grammar_containsonly PASSED   [ 62%]
test/parser_lexer_test.py::test__parser__lexer_obj[a b-res0] PASSED      [ 62%]
test/parser_lexer_test.py::test__parser__lexer_obj[b.c-res1] PASSED      [ 62%]
test/parser_lexer_test.py::test__parser__lexer_obj[abc \n \t def  ;blah-res2] PASSED [ 62%]
test/parser_lexer_test.py::test__parser__lexer_obj[abc'\n "\t' "de`f"-res3] PASSED [ 63%]
test/parser_lexer_test.py::test__parser__lexer_obj[abc -- comment \nblah-res4] PASSED [ 63%]
test/parser_lexer_test.py::test__parser__lexer_obj[abc # comment \nblah-res5] PASSED [ 63%]
test/parser_lexer_test.py::test__parser__lexer_obj[abc /* comment \nblah*/-res6] PASSED [ 64%]
test/parser_lexer_test.py::test__parser__lexer_obj[abc /*\n\t\n*/-res7] PASSED [ 64%]
test/parser_lexer_test.py::test__parser__lexer_obj[*-+bd/-res8] PASSED   [ 64%]
test/parser_lexer_test.py::test__parser__lexer_obj[2+4 -5-res9] PASSED   [ 65%]
test/parser_lexer_test.py::test__parser__lexer_singleton[.fsaljk-.] PASSED [ 65%]
test/parser_lexer_test.py::test__parser__lexer_singleton[fsaljk-None] PASSED [ 65%]
test/parser_lexer_test.py::test__parser__lexer_regex[fsaljk-f-f0] PASSED [ 65%]
test/parser_lexer_test.py::test__parser__lexer_regex[fsaljk-f-f1] PASSED [ 66%]
test/parser_lexer_test.py::test__parser__lexer_regex[fsaljk-[fas]*-fsa] PASSED [ 66%]
test/parser_lexer_test.py::test__parser__lexer_regex[   \t   fsaljk-[\\t ]*-   \t   ] PASSED [ 66%]
test/parser_lexer_test.py::test__parser__lexer_regex[   \t \n  fsaljk-[\\t ]*-   \t ] PASSED [ 67%]
test/parser_lexer_test.py::test__parser__lexer_regex['something boring'   \t \n  fsaljk-'[^']*'-'something boring'] PASSED [ 67%]
test/parser_lexer_test.py::test__parser__lexer_regex[' something exciting \t\n '   \t \n  fsaljk-'[^']*'-' something exciting \t\n '] PASSED [ 67%]
test/parser_lexer_test.py::test__parser__lexer_multimatcher PASSED       [ 67%]
test/parser_lexer_test.py::test__parser__lexer_fail PASSED               [ 68%]
test/parser_lexer_test.py::test__parser__lexer_fail_via_parse PASSED     [ 68%]
test/parser_markers_test.py::test__parser__common_marker PASSED          [ 68%]
test/parser_markers_test.py::test__parser__common_marker_format PASSED   [ 69%]
test/parser_match_test.py::test__parser__match_construct[<lambda>0-from_unmatched] PASSED [ 69%]
test/parser_match_test.py::test__parser__match_construct[<lambda>0-from_matched] PASSED [ 69%]
test/parser_match_test.py::test__parser__match_construct[<lambda>1-from_unmatched] PASSED [ 69%]
test/parser_match_test.py::test__parser__match_construct[<lambda>1-from_matched] PASSED [ 70%]
test/parser_match_test.py::test__parser__match_construct[<lambda>2-from_unmatched] PASSED [ 70%]
test/parser_match_test.py::test__parser__match_construct[<lambda>2-from_matched] PASSED [ 70%]
test/parser_match_test.py::test__parser__match_construct[<lambda>3-from_unmatched] PASSED [ 71%]
test/parser_match_test.py::test__parser__match_construct[<lambda>3-from_matched] PASSED [ 71%]
test/parser_match_test.py::test__parser__match_construct_from_empty PASSED [ 71%]
test/parser_match_test.py::test__parser__match_add[<lambda>0] PASSED     [ 72%]
test/parser_match_test.py::test__parser__match_add[<lambda>1] PASSED     [ 72%]
test/parser_match_test.py::test__parser__match_add[<lambda>2] PASSED     [ 72%]
test/parser_match_test.py::test__parser__match_add[<lambda>3] PASSED     [ 72%]
test/parser_match_test.py::test__parser__match_add_raises[string] PASSED [ 73%]
test/parser_match_test.py::test__parser__match_add_raises[fail_case1] PASSED [ 73%]
test/parser_match_test.py::test__parser__match_add_raises[fail_case2] PASSED [ 73%]
test/parser_match_test.py::test__parser__match_add_raises[fail_case3] PASSED [ 74%]
test/parser_segments_base_test.py::test__parser__base_segments_raw_init PASSED [ 74%]
test/parser_segments_base_test.py::test__parser__base_segments_raw PASSED [ 74%]
test/parser_segments_base_test.py::test__parser__base_segments_base PASSED [ 74%]
test/parser_segments_base_test.py::test__parser__base_segments_raw_compare PASSED [ 75%]
test/parser_segments_base_test.py::test__parser__base_segments_base_compare PASSED [ 75%]
test/parser_segments_core_test.py::test__parser__core_keyword PASSED     [ 75%]
test/rules_std_fix_auto_test.py::test__std_fix_auto[ansi-003_L016_long_line_2-L016] PASSED [ 76%]
test/rules_std_fix_auto_test.py::test__std_fix_auto[ansi-001_L016_long_line_1-L016] PASSED [ 76%]
test/rules_std_fix_auto_test.py::test__std_fix_auto[ansi-002_L003_indentation_2-L003] PASSED [ 76%]
test/rules_std_fix_auto_test.py::test__std_fix_auto[ansi-007_L018_with_clause_1-L018] PASSED [ 76%]
test/rules_std_fix_auto_test.py::test__std_fix_auto[ansi-004_L003_indentation_3-L003] PASSED [ 77%]
test/rules_std_fix_auto_test.py::test__std_fix_auto[ansi-006_L003_indentation_4-L003] PASSED [ 77%]
test/rules_std_fix_auto_test.py::test__std_fix_auto[ansi-005_L017_function_spacing-L017] PASSED [ 77%]
test/rules_std_fix_auto_test.py::test__std_fix_auto[bigquery-001_L003L006L009_templating-L003,L006,L009] FAILED [ 78%]
test/rules_std_roundtrip_test.py::test__cli__command__fix[L001-test/fixtures/linter/indentation_errors.sql] PASSED [ 78%]
test/rules_std_roundtrip_test.py::test__cli__command__fix[L008-test/fixtures/linter/whitespace_errors.sql] PASSED [ 78%]
test/rules_std_roundtrip_test.py::test__cli__command__fix[L008-test/fixtures/linter/indentation_errors.sql] PASSED [ 79%]
test/rules_std_roundtrip_test.py::test__cli__command__fix[L010-test/fixtures/linter/whitespace_errors.sql] PASSED [ 79%]
test/rules_std_roundtrip_test.py::test__cli__command__fix[L011-test/fixtures/parser/ansi/select_simple_i.sql] PASSED [ 79%]
test/rules_std_roundtrip_test.py::test__cli__command__fix[L012-test/fixtures/parser/ansi/select_simple_i.sql] PASSED [ 79%]
test/rules_std_roundtrip_test.py::test__cli__command__fix_templated[L010] PASSED [ 80%]
test/rules_std_roundtrip_test.py::test__cli__command__fix_templated[L001] PASSED [ 80%]
test/rules_std_test.py::test__rules__std_string[L001-fail-SELECT 1     \n-SELECT 1\n-None] PASSED [ 80%]
test/rules_std_test.py::test__rules__std_string[L002-fail-    \t    \t    SELECT 1-None-None] PASSED [ 81%]
test/rules_std_test.py::test__rules__std_string[L003-fail-     SELECT 1-SELECT 1-None] PASSED [ 81%]
test/rules_std_test.py::test__rules__std_string[L004-pass-   \nSELECT 1-None-None] PASSED [ 81%]
test/rules_std_test.py::test__rules__std_string[L004-pass-\t\tSELECT 1\n-None-None] PASSED [ 81%]
test/rules_std_test.py::test__rules__std_string[L004-fail-   \n  \t \n  SELECT 1-None-None] PASSED [ 82%]
test/rules_std_test.py::test__rules__std_string[L005-fail-SELECT 1 ,4-SELECT 1,4-None] PASSED [ 82%]
test/rules_std_test.py::test__rules__std_string[L008-pass-SELECT 1, 4-None-None] PASSED [ 82%]
test/rules_std_test.py::test__rules__std_string[L008-fail-SELECT 1,   4-SELECT 1, 4-None] PASSED [ 83%]
test/rules_std_test.py::test__rules__std_string[L014-pass-SELECT a, b-None-None] PASSED [ 83%]
test/rules_std_test.py::test__rules__std_string[L014-pass-SELECT A, B-None-None] PASSED [ 83%]
test/rules_std_test.py::test__rules__std_string[L015-fail-SELECT DISTINCT(a)-None-None] PASSED [ 83%]
test/rules_std_test.py::test__rules__std_string[L015-fail-SELECT DISTINCT(a + b) * c-None-None] PASSED [ 84%]
test/rules_std_test.py::test__rules__std_string[L015-pass-SELECT DISTINCT (a)-None-None] PASSED [ 84%]
test/rules_std_test.py::test__rules__std_string[L015-pass-SELECT DISTINCT (a + b) * c-None-None] PASSED [ 84%]
test/rules_std_test.py::test__rules__std_string[L014-fail-SELECT a,   B-SELECT a,   b-None] PASSED [ 85%]
test/rules_std_test.py::test__rules__std_string[L014-fail-SELECT B,   a-SELECT B,   A-None] PASSED [ 85%]
test/rules_std_test.py::test__rules__std_string[L014-pass-SELECT NULL,   a-None-None] PASSED [ 85%]
test/rules_std_test.py::test__rules__std_string[L010-fail-SELECT null,   a-SELECT NULL,   a-None] PASSED [ 86%]
test/rules_std_test.py::test__rules__std_string[L006-pass-SELECT COUNT(*) FROM tbl\n-None-None] PASSED [ 86%]
test/rules_std_test.py::test__rules__std_string[L016-pass-SELECT COUNT(*) FROM tbl\n-None-configs20] PASSED [ 86%]
test/rules_std_test.py::test__rules__std_string[L016-fail-SELECT 1 -- Some Comment\n--- Some Comment\nSELECT 1\n-configs21] PASSED [ 86%]
test/rules_std_test.py::test__rules__std_string[L016-fail-    SELECT COUNT(*) FROM tbl\n-    SELECT\n        COUNT(*)\n    FROM tbl\n-configs22] PASSED [ 87%]
test/rules_std_test.py::test__rules__std_string[L016-fail-SELECT 12345\n-SELECT\n    12345\n-configs23] PASSED [ 87%]
test/rules_std_test.py::test__rules__std_string[L016-fail-SELECT COUNT(*) FROM tbl -- Some Comment\n--- Some Comment\nSELECT\n    COUNT(*)\nFROM tbl\n-configs24] PASSED [ 87%]
test/rules_std_test.py::test__rules__std_string[L010-fail-SeLeCt 1-SELECT 1-None] PASSED [ 88%]
test/rules_std_test.py::test__rules__std_string[L010-fail-SeLeCt 1 from blah-SELECT 1 FROM blah-None] PASSED [ 88%]
test/rules_std_test.py::test__rules__std_string[L003-fail-  select 1 from tbl;-select 1 from tbl;-None] PASSED [ 88%]
test/rules_std_test.py::test__rules__std_string[L006-pass-select\n    field,\n    date(field_1) - date(field_2) as diff\nfrom table-None-None] PASSED [ 88%]
test/rules_std_test.py::test__rules__std_string[L003-pass-SELECT\n    -- Compute the thing\n    (a + b) AS c\nFROM\n    acceptable_buckets-None-None] PASSED [ 89%]
test/rules_std_test.py::test__rules__std_string[L003-pass-SELECT\n    user_id\nFROM\n    age_data\nJOIN\n    audience_size\n    USING (user_id, list_id)\n-- We LEFT JOIN because blah\nLEFT JOIN\n    verts\n    USING\n        (user_id)-None-None] PASSED [ 89%]
test/rules_std_test.py::test__rules__std_string[L019-fail-SELECT\n    a\n    , b\n    FROM c-None-configs31] PASSED [ 89%]
test/rules_std_test.py::test__rules__std_string[L019-pass-SELECT\n    a\n    , b\n    FROM c-None-configs32] PASSED [ 90%]
test/rules_std_test.py::test__rules__std_string[L019-fail-SELECT\n    a,\n    b\n    FROM c-None-configs33] PASSED [ 90%]
test/rules_std_test.py::test__rules__std_string[L019-pass-SELECT\n    a,\n    b\n    FROM c-None-configs34] PASSED [ 90%]
test/rules_std_test.py::test__rules__std_string[L003-pass-SELECT a, b, c\nFROM my_tbl\nLEFT JOIN another_tbl USING(a)-None-None] PASSED [ 90%]
test/rules_std_test.py::test__rules__std_string[L003-pass-SELECT a, b, c\nFROM my_tbl\nLEFT JOIN another_tbl USING(a)-None-configs36] PASSED [ 91%]
test/rules_std_test.py::test__rules__std_string[L003-pass-SELECT a, b, c\nFROM my_tbl\n    LEFT JOIN another_tbl USING(a)-None-configs37] PASSED [ 91%]
test/rules_std_test.py::test__rules__std_string[L003-fail-SELECT a, b, c\nFROM my_tbl\nLEFT JOIN another_tbl USING(a)-SELECT a, b, c\nFROM my_tbl\n    LEFT JOIN another_tbl USING(a)-configs38] PASSED [ 91%]
test/rules_std_test.py::test__rules__std_string[L003-fail-SELECT a, b, c\nFROM my_tbl\n    LEFT JOIN another_tbl USING(a)-SELECT a, b, c\nFROM my_tbl\nLEFT JOIN another_tbl USING(a)-configs39] PASSED [ 92%]
test/rules_std_test.py::test__rules__std_file[L001-test/fixtures/linter/indentation_errors.sql-violations0] PASSED [ 92%]
test/rules_std_test.py::test__rules__std_file[L002-test/fixtures/linter/indentation_errors.sql-violations1] PASSED [ 92%]
test/rules_std_test.py::test__rules__std_file[L003-test/fixtures/linter/indentation_errors.sql-violations2] PASSED [ 93%]
test/rules_std_test.py::test__rules__std_file[L004-test/fixtures/linter/indentation_errors.sql-violations3] PASSED [ 93%]
test/rules_std_test.py::test__rules__std_file[L005-test/fixtures/linter/whitespace_errors.sql-violations4] PASSED [ 93%]
test/rules_std_test.py::test__rules__std_file[L019-test/fixtures/linter/whitespace_errors.sql-violations5] PASSED [ 93%]
test/rules_std_test.py::test__rules__std_file[L008-test/fixtures/linter/whitespace_errors.sql-violations6] PASSED [ 94%]
test/rules_std_test.py::test__rules__std_file[L006-test/fixtures/linter/operator_errors.sql-violations7] PASSED [ 94%]
test/rules_std_test.py::test__rules__std_file[L007-test/fixtures/linter/operator_errors.sql-violations8] PASSED [ 94%]
test/rules_std_test.py::test__rules__std_file[L006-test/fixtures/linter/operator_errors_negative.sql-violations9] PASSED [ 95%]
test/rules_std_test.py::test__rules__std_file[L003-test/fixtures/linter/indentation_error_hard.sql-violations10] PASSED [ 95%]
test/rules_std_test.py::test__rules__std_file[L003-test/fixtures/linter/indentation_error_contained.sql-violations11] PASSED [ 95%]
test/rules_std_test.py::test__rules__std_file[L003-test/fixtures/linter/block_comment_errors.sql-violations12] PASSED [ 95%]
test/rules_std_test.py::test__rules__std_file[L016-test/fixtures/linter/block_comment_errors.sql-violations13] PASSED [ 96%]
test/rules_std_test.py::test__rules__std_file[L016-test/fixtures/linter/block_comment_errors_2.sql-violations14] PASSED [ 96%]
test/rules_std_test.py::test__rules__std_L003_process_raw_stack PASSED   [ 96%]
test/templaters_test.py::test__templater_selection PASSED                [ 97%]
test/templaters_test.py::test__templater_raw PASSED                      [ 97%]
test/templaters_test.py::test__templater_python PASSED                   [ 97%]
test/templaters_test.py::test__templater_python_error PASSED             [ 97%]
test/templaters_test.py::test__templater_jinja PASSED                    [ 98%]
test/templaters_test.py::test__templater_jinja_error PASSED              [ 98%]
test/templaters_test.py::test__templater_full[jinja_a/jinja-True] PASSED [ 98%]
test/templaters_test.py::test__templater_full[jinja_b/jinja-False] PASSED [ 99%]
test/templaters_test.py::test__templater_full[jinja_c_dbt/dbt_builtins-True] PASSED [ 99%]
test/templaters_test.py::test__templater_full[jinja_e/jinja-True] PASSED [ 99%]
test/templaters_test.py::test__templater_full[jinja_f/jinja-True] PASSED [100%]

=================================== FAILURES ===================================
___________ test__dialect__base_file_parse[teradata-select_stmt.sql] ___________

dialect = 'teradata', file = 'select_stmt.sql'

    @pytest.mark.parametrize(
        "dialect,file",
        parse_success_examples
    )
    def test__dialect__base_file_parse(dialect, file):
        """For given test examples, check successful parsing."""
        raw = load_file(dialect, file)
        # Load the right dialect
        config = FluffConfig(overrides=dict(dialect=dialect))
        context = ParseContext.from_config(config)
        fs, lex_vs = FileSegment.from_raw(raw, config=config)
        # From just the initial parse, check we're all there
        assert fs.raw == raw
        # Check we don't have lexing issues
        assert not lex_vs
    
        # Do the parse WITHOUT lots of logging
        # The logs get too long here to be useful. We should use
        # specfic segment tests if we want to debug logs.
        # with caplog.at_level(logging.DEBUG):
        print("Pre-parse structure: {0}".format(fs.to_tuple(show_raw=True)))
        print("Pre-parse structure: {0}".format(fs.stringify()))
>       parsed = fs.parse(parse_context=context)  # Optional: set recurse=1 to limit recursion

test/dialects_test.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/sqlfluff/parser/segments_base.py:456: in parse
    incr='parse_depth', match_depth=0, recurse=True
src/sqlfluff/parser/segments_base.py:688: in expand
    res = stmt.parse(parse_context=parse_context)
src/sqlfluff/parser/segments_base.py:409: in parse
    match_segment=self.__class__.__name__
src/sqlfluff/parser/grammar.py:81: in _match
    m = self.match(segments, parse_context=parse_context)
src/sqlfluff/parser/grammar.py:656: in match
    parse_context=parse_context.copy(incr='match_depth')
src/sqlfluff/parser/grammar.py:81: in _match
    m = self.match(segments, parse_context=parse_context)
src/sqlfluff/parser/grammar.py:580: in match
    parse_context=parse_context.copy(match_segment=self._get_ref()))
src/sqlfluff/parser/segments_base.py:651: in _match
    m = cls.match(segments, parse_context=parse_context)
src/sqlfluff/parser/segments_base.py:614: in match
    m = cls._match_grammar()._match(segments=segments, parse_context=parse_context.copy(incr='match_depth'))
src/sqlfluff/parser/grammar.py:81: in _match
    m = self.match(segments, parse_context=parse_context)
src/sqlfluff/parser/grammar.py:971: in match
    code_only=False)
src/sqlfluff/parser/grammar.py:467: in _bracket_sensitive_look_ahead_match
    code_only=code_only)
src/sqlfluff/parser/grammar.py:275: in _look_ahead_match
    simple_matchers = [m for m in matchers if m.simple(parse_context=parse_context)]
src/sqlfluff/parser/grammar.py:275: in <listcomp>
    simple_matchers = [m for m in matchers if m.simple(parse_context=parse_context)]
src/sqlfluff/parser/grammar.py:524: in simple
    ).simple(parse_context=parse_context)
src/sqlfluff/parser/segments_base.py:232: in simple
    return match_grammar.simple(parse_context=parse_context)
src/sqlfluff/parser/grammar.py:638: in simple
    simple = opt.simple(parse_context=parse_context)
src/sqlfluff/parser/grammar.py:523: in simple
    dialect=parse_context.dialect
src/sqlfluff/parser/grammar.py:542: in _get_elem
    return dialect.ref(self._get_ref())
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Dialect: teradata>, name = 'IntersectKeywordSegment'

    def ref(self, name):
        """Return an object which acts as a late binding reference to the element named.
    
        NB: This requires the dialect to be expanded.
    
        """
        if not self.expanded:
            raise RuntimeError("Dialect must be expanded before use.")
    
        if name in self._library:
            res = self._library[name]
            if res:
                return res
            else:
                raise ValueError(
                    "Unexpected Null response while fetching {0!r} from {1}".format(
                        name, self.name))
        else:
            raise RuntimeError(
                "Grammar refers to {0!r} which was not found in the {1} dialect".format(
>                   name, self.name))
E           RuntimeError: Grammar refers to 'IntersectKeywordSegment' which was not found in the teradata dialect

src/sqlfluff/dialects/base.py:219: RuntimeError
----------------------------- Captured stdout call -----------------------------
Pre-parse structure: ('file', (('raw', 'SELECT'), ('newline', '\n'), ('whitespace', '    '), ('raw', 'ADD_MONTHS'), ('raw', '('), ('raw', 'abandono'), ('raw', '.'), ('raw', 'FEC_CIERRE_EST'), ('comma', ','), ('whitespace', ' '), ('raw', '-'), ('raw', '12'), ('raw', ')'), ('whitespace', ' '), ('raw', 'AS'), ('whitespace', ' '), ('raw', 'FEC_CIERRE_EST_ULT12'), ('comma', ','), ('newline', '\n'), ('whitespace', '    '), ('raw', 'CAST'), ('raw', '('), ('raw', "'200010'"), ('whitespace', ' '), ('raw', 'AS'), ('whitespace', ' '), ('raw', 'DATE'), ('whitespace', ' '), ('raw', 'FORMAT'), ('whitespace', ' '), ('raw', "'YYYYMM'"), ('raw', ')'), ('whitespace', ' '), ('raw', 'AS'), ('whitespace', ' '), ('raw', 'CAST_STATEMENT_EXAMPLE'), ('newline', '\n'), ('raw', 'FROM'), ('whitespace', ' '), ('raw', 'EXAMPLE_TABLE'), ('raw', ';'), ('newline', '\n')))
Pre-parse structure: FileSegment:                                                [0](1, 1, 1)
    code_RawSegment:                                        [0](1, 1, 1)        'SELECT'
    newline_RawSegment:                                     [6](1, 1, 7)        '\n'
    whitespace_RawSegment:                                  [7](1, 2, 1)        '    '
    code_RawSegment:                                        [11](1, 2, 5)       'ADD_MONTHS'
    bracket_open_RawSegment:                                [21](1, 2, 15)      '('
    code_RawSegment:                                        [22](1, 2, 16)      'abandono'
    dot_RawSegment:                                         [30](1, 2, 24)      '.'
    code_RawSegment:                                        [31](1, 2, 25)      'FEC_CIERRE_EST'
    comma_RawSegment:                                       [45](1, 2, 39)      ','
    whitespace_RawSegment:                                  [46](1, 2, 40)      ' '
    minus_RawSegment:                                       [47](1, 2, 41)      '-'
    numeric_literal_RawSegment:                             [48](1, 2, 42)      '12'
    bracket_close_RawSegment:                               [50](1, 2, 44)      ')'
    whitespace_RawSegment:                                  [51](1, 2, 45)      ' '
    code_RawSegment:                                        [52](1, 2, 46)      'AS'
    whitespace_RawSegment:                                  [54](1, 2, 48)      ' '
    code_RawSegment:                                        [55](1, 2, 49)      'FEC_CIERRE_EST_ULT12'
    comma_RawSegment:                                       [75](1, 2, 69)      ','
    newline_RawSegment:                                     [76](1, 2, 70)      '\n'
    whitespace_RawSegment:                                  [77](1, 3, 1)       '    '
    code_RawSegment:                                        [81](1, 3, 5)       'CAST'
    bracket_open_RawSegment:                                [85](1, 3, 9)       '('
    single_quote_RawSegment:                                [86](1, 3, 10)      "'200010'"
    whitespace_RawSegment:                                  [94](1, 3, 18)      ' '
    code_RawSegment:                                        [95](1, 3, 19)      'AS'
    whitespace_RawSegment:                                  [97](1, 3, 21)      ' '
    code_RawSegment:                                        [98](1, 3, 22)      'DATE'
    whitespace_RawSegment:                                  [102](1, 3, 26)     ' '
    code_RawSegment:                                        [103](1, 3, 27)     'FORMAT'
    whitespace_RawSegment:                                  [109](1, 3, 33)     ' '
    single_quote_RawSegment:                                [110](1, 3, 34)     "'YYYYMM'"
    bracket_close_RawSegment:                               [118](1, 3, 42)     ')'
    whitespace_RawSegment:                                  [119](1, 3, 43)     ' '
    code_RawSegment:                                        [120](1, 3, 44)     'AS'
    whitespace_RawSegment:                                  [122](1, 3, 46)     ' '
    code_RawSegment:                                        [123](1, 3, 47)     'CAST_STATEMENT_EXAMPLE'
    newline_RawSegment:                                     [145](1, 3, 69)     '\n'
    code_RawSegment:                                        [146](1, 4, 1)      'FROM'
    whitespace_RawSegment:                                  [150](1, 4, 5)      ' '
    code_RawSegment:                                        [151](1, 4, 6)      'EXAMPLE_TABLE'
    semicolon_RawSegment:                                   [164](1, 4, 19)     ';'
    newline_RawSegment:                                     [165](1, 4, 20)     '\n'

_______ test__dialect__base_file_parse[teradata-create_table_stmt_3.sql] _______

dialect = 'teradata', file = 'create_table_stmt_3.sql'

    @pytest.mark.parametrize(
        "dialect,file",
        parse_success_examples
    )
    def test__dialect__base_file_parse(dialect, file):
        """For given test examples, check successful parsing."""
        raw = load_file(dialect, file)
        # Load the right dialect
        config = FluffConfig(overrides=dict(dialect=dialect))
        context = ParseContext.from_config(config)
        fs, lex_vs = FileSegment.from_raw(raw, config=config)
        # From just the initial parse, check we're all there
        assert fs.raw == raw
        # Check we don't have lexing issues
        assert not lex_vs
    
        # Do the parse WITHOUT lots of logging
        # The logs get too long here to be useful. We should use
        # specfic segment tests if we want to debug logs.
        # with caplog.at_level(logging.DEBUG):
        print("Pre-parse structure: {0}".format(fs.to_tuple(show_raw=True)))
        print("Pre-parse structure: {0}".format(fs.stringify()))
>       parsed = fs.parse(parse_context=context)  # Optional: set recurse=1 to limit recursion

test/dialects_test.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/sqlfluff/parser/segments_base.py:456: in parse
    incr='parse_depth', match_depth=0, recurse=True
src/sqlfluff/parser/segments_base.py:688: in expand
    res = stmt.parse(parse_context=parse_context)
src/sqlfluff/parser/segments_base.py:409: in parse
    match_segment=self.__class__.__name__
src/sqlfluff/parser/grammar.py:81: in _match
    m = self.match(segments, parse_context=parse_context)
src/sqlfluff/parser/grammar.py:656: in match
    parse_context=parse_context.copy(incr='match_depth')
src/sqlfluff/parser/grammar.py:81: in _match
    m = self.match(segments, parse_context=parse_context)
src/sqlfluff/parser/grammar.py:580: in match
    parse_context=parse_context.copy(match_segment=self._get_ref()))
src/sqlfluff/parser/segments_base.py:651: in _match
    m = cls.match(segments, parse_context=parse_context)
src/sqlfluff/parser/segments_base.py:614: in match
    m = cls._match_grammar()._match(segments=segments, parse_context=parse_context.copy(incr='match_depth'))
src/sqlfluff/parser/grammar.py:81: in _match
    m = self.match(segments, parse_context=parse_context)
src/sqlfluff/parser/grammar.py:971: in match
    code_only=False)
src/sqlfluff/parser/grammar.py:467: in _bracket_sensitive_look_ahead_match
    code_only=code_only)
src/sqlfluff/parser/grammar.py:275: in _look_ahead_match
    simple_matchers = [m for m in matchers if m.simple(parse_context=parse_context)]
src/sqlfluff/parser/grammar.py:275: in <listcomp>
    simple_matchers = [m for m in matchers if m.simple(parse_context=parse_context)]
src/sqlfluff/parser/grammar.py:524: in simple
    ).simple(parse_context=parse_context)
src/sqlfluff/parser/segments_base.py:232: in simple
    return match_grammar.simple(parse_context=parse_context)
src/sqlfluff/parser/grammar.py:638: in simple
    simple = opt.simple(parse_context=parse_context)
src/sqlfluff/parser/grammar.py:523: in simple
    dialect=parse_context.dialect
src/sqlfluff/parser/grammar.py:542: in _get_elem
    return dialect.ref(self._get_ref())
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Dialect: teradata>, name = 'IntersectKeywordSegment'

    def ref(self, name):
        """Return an object which acts as a late binding reference to the element named.
    
        NB: This requires the dialect to be expanded.
    
        """
        if not self.expanded:
            raise RuntimeError("Dialect must be expanded before use.")
    
        if name in self._library:
            res = self._library[name]
            if res:
                return res
            else:
                raise ValueError(
                    "Unexpected Null response while fetching {0!r} from {1}".format(
                        name, self.name))
        else:
            raise RuntimeError(
                "Grammar refers to {0!r} which was not found in the {1} dialect".format(
>                   name, self.name))
E           RuntimeError: Grammar refers to 'IntersectKeywordSegment' which was not found in the teradata dialect

src/sqlfluff/dialects/base.py:219: RuntimeError
----------------------------- Captured stdout call -----------------------------
Pre-parse structure: ('file', (('comment', '-- Testing of the specific create table end options'), ('newline', '\n'), ('raw', 'CREATE'), ('whitespace', ' '), ('raw', 'MULTISET'), ('whitespace', ' '), ('raw', 'TABLE'), ('whitespace', ' '), ('raw', 'NUM_LTR_DESVINCULADOS_ADH'), ('newline', '\n'), ('raw', '('), ('newline', '\n'), ('whitespace', '    '), ('raw', 'DES_EVENTO'), ('whitespace', ' '), ('raw', 'VARCHAR'), ('raw', '('), ('raw', '255'), ('raw', ')'), ('whitespace', ' '), ('raw', 'CHARACTER'), ('whitespace', ' '), ('raw', 'SET'), ('whitespace', ' '), ('raw', 'LATIN'), ('whitespace', ' '), ('raw', 'NOT'), ('whitespace', ' '), ('raw', 'CASESPECIFIC'), ('whitespace', ' '), ('raw', 'COMPRESS'), ('whitespace', ' '), ('raw', '('), ('raw', "'Cambio de bandera'"), ('comma', ','), ('whitespace', ' '), ('raw', "'Cierre'"), ('raw', ')'), ('comma', ','), ('newline', '\n'), ('whitespace', '    '), ('raw', 'IND_CONTINUA'), ('whitespace', ' '), ('raw', 'BYTEINT'), ('whitespace', ' '), ('raw', 'COMPRESS'), ('newline', '\n'), ('whitespace', ' '), ('raw', ')'), ('newline', '\n'), ('raw', 'PRIMARY'), ('whitespace', ' '), ('raw', 'INDEX'), ('raw', '('), ('whitespace', ' '), ('raw', 'COD_TARJETA'), ('comma', ','), ('whitespace', ' '), ('raw', 'COD_EST'), ('comma', ','), ('whitespace', ' '), ('raw', 'FEC_CIERRE_EST'), ('comma', ','), ('whitespace', ' '), ('raw', 'IND_TIPO_TARJETA'), ('whitespace', ' '), ('raw', ')'), ('newline', '\n'), ('raw', 'PARTITION'), ('whitespace', ' '), ('raw', 'BY'), ('whitespace', ' '), ('raw', 'RANGE_N'), ('whitespace', ' '), ('raw', '('), ('raw', 'FEC_OPERACION'), ('whitespace', ' '), ('raw', 'BETWEEN'), ('whitespace', ' '), ('raw', 'DATE'), ('whitespace', ' '), ('raw', "'2007-01-01'"), ('whitespace', ' '), ('raw', 'AND'), ('whitespace', ' '), ('raw', 'DATE'), ('whitespace', ' '), ('raw', "'2022-01-01'"), ('whitespace', ' '), ('raw', 'EACH'), ('whitespace', ' '), ('raw', 'INTERVAL'), ('whitespace', ' '), ('raw', "'1'"), ('whitespace', ' '), ('raw', 'MONTH'), ('comma', ','), ('whitespace', ' '), ('raw', 'NO'), ('whitespace', ' '), ('raw', 'RANGE'), ('whitespace', ' '), ('raw', 'OR'), ('whitespace', ' '), ('raw', 'UNKNOWN'), ('raw', ')'), ('newline', '\n'), ('raw', 'INDEX'), ('whitespace', ' '), ('raw', 'HOPR_TRN_TRAV_SIN_MP_I'), ('whitespace', ' '), ('raw', '('), ('whitespace', ' '), ('raw', 'IND_TIPO_TARJETA'), ('whitespace', ' '), ('raw', ')'), ('raw', ';')))
Pre-parse structure: FileSegment:                                                [0](1, 1, 1)
    inline_comment_RawSegment:                              [0](1, 1, 1)        '-- Testing of the specific create table end options'
    newline_RawSegment:                                     [51](1, 1, 52)      '\n'
    code_RawSegment:                                        [52](1, 2, 1)       'CREATE'
    whitespace_RawSegment:                                  [58](1, 2, 7)       ' '
    code_RawSegment:                                        [59](1, 2, 8)       'MULTISET'
    whitespace_RawSegment:                                  [67](1, 2, 16)      ' '
    code_RawSegment:                                        [68](1, 2, 17)      'TABLE'
    whitespace_RawSegment:                                  [73](1, 2, 22)      ' '
    code_RawSegment:                                        [74](1, 2, 23)      'NUM_LTR_DESVINCULADOS_ADH'
    newline_RawSegment:                                     [99](1, 2, 48)      '\n'
    bracket_open_RawSegment:                                [100](1, 3, 1)      '('
    newline_RawSegment:                                     [101](1, 3, 2)      '\n'
    whitespace_RawSegment:                                  [102](1, 4, 1)      '    '
    code_RawSegment:                                        [106](1, 4, 5)      'DES_EVENTO'
    whitespace_RawSegment:                                  [116](1, 4, 15)     ' '
    code_RawSegment:                                        [117](1, 4, 16)     'VARCHAR'
    bracket_open_RawSegment:                                [124](1, 4, 23)     '('
    numeric_literal_RawSegment:                             [125](1, 4, 24)     '255'
    bracket_close_RawSegment:                               [128](1, 4, 27)     ')'
    whitespace_RawSegment:                                  [129](1, 4, 28)     ' '
    code_RawSegment:                                        [130](1, 4, 29)     'CHARACTER'
    whitespace_RawSegment:                                  [139](1, 4, 38)     ' '
    code_RawSegment:                                        [140](1, 4, 39)     'SET'
    whitespace_RawSegment:                                  [143](1, 4, 42)     ' '
    code_RawSegment:                                        [144](1, 4, 43)     'LATIN'
    whitespace_RawSegment:                                  [149](1, 4, 48)     ' '
    code_RawSegment:                                        [150](1, 4, 49)     'NOT'
    whitespace_RawSegment:                                  [153](1, 4, 52)     ' '
    code_RawSegment:                                        [154](1, 4, 53)     'CASESPECIFIC'
    whitespace_RawSegment:                                  [166](1, 4, 65)     ' '
    code_RawSegment:                                        [167](1, 4, 66)     'COMPRESS'
    whitespace_RawSegment:                                  [175](1, 4, 74)     ' '
    bracket_open_RawSegment:                                [176](1, 4, 75)     '('
    single_quote_RawSegment:                                [177](1, 4, 76)     "'Cambio de bandera'"
    comma_RawSegment:                                       [196](1, 4, 95)     ','
    whitespace_RawSegment:                                  [197](1, 4, 96)     ' '
    single_quote_RawSegment:                                [198](1, 4, 97)     "'Cierre'"
    bracket_close_RawSegment:                               [206](1, 4, 105)    ')'
    comma_RawSegment:                                       [207](1, 4, 106)    ','
    newline_RawSegment:                                     [208](1, 4, 107)    '\n'
    whitespace_RawSegment:                                  [209](1, 5, 1)      '    '
    code_RawSegment:                                        [213](1, 5, 5)      'IND_CONTINUA'
    whitespace_RawSegment:                                  [225](1, 5, 17)     ' '
    code_RawSegment:                                        [226](1, 5, 18)     'BYTEINT'
    whitespace_RawSegment:                                  [233](1, 5, 25)     ' '
    code_RawSegment:                                        [234](1, 5, 26)     'COMPRESS'
    newline_RawSegment:                                     [242](1, 5, 34)     '\n'
    whitespace_RawSegment:                                  [243](1, 6, 1)      ' '
    bracket_close_RawSegment:                               [244](1, 6, 2)      ')'
    newline_RawSegment:                                     [245](1, 6, 3)      '\n'
    code_RawSegment:                                        [246](1, 7, 1)      'PRIMARY'
    whitespace_RawSegment:                                  [253](1, 7, 8)      ' '
    code_RawSegment:                                        [254](1, 7, 9)      'INDEX'
    bracket_open_RawSegment:                                [259](1, 7, 14)     '('
    whitespace_RawSegment:                                  [260](1, 7, 15)     ' '
    code_RawSegment:                                        [261](1, 7, 16)     'COD_TARJETA'
    comma_RawSegment:                                       [272](1, 7, 27)     ','
    whitespace_RawSegment:                                  [273](1, 7, 28)     ' '
    code_RawSegment:                                        [274](1, 7, 29)     'COD_EST'
    comma_RawSegment:                                       [281](1, 7, 36)     ','
    whitespace_RawSegment:                                  [282](1, 7, 37)     ' '
    code_RawSegment:                                        [283](1, 7, 38)     'FEC_CIERRE_EST'
    comma_RawSegment:                                       [297](1, 7, 52)     ','
    whitespace_RawSegment:                                  [298](1, 7, 53)     ' '
    code_RawSegment:                                        [299](1, 7, 54)     'IND_TIPO_TARJETA'
    whitespace_RawSegment:                                  [315](1, 7, 70)     ' '
    bracket_close_RawSegment:                               [316](1, 7, 71)     ')'
    newline_RawSegment:                                     [317](1, 7, 72)     '\n'
    code_RawSegment:                                        [318](1, 8, 1)      'PARTITION'
    whitespace_RawSegment:                                  [327](1, 8, 10)     ' '
    code_RawSegment:                                        [328](1, 8, 11)     'BY'
    whitespace_RawSegment:                                  [330](1, 8, 13)     ' '
    code_RawSegment:                                        [331](1, 8, 14)     'RANGE_N'
    whitespace_RawSegment:                                  [338](1, 8, 21)     ' '
    bracket_open_RawSegment:                                [339](1, 8, 22)     '('
    code_RawSegment:                                        [340](1, 8, 23)     'FEC_OPERACION'
    whitespace_RawSegment:                                  [353](1, 8, 36)     ' '
    code_RawSegment:                                        [354](1, 8, 37)     'BETWEEN'
    whitespace_RawSegment:                                  [361](1, 8, 44)     ' '
    code_RawSegment:                                        [362](1, 8, 45)     'DATE'
    whitespace_RawSegment:                                  [366](1, 8, 49)     ' '
    single_quote_RawSegment:                                [367](1, 8, 50)     "'2007-01-01'"
    whitespace_RawSegment:                                  [379](1, 8, 62)     ' '
    code_RawSegment:                                        [380](1, 8, 63)     'AND'
    whitespace_RawSegment:                                  [383](1, 8, 66)     ' '
    code_RawSegment:                                        [384](1, 8, 67)     'DATE'
    whitespace_RawSegment:                                  [388](1, 8, 71)     ' '
    single_quote_RawSegment:                                [389](1, 8, 72)     "'2022-01-01'"
    whitespace_RawSegment:                                  [401](1, 8, 84)     ' '
    code_RawSegment:                                        [402](1, 8, 85)     'EACH'
    whitespace_RawSegment:                                  [406](1, 8, 89)     ' '
    code_RawSegment:                                        [407](1, 8, 90)     'INTERVAL'
    whitespace_RawSegment:                                  [415](1, 8, 98)     ' '
    single_quote_RawSegment:                                [416](1, 8, 99)     "'1'"
    whitespace_RawSegment:                                  [419](1, 8, 102)    ' '
    code_RawSegment:                                        [420](1, 8, 103)    'MONTH'
    comma_RawSegment:                                       [425](1, 8, 108)    ','
    whitespace_RawSegment:                                  [426](1, 8, 109)    ' '
    code_RawSegment:                                        [427](1, 8, 110)    'NO'
    whitespace_RawSegment:                                  [429](1, 8, 112)    ' '
    code_RawSegment:                                        [430](1, 8, 113)    'RANGE'
    whitespace_RawSegment:                                  [435](1, 8, 118)    ' '
    code_RawSegment:                                        [436](1, 8, 119)    'OR'
    whitespace_RawSegment:                                  [438](1, 8, 121)    ' '
    code_RawSegment:                                        [439](1, 8, 122)    'UNKNOWN'
    bracket_close_RawSegment:                               [446](1, 8, 129)    ')'
    newline_RawSegment:                                     [447](1, 8, 130)    '\n'
    code_RawSegment:                                        [448](1, 9, 1)      'INDEX'
    whitespace_RawSegment:                                  [453](1, 9, 6)      ' '
    code_RawSegment:                                        [454](1, 9, 7)      'HOPR_TRN_TRAV_SIN_MP_I'
    whitespace_RawSegment:                                  [476](1, 9, 29)     ' '
    bracket_open_RawSegment:                                [477](1, 9, 30)     '('
    whitespace_RawSegment:                                  [478](1, 9, 31)     ' '
    code_RawSegment:                                        [479](1, 9, 32)     'IND_TIPO_TARJETA'
    whitespace_RawSegment:                                  [495](1, 9, 48)     ' '
    bracket_close_RawSegment:                               [496](1, 9, 49)     ')'
    semicolon_RawSegment:                                   [497](1, 9, 50)     ';'

_______ test__dialect__base_file_parse[teradata-create_table_stmt_2.sql] _______

dialect = 'teradata', file = 'create_table_stmt_2.sql'

    @pytest.mark.parametrize(
        "dialect,file",
        parse_success_examples
    )
    def test__dialect__base_file_parse(dialect, file):
        """For given test examples, check successful parsing."""
        raw = load_file(dialect, file)
        # Load the right dialect
        config = FluffConfig(overrides=dict(dialect=dialect))
        context = ParseContext.from_config(config)
        fs, lex_vs = FileSegment.from_raw(raw, config=config)
        # From just the initial parse, check we're all there
        assert fs.raw == raw
        # Check we don't have lexing issues
        assert not lex_vs
    
        # Do the parse WITHOUT lots of logging
        # The logs get too long here to be useful. We should use
        # specfic segment tests if we want to debug logs.
        # with caplog.at_level(logging.DEBUG):
        print("Pre-parse structure: {0}".format(fs.to_tuple(show_raw=True)))
        print("Pre-parse structure: {0}".format(fs.stringify()))
>       parsed = fs.parse(parse_context=context)  # Optional: set recurse=1 to limit recursion

test/dialects_test.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/sqlfluff/parser/segments_base.py:456: in parse
    incr='parse_depth', match_depth=0, recurse=True
src/sqlfluff/parser/segments_base.py:688: in expand
    res = stmt.parse(parse_context=parse_context)
src/sqlfluff/parser/segments_base.py:409: in parse
    match_segment=self.__class__.__name__
src/sqlfluff/parser/grammar.py:81: in _match
    m = self.match(segments, parse_context=parse_context)
src/sqlfluff/parser/grammar.py:656: in match
    parse_context=parse_context.copy(incr='match_depth')
src/sqlfluff/parser/grammar.py:81: in _match
    m = self.match(segments, parse_context=parse_context)
src/sqlfluff/parser/grammar.py:580: in match
    parse_context=parse_context.copy(match_segment=self._get_ref()))
src/sqlfluff/parser/segments_base.py:651: in _match
    m = cls.match(segments, parse_context=parse_context)
src/sqlfluff/parser/segments_base.py:614: in match
    m = cls._match_grammar()._match(segments=segments, parse_context=parse_context.copy(incr='match_depth'))
src/sqlfluff/parser/grammar.py:81: in _match
    m = self.match(segments, parse_context=parse_context)
src/sqlfluff/parser/grammar.py:971: in match
    code_only=False)
src/sqlfluff/parser/grammar.py:467: in _bracket_sensitive_look_ahead_match
    code_only=code_only)
src/sqlfluff/parser/grammar.py:275: in _look_ahead_match
    simple_matchers = [m for m in matchers if m.simple(parse_context=parse_context)]
src/sqlfluff/parser/grammar.py:275: in <listcomp>
    simple_matchers = [m for m in matchers if m.simple(parse_context=parse_context)]
src/sqlfluff/parser/grammar.py:524: in simple
    ).simple(parse_context=parse_context)
src/sqlfluff/parser/segments_base.py:232: in simple
    return match_grammar.simple(parse_context=parse_context)
src/sqlfluff/parser/grammar.py:638: in simple
    simple = opt.simple(parse_context=parse_context)
src/sqlfluff/parser/grammar.py:523: in simple
    dialect=parse_context.dialect
src/sqlfluff/parser/grammar.py:542: in _get_elem
    return dialect.ref(self._get_ref())
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Dialect: teradata>, name = 'IntersectKeywordSegment'

    def ref(self, name):
        """Return an object which acts as a late binding reference to the element named.
    
        NB: This requires the dialect to be expanded.
    
        """
        if not self.expanded:
            raise RuntimeError("Dialect must be expanded before use.")
    
        if name in self._library:
            res = self._library[name]
            if res:
                return res
            else:
                raise ValueError(
                    "Unexpected Null response while fetching {0!r} from {1}".format(
                        name, self.name))
        else:
            raise RuntimeError(
                "Grammar refers to {0!r} which was not found in the {1} dialect".format(
>                   name, self.name))
E           RuntimeError: Grammar refers to 'IntersectKeywordSegment' which was not found in the teradata dialect

src/sqlfluff/dialects/base.py:219: RuntimeError
----------------------------- Captured stdout call -----------------------------
Pre-parse structure: ('file', (('comment', '-- Testing of the specific column options'), ('newline', '\n'), ('raw', 'CREATE'), ('whitespace', ' '), ('raw', 'MULTISET'), ('whitespace', ' '), ('raw', 'TABLE'), ('whitespace', ' '), ('raw', 'TABLE_2'), ('newline', '\n'), ('raw', '('), ('newline', '\n'), ('whitespace', '    '), ('raw', 'CHAR_FIELD'), ('whitespace', ' '), ('raw', 'CHAR'), ('raw', '('), ('raw', '19'), ('raw', ')'), ('whitespace', ' '), ('raw', 'CHARACTER'), ('whitespace', ' '), ('raw', 'SET'), ('whitespace', ' '), ('raw', 'LATIN'), ('whitespace', ' '), ('raw', 'NOT'), ('whitespace', ' '), ('raw', 'CASESPECIFIC'), ('whitespace', ' '), ('raw', 'NOT'), ('whitespace', ' '), ('raw', 'NULL'), ('comma', ','), ('newline', '\n'), ('whitespace', '    '), ('raw', 'DATE_FIELD'), ('whitespace', ' '), ('raw', 'DATE'), ('whitespace', ' '), ('raw', 'FORMAT'), ('whitespace', ' '), ('raw', "'YYYY-MM-DD'"), ('whitespace', ' '), ('raw', 'NOT'), ('whitespace', ' '), ('raw', 'NULL'), ('comma', ','), ('newline', '\n'), ('whitespace', '    '), ('raw', 'BYTE_FIELD'), ('whitespace', ' '), ('raw', 'BYTEINT'), ('whitespace', ' '), ('raw', 'COMPRESS'), ('whitespace', ' '), ('raw', '0'), ('comma', ','), ('newline', '\n'), ('whitespace', '    '), ('raw', 'DECIMAL_FIELD'), ('whitespace', ' '), ('raw', 'DECIMAL'), ('raw', '('), ('raw', '15'), ('comma', ','), ('whitespace', ' '), ('raw', '2'), ('raw', ')'), ('whitespace', ' '), ('raw', 'COMPRESS'), ('whitespace', ' '), ('raw', '('), ('raw', '50.00'), ('comma', ','), ('whitespace', ' '), ('raw', '45.50'), ('comma', ','), ('whitespace', ' '), ('raw', '40.00'), ('comma', ','), ('whitespace', ' '), ('raw', '30.00'), ('comma', ','), ('whitespace', ' '), ('raw', '27.80'), ('comma', ','), ('whitespace', ' '), ('raw', '27.05'), ('comma', ','), ('whitespace', ' '), ('raw', '20.00'), ('comma', ','), ('whitespace', ' '), ('raw', '17.87'), ('comma', ','), ('whitespace', ' '), ('raw', '17.56'), ('comma', ','), ('whitespace', ' '), ('raw', '17.41'), ('comma', ','), ('whitespace', ' '), ('raw', '17.26'), ('comma', ','), ('whitespace', ' '), ('raw', '17.11'), ('comma', ','), ('whitespace', ' '), ('raw', '16.96'), ('comma', ','), ('whitespace', ' '), ('raw', '16.82'), ('comma', ','), ('whitespace', ' '), ('raw', '16.68'), ('raw', ')'), ('comma', ','), ('newline', '\n'), ('whitespace', '    '), ('raw', 'TIMESTAMP_FIELD'), ('whitespace', ' '), ('raw', 'TIMESTAMP'), ('raw', '('), ('raw', '6'), ('raw', ')'), ('whitespace', ' '), ('raw', 'NOT'), ('whitespace', ' '), ('raw', 'NULL'), ('newline', '\n'), ('raw', ')'), ('newline', '\n'), ('raw', 'PRIMARY'), ('whitespace', ' '), ('raw', 'INDEX'), ('raw', '('), ('whitespace', ' '), ('raw', 'CHAR_FIELD'), ('comma', ','), ('whitespace', ' '), ('raw', 'DATE_FIELD'), ('comma', ','), ('whitespace', ' '), ('raw', 'BYTE_FIELD'), ('whitespace', ' '), ('raw', ')'), ('raw', ';')))
Pre-parse structure: FileSegment:                                                [0](1, 1, 1)
    inline_comment_RawSegment:                              [0](1, 1, 1)        '-- Testing of the specific column options'
    newline_RawSegment:                                     [41](1, 1, 42)      '\n'
    code_RawSegment:                                        [42](1, 2, 1)       'CREATE'
    whitespace_RawSegment:                                  [48](1, 2, 7)       ' '
    code_RawSegment:                                        [49](1, 2, 8)       'MULTISET'
    whitespace_RawSegment:                                  [57](1, 2, 16)      ' '
    code_RawSegment:                                        [58](1, 2, 17)      'TABLE'
    whitespace_RawSegment:                                  [63](1, 2, 22)      ' '
    code_RawSegment:                                        [64](1, 2, 23)      'TABLE_2'
    newline_RawSegment:                                     [71](1, 2, 30)      '\n'
    bracket_open_RawSegment:                                [72](1, 3, 1)       '('
    newline_RawSegment:                                     [73](1, 3, 2)       '\n'
    whitespace_RawSegment:                                  [74](1, 4, 1)       '    '
    code_RawSegment:                                        [78](1, 4, 5)       'CHAR_FIELD'
    whitespace_RawSegment:                                  [88](1, 4, 15)      ' '
    code_RawSegment:                                        [89](1, 4, 16)      'CHAR'
    bracket_open_RawSegment:                                [93](1, 4, 20)      '('
    numeric_literal_RawSegment:                             [94](1, 4, 21)      '19'
    bracket_close_RawSegment:                               [96](1, 4, 23)      ')'
    whitespace_RawSegment:                                  [97](1, 4, 24)      ' '
    code_RawSegment:                                        [98](1, 4, 25)      'CHARACTER'
    whitespace_RawSegment:                                  [107](1, 4, 34)     ' '
    code_RawSegment:                                        [108](1, 4, 35)     'SET'
    whitespace_RawSegment:                                  [111](1, 4, 38)     ' '
    code_RawSegment:                                        [112](1, 4, 39)     'LATIN'
    whitespace_RawSegment:                                  [117](1, 4, 44)     ' '
    code_RawSegment:                                        [118](1, 4, 45)     'NOT'
    whitespace_RawSegment:                                  [121](1, 4, 48)     ' '
    code_RawSegment:                                        [122](1, 4, 49)     'CASESPECIFIC'
    whitespace_RawSegment:                                  [134](1, 4, 61)     ' '
    code_RawSegment:                                        [135](1, 4, 62)     'NOT'
    whitespace_RawSegment:                                  [138](1, 4, 65)     ' '
    code_RawSegment:                                        [139](1, 4, 66)     'NULL'
    comma_RawSegment:                                       [143](1, 4, 70)     ','
    newline_RawSegment:                                     [144](1, 4, 71)     '\n'
    whitespace_RawSegment:                                  [145](1, 5, 1)      '    '
    code_RawSegment:                                        [149](1, 5, 5)      'DATE_FIELD'
    whitespace_RawSegment:                                  [159](1, 5, 15)     ' '
    code_RawSegment:                                        [160](1, 5, 16)     'DATE'
    whitespace_RawSegment:                                  [164](1, 5, 20)     ' '
    code_RawSegment:                                        [165](1, 5, 21)     'FORMAT'
    whitespace_RawSegment:                                  [171](1, 5, 27)     ' '
    single_quote_RawSegment:                                [172](1, 5, 28)     "'YYYY-MM-DD'"
    whitespace_RawSegment:                                  [184](1, 5, 40)     ' '
    code_RawSegment:                                        [185](1, 5, 41)     'NOT'
    whitespace_RawSegment:                                  [188](1, 5, 44)     ' '
    code_RawSegment:                                        [189](1, 5, 45)     'NULL'
    comma_RawSegment:                                       [193](1, 5, 49)     ','
    newline_RawSegment:                                     [194](1, 5, 50)     '\n'
    whitespace_RawSegment:                                  [195](1, 6, 1)      '    '
    code_RawSegment:                                        [199](1, 6, 5)      'BYTE_FIELD'
    whitespace_RawSegment:                                  [209](1, 6, 15)     ' '
    code_RawSegment:                                        [210](1, 6, 16)     'BYTEINT'
    whitespace_RawSegment:                                  [217](1, 6, 23)     ' '
    code_RawSegment:                                        [218](1, 6, 24)     'COMPRESS'
    whitespace_RawSegment:                                  [226](1, 6, 32)     ' '
    numeric_literal_RawSegment:                             [227](1, 6, 33)     '0'
    comma_RawSegment:                                       [228](1, 6, 34)     ','
    newline_RawSegment:                                     [229](1, 6, 35)     '\n'
    whitespace_RawSegment:                                  [230](1, 7, 1)      '    '
    code_RawSegment:                                        [234](1, 7, 5)      'DECIMAL_FIELD'
    whitespace_RawSegment:                                  [247](1, 7, 18)     ' '
    code_RawSegment:                                        [248](1, 7, 19)     'DECIMAL'
    bracket_open_RawSegment:                                [255](1, 7, 26)     '('
    numeric_literal_RawSegment:                             [256](1, 7, 27)     '15'
    comma_RawSegment:                                       [258](1, 7, 29)     ','
    whitespace_RawSegment:                                  [259](1, 7, 30)     ' '
    numeric_literal_RawSegment:                             [260](1, 7, 31)     '2'
    bracket_close_RawSegment:                               [261](1, 7, 32)     ')'
    whitespace_RawSegment:                                  [262](1, 7, 33)     ' '
    code_RawSegment:                                        [263](1, 7, 34)     'COMPRESS'
    whitespace_RawSegment:                                  [271](1, 7, 42)     ' '
    bracket_open_RawSegment:                                [272](1, 7, 43)     '('
    numeric_literal_RawSegment:                             [273](1, 7, 44)     '50.00'
    comma_RawSegment:                                       [278](1, 7, 49)     ','
    whitespace_RawSegment:                                  [279](1, 7, 50)     ' '
    numeric_literal_RawSegment:                             [280](1, 7, 51)     '45.50'
    comma_RawSegment:                                       [285](1, 7, 56)     ','
    whitespace_RawSegment:                                  [286](1, 7, 57)     ' '
    numeric_literal_RawSegment:                             [287](1, 7, 58)     '40.00'
    comma_RawSegment:                                       [292](1, 7, 63)     ','
    whitespace_RawSegment:                                  [293](1, 7, 64)     ' '
    numeric_literal_RawSegment:                             [294](1, 7, 65)     '30.00'
    comma_RawSegment:                                       [299](1, 7, 70)     ','
    whitespace_RawSegment:                                  [300](1, 7, 71)     ' '
    numeric_literal_RawSegment:                             [301](1, 7, 72)     '27.80'
    comma_RawSegment:                                       [306](1, 7, 77)     ','
    whitespace_RawSegment:                                  [307](1, 7, 78)     ' '
    numeric_literal_RawSegment:                             [308](1, 7, 79)     '27.05'
    comma_RawSegment:                                       [313](1, 7, 84)     ','
    whitespace_RawSegment:                                  [314](1, 7, 85)     ' '
    numeric_literal_RawSegment:                             [315](1, 7, 86)     '20.00'
    comma_RawSegment:                                       [320](1, 7, 91)     ','
    whitespace_RawSegment:                                  [321](1, 7, 92)     ' '
    numeric_literal_RawSegment:                             [322](1, 7, 93)     '17.87'
    comma_RawSegment:                                       [327](1, 7, 98)     ','
    whitespace_RawSegment:                                  [328](1, 7, 99)     ' '
    numeric_literal_RawSegment:                             [329](1, 7, 100)    '17.56'
    comma_RawSegment:                                       [334](1, 7, 105)    ','
    whitespace_RawSegment:                                  [335](1, 7, 106)    ' '
    numeric_literal_RawSegment:                             [336](1, 7, 107)    '17.41'
    comma_RawSegment:                                       [341](1, 7, 112)    ','
    whitespace_RawSegment:                                  [342](1, 7, 113)    ' '
    numeric_literal_RawSegment:                             [343](1, 7, 114)    '17.26'
    comma_RawSegment:                                       [348](1, 7, 119)    ','
    whitespace_RawSegment:                                  [349](1, 7, 120)    ' '
    numeric_literal_RawSegment:                             [350](1, 7, 121)    '17.11'
    comma_RawSegment:                                       [355](1, 7, 126)    ','
    whitespace_RawSegment:                                  [356](1, 7, 127)    ' '
    numeric_literal_RawSegment:                             [357](1, 7, 128)    '16.96'
    comma_RawSegment:                                       [362](1, 7, 133)    ','
    whitespace_RawSegment:                                  [363](1, 7, 134)    ' '
    numeric_literal_RawSegment:                             [364](1, 7, 135)    '16.82'
    comma_RawSegment:                                       [369](1, 7, 140)    ','
    whitespace_RawSegment:                                  [370](1, 7, 141)    ' '
    numeric_literal_RawSegment:                             [371](1, 7, 142)    '16.68'
    bracket_close_RawSegment:                               [376](1, 7, 147)    ')'
    comma_RawSegment:                                       [377](1, 7, 148)    ','
    newline_RawSegment:                                     [378](1, 7, 149)    '\n'
    whitespace_RawSegment:                                  [379](1, 8, 1)      '    '
    code_RawSegment:                                        [383](1, 8, 5)      'TIMESTAMP_FIELD'
    whitespace_RawSegment:                                  [398](1, 8, 20)     ' '
    code_RawSegment:                                        [399](1, 8, 21)     'TIMESTAMP'
    bracket_open_RawSegment:                                [408](1, 8, 30)     '('
    numeric_literal_RawSegment:                             [409](1, 8, 31)     '6'
    bracket_close_RawSegment:                               [410](1, 8, 32)     ')'
    whitespace_RawSegment:                                  [411](1, 8, 33)     ' '
    code_RawSegment:                                        [412](1, 8, 34)     'NOT'
    whitespace_RawSegment:                                  [415](1, 8, 37)     ' '
    code_RawSegment:                                        [416](1, 8, 38)     'NULL'
    newline_RawSegment:                                     [420](1, 8, 42)     '\n'
    bracket_close_RawSegment:                               [421](1, 9, 1)      ')'
    newline_RawSegment:                                     [422](1, 9, 2)      '\n'
    code_RawSegment:                                        [423](1, 10, 1)     'PRIMARY'
    whitespace_RawSegment:                                  [430](1, 10, 8)     ' '
    code_RawSegment:                                        [431](1, 10, 9)     'INDEX'
    bracket_open_RawSegment:                                [436](1, 10, 14)    '('
    whitespace_RawSegment:                                  [437](1, 10, 15)    ' '
    code_RawSegment:                                        [438](1, 10, 16)    'CHAR_FIELD'
    comma_RawSegment:                                       [448](1, 10, 26)    ','
    whitespace_RawSegment:                                  [449](1, 10, 27)    ' '
    code_RawSegment:                                        [450](1, 10, 28)    'DATE_FIELD'
    comma_RawSegment:                                       [460](1, 10, 38)    ','
    whitespace_RawSegment:                                  [461](1, 10, 39)    ' '
    code_RawSegment:                                        [462](1, 10, 40)    'BYTE_FIELD'
    whitespace_RawSegment:                                  [472](1, 10, 50)    ' '
    bracket_close_RawSegment:                               [473](1, 10, 51)    ')'
    semicolon_RawSegment:                                   [474](1, 10, 52)    ';'

________ test__dialect__base_file_parse[teradata-create_table_stmt.sql] ________

dialect = 'teradata', file = 'create_table_stmt.sql'

    @pytest.mark.parametrize(
        "dialect,file",
        parse_success_examples
    )
    def test__dialect__base_file_parse(dialect, file):
        """For given test examples, check successful parsing."""
        raw = load_file(dialect, file)
        # Load the right dialect
        config = FluffConfig(overrides=dict(dialect=dialect))
        context = ParseContext.from_config(config)
        fs, lex_vs = FileSegment.from_raw(raw, config=config)
        # From just the initial parse, check we're all there
        assert fs.raw == raw
        # Check we don't have lexing issues
        assert not lex_vs
    
        # Do the parse WITHOUT lots of logging
        # The logs get too long here to be useful. We should use
        # specfic segment tests if we want to debug logs.
        # with caplog.at_level(logging.DEBUG):
        print("Pre-parse structure: {0}".format(fs.to_tuple(show_raw=True)))
        print("Pre-parse structure: {0}".format(fs.stringify()))
>       parsed = fs.parse(parse_context=context)  # Optional: set recurse=1 to limit recursion

test/dialects_test.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/sqlfluff/parser/segments_base.py:456: in parse
    incr='parse_depth', match_depth=0, recurse=True
src/sqlfluff/parser/segments_base.py:688: in expand
    res = stmt.parse(parse_context=parse_context)
src/sqlfluff/parser/segments_base.py:409: in parse
    match_segment=self.__class__.__name__
src/sqlfluff/parser/grammar.py:81: in _match
    m = self.match(segments, parse_context=parse_context)
src/sqlfluff/parser/grammar.py:656: in match
    parse_context=parse_context.copy(incr='match_depth')
src/sqlfluff/parser/grammar.py:81: in _match
    m = self.match(segments, parse_context=parse_context)
src/sqlfluff/parser/grammar.py:580: in match
    parse_context=parse_context.copy(match_segment=self._get_ref()))
src/sqlfluff/parser/segments_base.py:651: in _match
    m = cls.match(segments, parse_context=parse_context)
src/sqlfluff/parser/segments_base.py:614: in match
    m = cls._match_grammar()._match(segments=segments, parse_context=parse_context.copy(incr='match_depth'))
src/sqlfluff/parser/grammar.py:81: in _match
    m = self.match(segments, parse_context=parse_context)
src/sqlfluff/parser/grammar.py:971: in match
    code_only=False)
src/sqlfluff/parser/grammar.py:467: in _bracket_sensitive_look_ahead_match
    code_only=code_only)
src/sqlfluff/parser/grammar.py:275: in _look_ahead_match
    simple_matchers = [m for m in matchers if m.simple(parse_context=parse_context)]
src/sqlfluff/parser/grammar.py:275: in <listcomp>
    simple_matchers = [m for m in matchers if m.simple(parse_context=parse_context)]
src/sqlfluff/parser/grammar.py:524: in simple
    ).simple(parse_context=parse_context)
src/sqlfluff/parser/segments_base.py:232: in simple
    return match_grammar.simple(parse_context=parse_context)
src/sqlfluff/parser/grammar.py:638: in simple
    simple = opt.simple(parse_context=parse_context)
src/sqlfluff/parser/grammar.py:523: in simple
    dialect=parse_context.dialect
src/sqlfluff/parser/grammar.py:542: in _get_elem
    return dialect.ref(self._get_ref())
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Dialect: teradata>, name = 'IntersectKeywordSegment'

    def ref(self, name):
        """Return an object which acts as a late binding reference to the element named.
    
        NB: This requires the dialect to be expanded.
    
        """
        if not self.expanded:
            raise RuntimeError("Dialect must be expanded before use.")
    
        if name in self._library:
            res = self._library[name]
            if res:
                return res
            else:
                raise ValueError(
                    "Unexpected Null response while fetching {0!r} from {1}".format(
                        name, self.name))
        else:
            raise RuntimeError(
                "Grammar refers to {0!r} which was not found in the {1} dialect".format(
>                   name, self.name))
E           RuntimeError: Grammar refers to 'IntersectKeywordSegment' which was not found in the teradata dialect

src/sqlfluff/dialects/base.py:219: RuntimeError
----------------------------- Captured stdout call -----------------------------
Pre-parse structure: ('file', (('comment', '-- Testing of the specific create table begin options'), ('newline', '\n'), ('raw', 'CREATE'), ('whitespace', ' '), ('raw', 'MULTISET'), ('whitespace', ' '), ('raw', 'TABLE'), ('whitespace', ' '), ('raw', 'CONSUMOS'), ('comma', ','), ('whitespace', ' '), ('raw', 'NO'), ('whitespace', ' '), ('raw', 'FALLBACK'), ('comma', ','), ('whitespace', ' '), ('raw', 'NO'), ('whitespace', ' '), ('raw', 'BEFORE'), ('whitespace', ' '), ('raw', 'JOURNAL'), ('comma', ','), ('whitespace', ' '), ('raw', 'NO'), ('whitespace', ' '), ('raw', 'AFTER'), ('whitespace', ' '), ('raw', 'JOURNAL'), ('comma', ','), ('newline', '\n'), ('whitespace', '     '), ('raw', 'CHECKSUM'), ('whitespace', ' '), ('raw', '='), ('whitespace', ' '), ('raw', 'DEFAULT'), ('comma', ','), ('whitespace', ' '), ('raw', 'DEFAULT'), ('whitespace', ' '), ('raw', 'MERGEBLOCKRATIO'), ('newline', '\n'), ('raw', '('), ('newline', '\n'), ('whitespace', '    '), ('raw', 'FIELD1'), ('whitespace', ' '), ('raw', 'CHAR'), ('raw', '('), ('raw', '9'), ('raw', ')'), ('newline', '\n'), ('raw', ')'), ('newline', '\n'), ('raw', 'PRIMARY'), ('whitespace', ' '), ('raw', 'INDEX'), ('raw', '('), ('whitespace', ' '), ('raw', 'FIELD1'), ('whitespace', ' '), ('raw', ')'), ('raw', ';'), ('newline', '\n')))
Pre-parse structure: FileSegment:                                                [0](1, 1, 1)
    inline_comment_RawSegment:                              [0](1, 1, 1)        '-- Testing of the specific create table begin options'
    newline_RawSegment:                                     [53](1, 1, 54)      '\n'
    code_RawSegment:                                        [54](1, 2, 1)       'CREATE'
    whitespace_RawSegment:                                  [60](1, 2, 7)       ' '
    code_RawSegment:                                        [61](1, 2, 8)       'MULTISET'
    whitespace_RawSegment:                                  [69](1, 2, 16)      ' '
    code_RawSegment:                                        [70](1, 2, 17)      'TABLE'
    whitespace_RawSegment:                                  [75](1, 2, 22)      ' '
    code_RawSegment:                                        [76](1, 2, 23)      'CONSUMOS'
    comma_RawSegment:                                       [84](1, 2, 31)      ','
    whitespace_RawSegment:                                  [85](1, 2, 32)      ' '
    code_RawSegment:                                        [86](1, 2, 33)      'NO'
    whitespace_RawSegment:                                  [88](1, 2, 35)      ' '
    code_RawSegment:                                        [89](1, 2, 36)      'FALLBACK'
    comma_RawSegment:                                       [97](1, 2, 44)      ','
    whitespace_RawSegment:                                  [98](1, 2, 45)      ' '
    code_RawSegment:                                        [99](1, 2, 46)      'NO'
    whitespace_RawSegment:                                  [101](1, 2, 48)     ' '
    code_RawSegment:                                        [102](1, 2, 49)     'BEFORE'
    whitespace_RawSegment:                                  [108](1, 2, 55)     ' '
    code_RawSegment:                                        [109](1, 2, 56)     'JOURNAL'
    comma_RawSegment:                                       [116](1, 2, 63)     ','
    whitespace_RawSegment:                                  [117](1, 2, 64)     ' '
    code_RawSegment:                                        [118](1, 2, 65)     'NO'
    whitespace_RawSegment:                                  [120](1, 2, 67)     ' '
    code_RawSegment:                                        [121](1, 2, 68)     'AFTER'
    whitespace_RawSegment:                                  [126](1, 2, 73)     ' '
    code_RawSegment:                                        [127](1, 2, 74)     'JOURNAL'
    comma_RawSegment:                                       [134](1, 2, 81)     ','
    newline_RawSegment:                                     [135](1, 2, 82)     '\n'
    whitespace_RawSegment:                                  [136](1, 3, 1)      '     '
    code_RawSegment:                                        [141](1, 3, 6)      'CHECKSUM'
    whitespace_RawSegment:                                  [149](1, 3, 14)     ' '
    equals_RawSegment:                                      [150](1, 3, 15)     '='
    whitespace_RawSegment:                                  [151](1, 3, 16)     ' '
    code_RawSegment:                                        [152](1, 3, 17)     'DEFAULT'
    comma_RawSegment:                                       [159](1, 3, 24)     ','
    whitespace_RawSegment:                                  [160](1, 3, 25)     ' '
    code_RawSegment:                                        [161](1, 3, 26)     'DEFAULT'
    whitespace_RawSegment:                                  [168](1, 3, 33)     ' '
    code_RawSegment:                                        [169](1, 3, 34)     'MERGEBLOCKRATIO'
    newline_RawSegment:                                     [184](1, 3, 49)     '\n'
    bracket_open_RawSegment:                                [185](1, 4, 1)      '('
    newline_RawSegment:                                     [186](1, 4, 2)      '\n'
    whitespace_RawSegment:                                  [187](1, 5, 1)      '    '
    code_RawSegment:                                        [191](1, 5, 5)      'FIELD1'
    whitespace_RawSegment:                                  [197](1, 5, 11)     ' '
    code_RawSegment:                                        [198](1, 5, 12)     'CHAR'
    bracket_open_RawSegment:                                [202](1, 5, 16)     '('
    numeric_literal_RawSegment:                             [203](1, 5, 17)     '9'
    bracket_close_RawSegment:                               [204](1, 5, 18)     ')'
    newline_RawSegment:                                     [205](1, 5, 19)     '\n'
    bracket_close_RawSegment:                               [206](1, 6, 1)      ')'
    newline_RawSegment:                                     [207](1, 6, 2)      '\n'
    code_RawSegment:                                        [208](1, 7, 1)      'PRIMARY'
    whitespace_RawSegment:                                  [215](1, 7, 8)      ' '
    code_RawSegment:                                        [216](1, 7, 9)      'INDEX'
    bracket_open_RawSegment:                                [221](1, 7, 14)     '('
    whitespace_RawSegment:                                  [222](1, 7, 15)     ' '
    code_RawSegment:                                        [223](1, 7, 16)     'FIELD1'
    whitespace_RawSegment:                                  [229](1, 7, 22)     ' '
    bracket_close_RawSegment:                               [230](1, 7, 23)     ')'
    semicolon_RawSegment:                                   [231](1, 7, 24)     ';'
    newline_RawSegment:                                     [232](1, 7, 25)     '\n'

____________ test__dialect__base_file_parse[teradata-bteq_stmt.sql] ____________

dialect = 'teradata', file = 'bteq_stmt.sql'

    @pytest.mark.parametrize(
        "dialect,file",
        parse_success_examples
    )
    def test__dialect__base_file_parse(dialect, file):
        """For given test examples, check successful parsing."""
        raw = load_file(dialect, file)
        # Load the right dialect
        config = FluffConfig(overrides=dict(dialect=dialect))
        context = ParseContext.from_config(config)
        fs, lex_vs = FileSegment.from_raw(raw, config=config)
        # From just the initial parse, check we're all there
        assert fs.raw == raw
        # Check we don't have lexing issues
        assert not lex_vs
    
        # Do the parse WITHOUT lots of logging
        # The logs get too long here to be useful. We should use
        # specfic segment tests if we want to debug logs.
        # with caplog.at_level(logging.DEBUG):
        print("Pre-parse structure: {0}".format(fs.to_tuple(show_raw=True)))
        print("Pre-parse structure: {0}".format(fs.stringify()))
>       parsed = fs.parse(parse_context=context)  # Optional: set recurse=1 to limit recursion

test/dialects_test.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/sqlfluff/parser/segments_base.py:456: in parse
    incr='parse_depth', match_depth=0, recurse=True
src/sqlfluff/parser/segments_base.py:688: in expand
    res = stmt.parse(parse_context=parse_context)
src/sqlfluff/parser/segments_base.py:409: in parse
    match_segment=self.__class__.__name__
src/sqlfluff/parser/grammar.py:81: in _match
    m = self.match(segments, parse_context=parse_context)
src/sqlfluff/parser/grammar.py:656: in match
    parse_context=parse_context.copy(incr='match_depth')
src/sqlfluff/parser/grammar.py:81: in _match
    m = self.match(segments, parse_context=parse_context)
src/sqlfluff/parser/grammar.py:580: in match
    parse_context=parse_context.copy(match_segment=self._get_ref()))
src/sqlfluff/parser/segments_base.py:651: in _match
    m = cls.match(segments, parse_context=parse_context)
src/sqlfluff/parser/segments_base.py:614: in match
    m = cls._match_grammar()._match(segments=segments, parse_context=parse_context.copy(incr='match_depth'))
src/sqlfluff/parser/grammar.py:81: in _match
    m = self.match(segments, parse_context=parse_context)
src/sqlfluff/parser/grammar.py:971: in match
    code_only=False)
src/sqlfluff/parser/grammar.py:467: in _bracket_sensitive_look_ahead_match
    code_only=code_only)
src/sqlfluff/parser/grammar.py:275: in _look_ahead_match
    simple_matchers = [m for m in matchers if m.simple(parse_context=parse_context)]
src/sqlfluff/parser/grammar.py:275: in <listcomp>
    simple_matchers = [m for m in matchers if m.simple(parse_context=parse_context)]
src/sqlfluff/parser/grammar.py:524: in simple
    ).simple(parse_context=parse_context)
src/sqlfluff/parser/segments_base.py:232: in simple
    return match_grammar.simple(parse_context=parse_context)
src/sqlfluff/parser/grammar.py:638: in simple
    simple = opt.simple(parse_context=parse_context)
src/sqlfluff/parser/grammar.py:523: in simple
    dialect=parse_context.dialect
src/sqlfluff/parser/grammar.py:542: in _get_elem
    return dialect.ref(self._get_ref())
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Dialect: teradata>, name = 'IntersectKeywordSegment'

    def ref(self, name):
        """Return an object which acts as a late binding reference to the element named.
    
        NB: This requires the dialect to be expanded.
    
        """
        if not self.expanded:
            raise RuntimeError("Dialect must be expanded before use.")
    
        if name in self._library:
            res = self._library[name]
            if res:
                return res
            else:
                raise ValueError(
                    "Unexpected Null response while fetching {0!r} from {1}".format(
                        name, self.name))
        else:
            raise RuntimeError(
                "Grammar refers to {0!r} which was not found in the {1} dialect".format(
>                   name, self.name))
E           RuntimeError: Grammar refers to 'IntersectKeywordSegment' which was not found in the teradata dialect

src/sqlfluff/dialects/base.py:219: RuntimeError
----------------------------- Captured stdout call -----------------------------
Pre-parse structure: ('file', (('raw', '.'), ('raw', 'if'), ('whitespace', ' '), ('raw', 'errorcode'), ('whitespace', ' '), ('raw', '>'), ('whitespace', ' '), ('raw', '0'), ('whitespace', ' '), ('raw', 'then'), ('whitespace', ' '), ('raw', '.'), ('raw', 'quit'), ('whitespace', ' '), ('raw', '4'), ('raw', ';'), ('newline', '\n')))
Pre-parse structure: FileSegment:                                                [0](1, 1, 1)
    dot_RawSegment:                                         [0](1, 1, 1)        '.'
    code_RawSegment:                                        [1](1, 1, 2)        'if'
    whitespace_RawSegment:                                  [3](1, 1, 4)        ' '
    code_RawSegment:                                        [4](1, 1, 5)        'errorcode'
    whitespace_RawSegment:                                  [13](1, 1, 14)      ' '
    greater_than_RawSegment:                                [14](1, 1, 15)      '>'
    whitespace_RawSegment:                                  [15](1, 1, 16)      ' '
    numeric_literal_RawSegment:                             [16](1, 1, 17)      '0'
    whitespace_RawSegment:                                  [17](1, 1, 18)      ' '
    code_RawSegment:                                        [18](1, 1, 19)      'then'
    whitespace_RawSegment:                                  [22](1, 1, 23)      ' '
    dot_RawSegment:                                         [23](1, 1, 24)      '.'
    code_RawSegment:                                        [24](1, 1, 25)      'quit'
    whitespace_RawSegment:                                  [28](1, 1, 29)      ' '
    numeric_literal_RawSegment:                             [29](1, 1, 30)      '4'
    semicolon_RawSegment:                                   [30](1, 1, 31)      ';'
    newline_RawSegment:                                     [31](1, 1, 32)      '\n'

__________ test__dialect__base_file_parse[teradata-collect_stats.sql] __________

dialect = 'teradata', file = 'collect_stats.sql'

    @pytest.mark.parametrize(
        "dialect,file",
        parse_success_examples
    )
    def test__dialect__base_file_parse(dialect, file):
        """For given test examples, check successful parsing."""
        raw = load_file(dialect, file)
        # Load the right dialect
        config = FluffConfig(overrides=dict(dialect=dialect))
        context = ParseContext.from_config(config)
        fs, lex_vs = FileSegment.from_raw(raw, config=config)
        # From just the initial parse, check we're all there
        assert fs.raw == raw
        # Check we don't have lexing issues
        assert not lex_vs
    
        # Do the parse WITHOUT lots of logging
        # The logs get too long here to be useful. We should use
        # specfic segment tests if we want to debug logs.
        # with caplog.at_level(logging.DEBUG):
        print("Pre-parse structure: {0}".format(fs.to_tuple(show_raw=True)))
        print("Pre-parse structure: {0}".format(fs.stringify()))
>       parsed = fs.parse(parse_context=context)  # Optional: set recurse=1 to limit recursion

test/dialects_test.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/sqlfluff/parser/segments_base.py:456: in parse
    incr='parse_depth', match_depth=0, recurse=True
src/sqlfluff/parser/segments_base.py:688: in expand
    res = stmt.parse(parse_context=parse_context)
src/sqlfluff/parser/segments_base.py:409: in parse
    match_segment=self.__class__.__name__
src/sqlfluff/parser/grammar.py:81: in _match
    m = self.match(segments, parse_context=parse_context)
src/sqlfluff/parser/grammar.py:656: in match
    parse_context=parse_context.copy(incr='match_depth')
src/sqlfluff/parser/grammar.py:81: in _match
    m = self.match(segments, parse_context=parse_context)
src/sqlfluff/parser/grammar.py:580: in match
    parse_context=parse_context.copy(match_segment=self._get_ref()))
src/sqlfluff/parser/segments_base.py:651: in _match
    m = cls.match(segments, parse_context=parse_context)
src/sqlfluff/parser/segments_base.py:614: in match
    m = cls._match_grammar()._match(segments=segments, parse_context=parse_context.copy(incr='match_depth'))
src/sqlfluff/parser/grammar.py:81: in _match
    m = self.match(segments, parse_context=parse_context)
src/sqlfluff/parser/grammar.py:971: in match
    code_only=False)
src/sqlfluff/parser/grammar.py:467: in _bracket_sensitive_look_ahead_match
    code_only=code_only)
src/sqlfluff/parser/grammar.py:275: in _look_ahead_match
    simple_matchers = [m for m in matchers if m.simple(parse_context=parse_context)]
src/sqlfluff/parser/grammar.py:275: in <listcomp>
    simple_matchers = [m for m in matchers if m.simple(parse_context=parse_context)]
src/sqlfluff/parser/grammar.py:524: in simple
    ).simple(parse_context=parse_context)
src/sqlfluff/parser/segments_base.py:232: in simple
    return match_grammar.simple(parse_context=parse_context)
src/sqlfluff/parser/grammar.py:638: in simple
    simple = opt.simple(parse_context=parse_context)
src/sqlfluff/parser/grammar.py:523: in simple
    dialect=parse_context.dialect
src/sqlfluff/parser/grammar.py:542: in _get_elem
    return dialect.ref(self._get_ref())
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Dialect: teradata>, name = 'IntersectKeywordSegment'

    def ref(self, name):
        """Return an object which acts as a late binding reference to the element named.
    
        NB: This requires the dialect to be expanded.
    
        """
        if not self.expanded:
            raise RuntimeError("Dialect must be expanded before use.")
    
        if name in self._library:
            res = self._library[name]
            if res:
                return res
            else:
                raise ValueError(
                    "Unexpected Null response while fetching {0!r} from {1}".format(
                        name, self.name))
        else:
            raise RuntimeError(
                "Grammar refers to {0!r} which was not found in the {1} dialect".format(
>                   name, self.name))
E           RuntimeError: Grammar refers to 'IntersectKeywordSegment' which was not found in the teradata dialect

src/sqlfluff/dialects/base.py:219: RuntimeError
----------------------------- Captured stdout call -----------------------------
Pre-parse structure: ('file', (('raw', 'COLLECT'), ('whitespace', ' '), ('raw', 'STATISTICS'), ('whitespace', ' '), ('raw', 'COLUMN'), ('whitespace', ' '), ('raw', '('), ('whitespace', ' '), ('raw', 'IND_TIPO_TARJETA'), ('whitespace', ' '), ('raw', ')'), ('whitespace', ' '), ('raw', 'ON'), ('whitespace', ' '), ('raw', 'DB_1'), ('raw', '.'), ('raw', 'TABLE_1'), ('raw', ';'), ('newline', '\n'), ('newline', '\n'), ('raw', 'COLLECT'), ('whitespace', ' '), ('raw', 'STATISTICS'), ('whitespace', ' '), ('raw', 'INDEX'), ('whitespace', ' '), ('raw', '('), ('whitespace', ' '), ('raw', 'COD_TARJETA'), ('comma', ','), ('whitespace', ' '), ('raw', 'COD_EST'), ('comma', ','), ('whitespace', ' '), ('raw', 'IND_TIPO_TARJETA'), ('comma', ','), ('whitespace', ' '), ('raw', 'FEC_ANIO_MES'), ('whitespace', ' '), ('raw', ')'), ('whitespace', ' '), ('raw', 'ON'), ('whitespace', ' '), ('raw', 'DB_1'), ('raw', '.'), ('raw', 'TABLE_1'), ('raw', ';'), ('newline', '\n')))
Pre-parse structure: FileSegment:                                                [0](1, 1, 1)
    code_RawSegment:                                        [0](1, 1, 1)        'COLLECT'
    whitespace_RawSegment:                                  [7](1, 1, 8)        ' '
    code_RawSegment:                                        [8](1, 1, 9)        'STATISTICS'
    whitespace_RawSegment:                                  [18](1, 1, 19)      ' '
    code_RawSegment:                                        [19](1, 1, 20)      'COLUMN'
    whitespace_RawSegment:                                  [25](1, 1, 26)      ' '
    bracket_open_RawSegment:                                [26](1, 1, 27)      '('
    whitespace_RawSegment:                                  [27](1, 1, 28)      ' '
    code_RawSegment:                                        [28](1, 1, 29)      'IND_TIPO_TARJETA'
    whitespace_RawSegment:                                  [44](1, 1, 45)      ' '
    bracket_close_RawSegment:                               [45](1, 1, 46)      ')'
    whitespace_RawSegment:                                  [46](1, 1, 47)      ' '
    code_RawSegment:                                        [47](1, 1, 48)      'ON'
    whitespace_RawSegment:                                  [49](1, 1, 50)      ' '
    code_RawSegment:                                        [50](1, 1, 51)      'DB_1'
    dot_RawSegment:                                         [54](1, 1, 55)      '.'
    code_RawSegment:                                        [55](1, 1, 56)      'TABLE_1'
    semicolon_RawSegment:                                   [62](1, 1, 63)      ';'
    newline_RawSegment:                                     [63](1, 1, 64)      '\n'
    newline_RawSegment:                                     [64](1, 2, 1)       '\n'
    code_RawSegment:                                        [65](1, 3, 1)       'COLLECT'
    whitespace_RawSegment:                                  [72](1, 3, 8)       ' '
    code_RawSegment:                                        [73](1, 3, 9)       'STATISTICS'
    whitespace_RawSegment:                                  [83](1, 3, 19)      ' '
    code_RawSegment:                                        [84](1, 3, 20)      'INDEX'
    whitespace_RawSegment:                                  [89](1, 3, 25)      ' '
    bracket_open_RawSegment:                                [90](1, 3, 26)      '('
    whitespace_RawSegment:                                  [91](1, 3, 27)      ' '
    code_RawSegment:                                        [92](1, 3, 28)      'COD_TARJETA'
    comma_RawSegment:                                       [103](1, 3, 39)     ','
    whitespace_RawSegment:                                  [104](1, 3, 40)     ' '
    code_RawSegment:                                        [105](1, 3, 41)     'COD_EST'
    comma_RawSegment:                                       [112](1, 3, 48)     ','
    whitespace_RawSegment:                                  [113](1, 3, 49)     ' '
    code_RawSegment:                                        [114](1, 3, 50)     'IND_TIPO_TARJETA'
    comma_RawSegment:                                       [130](1, 3, 66)     ','
    whitespace_RawSegment:                                  [131](1, 3, 67)     ' '
    code_RawSegment:                                        [132](1, 3, 68)     'FEC_ANIO_MES'
    whitespace_RawSegment:                                  [144](1, 3, 80)     ' '
    bracket_close_RawSegment:                               [145](1, 3, 81)     ')'
    whitespace_RawSegment:                                  [146](1, 3, 82)     ' '
    code_RawSegment:                                        [147](1, 3, 83)     'ON'
    whitespace_RawSegment:                                  [149](1, 3, 85)     ' '
    code_RawSegment:                                        [150](1, 3, 86)     'DB_1'
    dot_RawSegment:                                         [154](1, 3, 90)     '.'
    code_RawSegment:                                        [155](1, 3, 91)     'TABLE_1'
    semicolon_RawSegment:                                   [162](1, 3, 98)     ';'
    newline_RawSegment:                                     [163](1, 3, 99)     '\n'

___________ test__dialect__base_file_parse[teradata-update_from.sql] ___________

dialect = 'teradata', file = 'update_from.sql'

    @pytest.mark.parametrize(
        "dialect,file",
        parse_success_examples
    )
    def test__dialect__base_file_parse(dialect, file):
        """For given test examples, check successful parsing."""
        raw = load_file(dialect, file)
        # Load the right dialect
        config = FluffConfig(overrides=dict(dialect=dialect))
        context = ParseContext.from_config(config)
        fs, lex_vs = FileSegment.from_raw(raw, config=config)
        # From just the initial parse, check we're all there
        assert fs.raw == raw
        # Check we don't have lexing issues
        assert not lex_vs
    
        # Do the parse WITHOUT lots of logging
        # The logs get too long here to be useful. We should use
        # specfic segment tests if we want to debug logs.
        # with caplog.at_level(logging.DEBUG):
        print("Pre-parse structure: {0}".format(fs.to_tuple(show_raw=True)))
        print("Pre-parse structure: {0}".format(fs.stringify()))
>       parsed = fs.parse(parse_context=context)  # Optional: set recurse=1 to limit recursion

test/dialects_test.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/sqlfluff/parser/segments_base.py:456: in parse
    incr='parse_depth', match_depth=0, recurse=True
src/sqlfluff/parser/segments_base.py:688: in expand
    res = stmt.parse(parse_context=parse_context)
src/sqlfluff/parser/segments_base.py:409: in parse
    match_segment=self.__class__.__name__
src/sqlfluff/parser/grammar.py:81: in _match
    m = self.match(segments, parse_context=parse_context)
src/sqlfluff/parser/grammar.py:656: in match
    parse_context=parse_context.copy(incr='match_depth')
src/sqlfluff/parser/grammar.py:81: in _match
    m = self.match(segments, parse_context=parse_context)
src/sqlfluff/parser/grammar.py:580: in match
    parse_context=parse_context.copy(match_segment=self._get_ref()))
src/sqlfluff/parser/segments_base.py:651: in _match
    m = cls.match(segments, parse_context=parse_context)
src/sqlfluff/parser/segments_base.py:614: in match
    m = cls._match_grammar()._match(segments=segments, parse_context=parse_context.copy(incr='match_depth'))
src/sqlfluff/parser/grammar.py:81: in _match
    m = self.match(segments, parse_context=parse_context)
src/sqlfluff/parser/grammar.py:971: in match
    code_only=False)
src/sqlfluff/parser/grammar.py:467: in _bracket_sensitive_look_ahead_match
    code_only=code_only)
src/sqlfluff/parser/grammar.py:275: in _look_ahead_match
    simple_matchers = [m for m in matchers if m.simple(parse_context=parse_context)]
src/sqlfluff/parser/grammar.py:275: in <listcomp>
    simple_matchers = [m for m in matchers if m.simple(parse_context=parse_context)]
src/sqlfluff/parser/grammar.py:524: in simple
    ).simple(parse_context=parse_context)
src/sqlfluff/parser/segments_base.py:232: in simple
    return match_grammar.simple(parse_context=parse_context)
src/sqlfluff/parser/grammar.py:638: in simple
    simple = opt.simple(parse_context=parse_context)
src/sqlfluff/parser/grammar.py:523: in simple
    dialect=parse_context.dialect
src/sqlfluff/parser/grammar.py:542: in _get_elem
    return dialect.ref(self._get_ref())
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Dialect: teradata>, name = 'IntersectKeywordSegment'

    def ref(self, name):
        """Return an object which acts as a late binding reference to the element named.
    
        NB: This requires the dialect to be expanded.
    
        """
        if not self.expanded:
            raise RuntimeError("Dialect must be expanded before use.")
    
        if name in self._library:
            res = self._library[name]
            if res:
                return res
            else:
                raise ValueError(
                    "Unexpected Null response while fetching {0!r} from {1}".format(
                        name, self.name))
        else:
            raise RuntimeError(
                "Grammar refers to {0!r} which was not found in the {1} dialect".format(
>                   name, self.name))
E           RuntimeError: Grammar refers to 'IntersectKeywordSegment' which was not found in the teradata dialect

src/sqlfluff/dialects/base.py:219: RuntimeError
----------------------------- Captured stdout call -----------------------------
Pre-parse structure: ('file', (('raw', 'UPDATE'), ('whitespace', ' '), ('raw', 'table_name'), ('newline', '\n'), ('raw', 'FROM'), ('newline', '\n'), ('raw', '('), ('newline', '\n'), ('whitespace', '    '), ('raw', 'SELECT'), ('newline', '\n'), ('whitespace', '       '), ('raw', 'a'), ('comma', ','), ('whitespace', ' '), ('raw', 'b'), ('comma', ','), ('whitespace', ' '), ('raw', 'c'), ('comma', ','), ('whitespace', ' '), ('raw', 'd'), ('newline', '\n'), ('whitespace', '    '), ('raw', 'FROM'), ('newline', '\n'), ('whitespace', '        '), ('raw', 't_b'), ('whitespace', ' '), ('raw', 'INNER'), ('whitespace', ' '), ('raw', 'JOIN'), ('whitespace', ' '), ('raw', 't_c'), ('newline', '\n'), ('whitespace', '        '), ('raw', 'ON'), ('whitespace', ' '), ('raw', 't_b'), ('raw', '.'), ('raw', 'd'), ('whitespace', ' '), ('raw', '='), ('whitespace', ' '), ('raw', 't_c'), ('raw', '.'), ('raw', 'd'), ('newline', '\n'), ('newline', '\n'), ('whitespace', '    '), ('raw', 'WHERE'), ('newline', '\n'), ('whitespace', '       '), ('raw', 'b'), ('whitespace', ' '), ('raw', '='), ('whitespace', ' '), ('raw', "'F'"), ('newline', '\n'), ('whitespace', '       '), ('comment', "-- AND SUBSTR(c, 1, 1) = 'T'"), ('newline', '\n'), ('newline', '\n'), ('raw', ')'), ('whitespace', ' '), ('raw', 'AS'), ('whitespace', ' '), ('raw', 't_d'), ('newline', '\n'), ('raw', 'SET'), ('newline', '\n'), ('whitespace', '    '), ('raw', 'column1'), ('whitespace', ' '), ('raw', '='), ('whitespace', ' '), ('raw', 'value1'), ('comma', ','), ('newline', '\n'), ('whitespace', '    '), ('raw', 'column2'), ('whitespace', ' '), ('raw', '='), ('whitespace', ' '), ('raw', "'value2'"), ('newline', '\n'), ('raw', 'WHERE'), ('whitespace', ' '), ('raw', 'a'), ('raw', '='), ('raw', '1'), ('raw', ';'), ('newline', '\n'), ('newline', '\n')))
Pre-parse structure: FileSegment:                                                [0](1, 1, 1)
    code_RawSegment:                                        [0](1, 1, 1)        'UPDATE'
    whitespace_RawSegment:                                  [6](1, 1, 7)        ' '
    code_RawSegment:                                        [7](1, 1, 8)        'table_name'
    newline_RawSegment:                                     [17](1, 1, 18)      '\n'
    code_RawSegment:                                        [18](1, 2, 1)       'FROM'
    newline_RawSegment:                                     [22](1, 2, 5)       '\n'
    bracket_open_RawSegment:                                [23](1, 3, 1)       '('
    newline_RawSegment:                                     [24](1, 3, 2)       '\n'
    whitespace_RawSegment:                                  [25](1, 4, 1)       '    '
    code_RawSegment:                                        [29](1, 4, 5)       'SELECT'
    newline_RawSegment:                                     [35](1, 4, 11)      '\n'
    whitespace_RawSegment:                                  [36](1, 5, 1)       '       '
    code_RawSegment:                                        [43](1, 5, 8)       'a'
    comma_RawSegment:                                       [44](1, 5, 9)       ','
    whitespace_RawSegment:                                  [45](1, 5, 10)      ' '
    code_RawSegment:                                        [46](1, 5, 11)      'b'
    comma_RawSegment:                                       [47](1, 5, 12)      ','
    whitespace_RawSegment:                                  [48](1, 5, 13)      ' '
    code_RawSegment:                                        [49](1, 5, 14)      'c'
    comma_RawSegment:                                       [50](1, 5, 15)      ','
    whitespace_RawSegment:                                  [51](1, 5, 16)      ' '
    code_RawSegment:                                        [52](1, 5, 17)      'd'
    newline_RawSegment:                                     [53](1, 5, 18)      '\n'
    whitespace_RawSegment:                                  [54](1, 6, 1)       '    '
    code_RawSegment:                                        [58](1, 6, 5)       'FROM'
    newline_RawSegment:                                     [62](1, 6, 9)       '\n'
    whitespace_RawSegment:                                  [63](1, 7, 1)       '        '
    code_RawSegment:                                        [71](1, 7, 9)       't_b'
    whitespace_RawSegment:                                  [74](1, 7, 12)      ' '
    code_RawSegment:                                        [75](1, 7, 13)      'INNER'
    whitespace_RawSegment:                                  [80](1, 7, 18)      ' '
    code_RawSegment:                                        [81](1, 7, 19)      'JOIN'
    whitespace_RawSegment:                                  [85](1, 7, 23)      ' '
    code_RawSegment:                                        [86](1, 7, 24)      't_c'
    newline_RawSegment:                                     [89](1, 7, 27)      '\n'
    whitespace_RawSegment:                                  [90](1, 8, 1)       '        '
    code_RawSegment:                                        [98](1, 8, 9)       'ON'
    whitespace_RawSegment:                                  [100](1, 8, 11)     ' '
    code_RawSegment:                                        [101](1, 8, 12)     't_b'
    dot_RawSegment:                                         [104](1, 8, 15)     '.'
    code_RawSegment:                                        [105](1, 8, 16)     'd'
    whitespace_RawSegment:                                  [106](1, 8, 17)     ' '
    equals_RawSegment:                                      [107](1, 8, 18)     '='
    whitespace_RawSegment:                                  [108](1, 8, 19)     ' '
    code_RawSegment:                                        [109](1, 8, 20)     't_c'
    dot_RawSegment:                                         [112](1, 8, 23)     '.'
    code_RawSegment:                                        [113](1, 8, 24)     'd'
    newline_RawSegment:                                     [114](1, 8, 25)     '\n'
    newline_RawSegment:                                     [115](1, 9, 1)      '\n'
    whitespace_RawSegment:                                  [116](1, 10, 1)     '    '
    code_RawSegment:                                        [120](1, 10, 5)     'WHERE'
    newline_RawSegment:                                     [125](1, 10, 10)    '\n'
    whitespace_RawSegment:                                  [126](1, 11, 1)     '       '
    code_RawSegment:                                        [133](1, 11, 8)     'b'
    whitespace_RawSegment:                                  [134](1, 11, 9)     ' '
    equals_RawSegment:                                      [135](1, 11, 10)    '='
    whitespace_RawSegment:                                  [136](1, 11, 11)    ' '
    single_quote_RawSegment:                                [137](1, 11, 12)    "'F'"
    newline_RawSegment:                                     [140](1, 11, 15)    '\n'
    whitespace_RawSegment:                                  [141](1, 12, 1)     '       '
    inline_comment_RawSegment:                              [148](1, 12, 8)     "-- AND SUBSTR(c, 1, 1) = 'T'"
    newline_RawSegment:                                     [176](1, 12, 36)    '\n'
    newline_RawSegment:                                     [177](1, 13, 1)     '\n'
    bracket_close_RawSegment:                               [178](1, 14, 1)     ')'
    whitespace_RawSegment:                                  [179](1, 14, 2)     ' '
    code_RawSegment:                                        [180](1, 14, 3)     'AS'
    whitespace_RawSegment:                                  [182](1, 14, 5)     ' '
    code_RawSegment:                                        [183](1, 14, 6)     't_d'
    newline_RawSegment:                                     [186](1, 14, 9)     '\n'
    code_RawSegment:                                        [187](1, 15, 1)     'SET'
    newline_RawSegment:                                     [190](1, 15, 4)     '\n'
    whitespace_RawSegment:                                  [191](1, 16, 1)     '    '
    code_RawSegment:                                        [195](1, 16, 5)     'column1'
    whitespace_RawSegment:                                  [202](1, 16, 12)    ' '
    equals_RawSegment:                                      [203](1, 16, 13)    '='
    whitespace_RawSegment:                                  [204](1, 16, 14)    ' '
    code_RawSegment:                                        [205](1, 16, 15)    'value1'
    comma_RawSegment:                                       [211](1, 16, 21)    ','
    newline_RawSegment:                                     [212](1, 16, 22)    '\n'
    whitespace_RawSegment:                                  [213](1, 17, 1)     '    '
    code_RawSegment:                                        [217](1, 17, 5)     'column2'
    whitespace_RawSegment:                                  [224](1, 17, 12)    ' '
    equals_RawSegment:                                      [225](1, 17, 13)    '='
    whitespace_RawSegment:                                  [226](1, 17, 14)    ' '
    single_quote_RawSegment:                                [227](1, 17, 15)    "'value2'"
    newline_RawSegment:                                     [235](1, 17, 23)    '\n'
    code_RawSegment:                                        [236](1, 18, 1)     'WHERE'
    whitespace_RawSegment:                                  [241](1, 18, 6)     ' '
    code_RawSegment:                                        [242](1, 18, 7)     'a'
    equals_RawSegment:                                      [243](1, 18, 8)     '='
    numeric_literal_RawSegment:                             [244](1, 18, 9)     '1'
    semicolon_RawSegment:                                   [245](1, 18, 10)    ';'
    newline_RawSegment:                                     [246](1, 18, 11)    '\n'
    newline_RawSegment:                                     [247](1, 19, 1)     '\n'

________ test__dialect__base_file_parse[teradata-select_stmt_cast.sql] _________

dialect = 'teradata', file = 'select_stmt_cast.sql'

    @pytest.mark.parametrize(
        "dialect,file",
        parse_success_examples
    )
    def test__dialect__base_file_parse(dialect, file):
        """For given test examples, check successful parsing."""
        raw = load_file(dialect, file)
        # Load the right dialect
        config = FluffConfig(overrides=dict(dialect=dialect))
        context = ParseContext.from_config(config)
        fs, lex_vs = FileSegment.from_raw(raw, config=config)
        # From just the initial parse, check we're all there
        assert fs.raw == raw
        # Check we don't have lexing issues
        assert not lex_vs
    
        # Do the parse WITHOUT lots of logging
        # The logs get too long here to be useful. We should use
        # specfic segment tests if we want to debug logs.
        # with caplog.at_level(logging.DEBUG):
        print("Pre-parse structure: {0}".format(fs.to_tuple(show_raw=True)))
        print("Pre-parse structure: {0}".format(fs.stringify()))
>       parsed = fs.parse(parse_context=context)  # Optional: set recurse=1 to limit recursion

test/dialects_test.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/sqlfluff/parser/segments_base.py:456: in parse
    incr='parse_depth', match_depth=0, recurse=True
src/sqlfluff/parser/segments_base.py:688: in expand
    res = stmt.parse(parse_context=parse_context)
src/sqlfluff/parser/segments_base.py:409: in parse
    match_segment=self.__class__.__name__
src/sqlfluff/parser/grammar.py:81: in _match
    m = self.match(segments, parse_context=parse_context)
src/sqlfluff/parser/grammar.py:656: in match
    parse_context=parse_context.copy(incr='match_depth')
src/sqlfluff/parser/grammar.py:81: in _match
    m = self.match(segments, parse_context=parse_context)
src/sqlfluff/parser/grammar.py:580: in match
    parse_context=parse_context.copy(match_segment=self._get_ref()))
src/sqlfluff/parser/segments_base.py:651: in _match
    m = cls.match(segments, parse_context=parse_context)
src/sqlfluff/parser/segments_base.py:614: in match
    m = cls._match_grammar()._match(segments=segments, parse_context=parse_context.copy(incr='match_depth'))
src/sqlfluff/parser/grammar.py:81: in _match
    m = self.match(segments, parse_context=parse_context)
src/sqlfluff/parser/grammar.py:971: in match
    code_only=False)
src/sqlfluff/parser/grammar.py:467: in _bracket_sensitive_look_ahead_match
    code_only=code_only)
src/sqlfluff/parser/grammar.py:275: in _look_ahead_match
    simple_matchers = [m for m in matchers if m.simple(parse_context=parse_context)]
src/sqlfluff/parser/grammar.py:275: in <listcomp>
    simple_matchers = [m for m in matchers if m.simple(parse_context=parse_context)]
src/sqlfluff/parser/grammar.py:524: in simple
    ).simple(parse_context=parse_context)
src/sqlfluff/parser/segments_base.py:232: in simple
    return match_grammar.simple(parse_context=parse_context)
src/sqlfluff/parser/grammar.py:638: in simple
    simple = opt.simple(parse_context=parse_context)
src/sqlfluff/parser/grammar.py:523: in simple
    dialect=parse_context.dialect
src/sqlfluff/parser/grammar.py:542: in _get_elem
    return dialect.ref(self._get_ref())
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Dialect: teradata>, name = 'IntersectKeywordSegment'

    def ref(self, name):
        """Return an object which acts as a late binding reference to the element named.
    
        NB: This requires the dialect to be expanded.
    
        """
        if not self.expanded:
            raise RuntimeError("Dialect must be expanded before use.")
    
        if name in self._library:
            res = self._library[name]
            if res:
                return res
            else:
                raise ValueError(
                    "Unexpected Null response while fetching {0!r} from {1}".format(
                        name, self.name))
        else:
            raise RuntimeError(
                "Grammar refers to {0!r} which was not found in the {1} dialect".format(
>                   name, self.name))
E           RuntimeError: Grammar refers to 'IntersectKeywordSegment' which was not found in the teradata dialect

src/sqlfluff/dialects/base.py:219: RuntimeError
----------------------------- Captured stdout call -----------------------------
Pre-parse structure: ('file', (('raw', 'SELECT'), ('newline', '\n'), ('whitespace', '    '), ('raw', "'9999-12-31'"), ('whitespace', ' '), ('raw', '('), ('raw', 'DATE'), ('raw', ')'), ('comma', ','), ('newline', '\n'), ('whitespace', '    '), ('raw', "'9999-12-31'"), ('whitespace', ' '), ('raw', '('), ('raw', 'DATE'), ('whitespace', ' '), ('raw', 'FORMAT'), ('whitespace', ' '), ('raw', "'YYYY-MM-DD'"), ('raw', ')'), ('comma', ','), ('newline', '\n'), ('whitespace', '    '), ('raw', "'100000'"), ('whitespace', ' '), ('raw', '('), ('raw', 'SMALLINT'), ('raw', ')'), ('newline', '\n'), ('raw', 'from'), ('whitespace', ' '), ('raw', 'test_table'), ('raw', ';')))
Pre-parse structure: FileSegment:                                                [0](1, 1, 1)
    code_RawSegment:                                        [0](1, 1, 1)        'SELECT'
    newline_RawSegment:                                     [6](1, 1, 7)        '\n'
    whitespace_RawSegment:                                  [7](1, 2, 1)        '    '
    single_quote_RawSegment:                                [11](1, 2, 5)       "'9999-12-31'"
    whitespace_RawSegment:                                  [23](1, 2, 17)      ' '
    bracket_open_RawSegment:                                [24](1, 2, 18)      '('
    code_RawSegment:                                        [25](1, 2, 19)      'DATE'
    bracket_close_RawSegment:                               [29](1, 2, 23)      ')'
    comma_RawSegment:                                       [30](1, 2, 24)      ','
    newline_RawSegment:                                     [31](1, 2, 25)      '\n'
    whitespace_RawSegment:                                  [32](1, 3, 1)       '    '
    single_quote_RawSegment:                                [36](1, 3, 5)       "'9999-12-31'"
    whitespace_RawSegment:                                  [48](1, 3, 17)      ' '
    bracket_open_RawSegment:                                [49](1, 3, 18)      '('
    code_RawSegment:                                        [50](1, 3, 19)      'DATE'
    whitespace_RawSegment:                                  [54](1, 3, 23)      ' '
    code_RawSegment:                                        [55](1, 3, 24)      'FORMAT'
    whitespace_RawSegment:                                  [61](1, 3, 30)      ' '
    single_quote_RawSegment:                                [62](1, 3, 31)      "'YYYY-MM-DD'"
    bracket_close_RawSegment:                               [74](1, 3, 43)      ')'
    comma_RawSegment:                                       [75](1, 3, 44)      ','
    newline_RawSegment:                                     [76](1, 3, 45)      '\n'
    whitespace_RawSegment:                                  [77](1, 4, 1)       '    '
    single_quote_RawSegment:                                [81](1, 4, 5)       "'100000'"
    whitespace_RawSegment:                                  [89](1, 4, 13)      ' '
    bracket_open_RawSegment:                                [90](1, 4, 14)      '('
    code_RawSegment:                                        [91](1, 4, 15)      'SMALLINT'
    bracket_close_RawSegment:                               [99](1, 4, 23)      ')'
    newline_RawSegment:                                     [100](1, 4, 24)     '\n'
    code_RawSegment:                                        [101](1, 5, 1)      'from'
    whitespace_RawSegment:                                  [105](1, 5, 5)      ' '
    code_RawSegment:                                        [106](1, 5, 6)      'test_table'
    semicolon_RawSegment:                                   [116](1, 5, 16)     ';'

________ test__dialect__base_file_parse[bigquery-interval_function.sql] ________

dialect = 'bigquery', file = 'interval_function.sql'

    @pytest.mark.parametrize(
        "dialect,file",
        parse_success_examples
    )
    def test__dialect__base_file_parse(dialect, file):
        """For given test examples, check successful parsing."""
        raw = load_file(dialect, file)
        # Load the right dialect
        config = FluffConfig(overrides=dict(dialect=dialect))
        context = ParseContext.from_config(config)
        fs, lex_vs = FileSegment.from_raw(raw, config=config)
        # From just the initial parse, check we're all there
        assert fs.raw == raw
        # Check we don't have lexing issues
        assert not lex_vs
    
        # Do the parse WITHOUT lots of logging
        # The logs get too long here to be useful. We should use
        # specfic segment tests if we want to debug logs.
        # with caplog.at_level(logging.DEBUG):
        print("Pre-parse structure: {0}".format(fs.to_tuple(show_raw=True)))
        print("Pre-parse structure: {0}".format(fs.stringify()))
>       parsed = fs.parse(parse_context=context)  # Optional: set recurse=1 to limit recursion

test/dialects_test.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/sqlfluff/parser/segments_base.py:456: in parse
    incr='parse_depth', match_depth=0, recurse=True
src/sqlfluff/parser/segments_base.py:688: in expand
    res = stmt.parse(parse_context=parse_context)
src/sqlfluff/parser/segments_base.py:409: in parse
    match_segment=self.__class__.__name__
src/sqlfluff/parser/grammar.py:81: in _match
    m = self.match(segments, parse_context=parse_context)
src/sqlfluff/parser/grammar.py:656: in match
    parse_context=parse_context.copy(incr='match_depth')
src/sqlfluff/parser/grammar.py:81: in _match
    m = self.match(segments, parse_context=parse_context)
src/sqlfluff/parser/grammar.py:580: in match
    parse_context=parse_context.copy(match_segment=self._get_ref()))
src/sqlfluff/parser/segments_base.py:651: in _match
    m = cls.match(segments, parse_context=parse_context)
src/sqlfluff/parser/segments_base.py:614: in match
    m = cls._match_grammar()._match(segments=segments, parse_context=parse_context.copy(incr='match_depth'))
src/sqlfluff/parser/grammar.py:81: in _match
    m = self.match(segments, parse_context=parse_context)
src/sqlfluff/parser/grammar.py:971: in match
    code_only=False)
src/sqlfluff/parser/grammar.py:467: in _bracket_sensitive_look_ahead_match
    code_only=code_only)
src/sqlfluff/parser/grammar.py:275: in _look_ahead_match
    simple_matchers = [m for m in matchers if m.simple(parse_context=parse_context)]
src/sqlfluff/parser/grammar.py:275: in <listcomp>
    simple_matchers = [m for m in matchers if m.simple(parse_context=parse_context)]
src/sqlfluff/parser/grammar.py:524: in simple
    ).simple(parse_context=parse_context)
src/sqlfluff/parser/segments_base.py:232: in simple
    return match_grammar.simple(parse_context=parse_context)
src/sqlfluff/parser/grammar.py:638: in simple
    simple = opt.simple(parse_context=parse_context)
src/sqlfluff/parser/grammar.py:801: in simple
    simple = opt.simple(parse_context=parse_context)
src/sqlfluff/parser/grammar.py:523: in simple
    dialect=parse_context.dialect
src/sqlfluff/parser/grammar.py:542: in _get_elem
    return dialect.ref(self._get_ref())
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Dialect: bigquery>, name = 'UnionKeywordSegment'

    def ref(self, name):
        """Return an object which acts as a late binding reference to the element named.
    
        NB: This requires the dialect to be expanded.
    
        """
        if not self.expanded:
            raise RuntimeError("Dialect must be expanded before use.")
    
        if name in self._library:
            res = self._library[name]
            if res:
                return res
            else:
                raise ValueError(
                    "Unexpected Null response while fetching {0!r} from {1}".format(
                        name, self.name))
        else:
            raise RuntimeError(
                "Grammar refers to {0!r} which was not found in the {1} dialect".format(
>                   name, self.name))
E           RuntimeError: Grammar refers to 'UnionKeywordSegment' which was not found in the bigquery dialect

src/sqlfluff/dialects/base.py:219: RuntimeError
----------------------------- Captured stdout call -----------------------------
Pre-parse structure: ('file', (('raw', 'SELECT'), ('newline', '\n'), ('whitespace', '    '), ('raw', 'TIMESTAMP_DIFF'), ('raw', '('), ('raw', 'session_end'), ('raw', '.'), ('raw', 'eventTimestamp'), ('comma', ','), ('whitespace', ' '), ('raw', 'session_start'), ('raw', '.'), ('raw', 'eventTimestamp'), ('comma', ','), ('whitespace', ' '), ('raw', 'SECOND'), ('raw', ')'), ('comma', ','), ('newline', '\n'), ('whitespace', '    '), ('raw', 'TIMESTAMP_TRUNC'), ('raw', '('), ('newline', '\n'), ('whitespace', '        '), ('raw', 'TIMESTAMP_ADD'), ('raw', '('), ('raw', 'session_start'), ('raw', '.'), ('raw', 'eventTimestamp'), ('comma', ','), ('newline', '\n'), ('whitespace', '            '), ('raw', 'INTERVAL'), ('whitespace', ' '), ('raw', 'cast'), ('raw', '('), ('raw', 'TIMESTAMP_DIFF'), ('raw', '('), ('raw', 'session_end'), ('raw', '.'), ('raw', 'eventTimestamp'), ('comma', ','), ('whitespace', ' '), ('raw', 'session_start'), ('raw', '.'), ('raw', 'eventTimestamp'), ('comma', ','), ('whitespace', ' '), ('raw', 'SECOND'), ('raw', ')'), ('raw', '/'), ('raw', '2'), ('whitespace', ' '), ('raw', 'AS'), ('whitespace', ' '), ('raw', 'int64'), ('raw', ')'), ('whitespace', ' '), ('raw', 'second'), ('raw', ')'), ('newline', '\n'), ('whitespace', '        '), ('comma', ','), ('whitespace', ' '), ('raw', 'HOUR'), ('raw', ')'), ('whitespace', ' '), ('raw', 'AS'), ('whitespace', ' '), ('raw', 'avgAtHour'), ('comma', ','), ('newline', '\n'), ('whitespace', '    '), ('raw', 'TIME_ADD'), ('raw', '('), ('raw', 'time1'), ('comma', ','), ('whitespace', ' '), ('raw', 'INTERVAL'), ('whitespace', ' '), ('raw', '10'), ('whitespace', ' '), ('raw', 'MINUTE'), ('raw', ')'), ('whitespace', ' '), ('raw', 'AS'), ('whitespace', ' '), ('raw', 'after1'), ('comma', ','), ('newline', '\n'), ('whitespace', '    '), ('raw', 'DATE_SUB'), ('raw', '('), ('raw', 'time2'), ('comma', ','), ('whitespace', ' '), ('raw', 'INTERVAL'), ('whitespace', ' '), ('raw', '5'), ('whitespace', ' '), ('raw', 'YEAR'), ('raw', ')'), ('whitespace', ' '), ('raw', 'AS'), ('whitespace', ' '), ('raw', 'before1'), ('newline', '\n'), ('raw', 'FROM'), ('whitespace', ' '), ('raw', 'dummy1'), ('raw', ';')))
Pre-parse structure: FileSegment:                                                [0](1, 1, 1)
    code_RawSegment:                                        [0](1, 1, 1)        'SELECT'
    newline_RawSegment:                                     [6](1, 1, 7)        '\n'
    whitespace_RawSegment:                                  [7](1, 2, 1)        '    '
    code_RawSegment:                                        [11](1, 2, 5)       'TIMESTAMP_DIFF'
    bracket_open_RawSegment:                                [25](1, 2, 19)      '('
    code_RawSegment:                                        [26](1, 2, 20)      'session_end'
    dot_RawSegment:                                         [37](1, 2, 31)      '.'
    code_RawSegment:                                        [38](1, 2, 32)      'eventTimestamp'
    comma_RawSegment:                                       [52](1, 2, 46)      ','
    whitespace_RawSegment:                                  [53](1, 2, 47)      ' '
    code_RawSegment:                                        [54](1, 2, 48)      'session_start'
    dot_RawSegment:                                         [67](1, 2, 61)      '.'
    code_RawSegment:                                        [68](1, 2, 62)      'eventTimestamp'
    comma_RawSegment:                                       [82](1, 2, 76)      ','
    whitespace_RawSegment:                                  [83](1, 2, 77)      ' '
    code_RawSegment:                                        [84](1, 2, 78)      'SECOND'
    bracket_close_RawSegment:                               [90](1, 2, 84)      ')'
    comma_RawSegment:                                       [91](1, 2, 85)      ','
    newline_RawSegment:                                     [92](1, 2, 86)      '\n'
    whitespace_RawSegment:                                  [93](1, 3, 1)       '    '
    code_RawSegment:                                        [97](1, 3, 5)       'TIMESTAMP_TRUNC'
    bracket_open_RawSegment:                                [112](1, 3, 20)     '('
    newline_RawSegment:                                     [113](1, 3, 21)     '\n'
    whitespace_RawSegment:                                  [114](1, 4, 1)      '        '
    code_RawSegment:                                        [122](1, 4, 9)      'TIMESTAMP_ADD'
    bracket_open_RawSegment:                                [135](1, 4, 22)     '('
    code_RawSegment:                                        [136](1, 4, 23)     'session_start'
    dot_RawSegment:                                         [149](1, 4, 36)     '.'
    code_RawSegment:                                        [150](1, 4, 37)     'eventTimestamp'
    comma_RawSegment:                                       [164](1, 4, 51)     ','
    newline_RawSegment:                                     [165](1, 4, 52)     '\n'
    whitespace_RawSegment:                                  [166](1, 5, 1)      '            '
    code_RawSegment:                                        [178](1, 5, 13)     'INTERVAL'
    whitespace_RawSegment:                                  [186](1, 5, 21)     ' '
    code_RawSegment:                                        [187](1, 5, 22)     'cast'
    bracket_open_RawSegment:                                [191](1, 5, 26)     '('
    code_RawSegment:                                        [192](1, 5, 27)     'TIMESTAMP_DIFF'
    bracket_open_RawSegment:                                [206](1, 5, 41)     '('
    code_RawSegment:                                        [207](1, 5, 42)     'session_end'
    dot_RawSegment:                                         [218](1, 5, 53)     '.'
    code_RawSegment:                                        [219](1, 5, 54)     'eventTimestamp'
    comma_RawSegment:                                       [233](1, 5, 68)     ','
    whitespace_RawSegment:                                  [234](1, 5, 69)     ' '
    code_RawSegment:                                        [235](1, 5, 70)     'session_start'
    dot_RawSegment:                                         [248](1, 5, 83)     '.'
    code_RawSegment:                                        [249](1, 5, 84)     'eventTimestamp'
    comma_RawSegment:                                       [263](1, 5, 98)     ','
    whitespace_RawSegment:                                  [264](1, 5, 99)     ' '
    code_RawSegment:                                        [265](1, 5, 100)    'SECOND'
    bracket_close_RawSegment:                               [271](1, 5, 106)    ')'
    divide_RawSegment:                                      [272](1, 5, 107)    '/'
    numeric_literal_RawSegment:                             [273](1, 5, 108)    '2'
    whitespace_RawSegment:                                  [274](1, 5, 109)    ' '
    code_RawSegment:                                        [275](1, 5, 110)    'AS'
    whitespace_RawSegment:                                  [277](1, 5, 112)    ' '
    code_RawSegment:                                        [278](1, 5, 113)    'int64'
    bracket_close_RawSegment:                               [283](1, 5, 118)    ')'
    whitespace_RawSegment:                                  [284](1, 5, 119)    ' '
    code_RawSegment:                                        [285](1, 5, 120)    'second'
    bracket_close_RawSegment:                               [291](1, 5, 126)    ')'
    newline_RawSegment:                                     [292](1, 5, 127)    '\n'
    whitespace_RawSegment:                                  [293](1, 6, 1)      '        '
    comma_RawSegment:                                       [301](1, 6, 9)      ','
    whitespace_RawSegment:                                  [302](1, 6, 10)     ' '
    code_RawSegment:                                        [303](1, 6, 11)     'HOUR'
    bracket_close_RawSegment:                               [307](1, 6, 15)     ')'
    whitespace_RawSegment:                                  [308](1, 6, 16)     ' '
    code_RawSegment:                                        [309](1, 6, 17)     'AS'
    whitespace_RawSegment:                                  [311](1, 6, 19)     ' '
    code_RawSegment:                                        [312](1, 6, 20)     'avgAtHour'
    comma_RawSegment:                                       [321](1, 6, 29)     ','
    newline_RawSegment:                                     [322](1, 6, 30)     '\n'
    whitespace_RawSegment:                                  [323](1, 7, 1)      '    '
    code_RawSegment:                                        [327](1, 7, 5)      'TIME_ADD'
    bracket_open_RawSegment:                                [335](1, 7, 13)     '('
    code_RawSegment:                                        [336](1, 7, 14)     'time1'
    comma_RawSegment:                                       [341](1, 7, 19)     ','
    whitespace_RawSegment:                                  [342](1, 7, 20)     ' '
    code_RawSegment:                                        [343](1, 7, 21)     'INTERVAL'
    whitespace_RawSegment:                                  [351](1, 7, 29)     ' '
    numeric_literal_RawSegment:                             [352](1, 7, 30)     '10'
    whitespace_RawSegment:                                  [354](1, 7, 32)     ' '
    code_RawSegment:                                        [355](1, 7, 33)     'MINUTE'
    bracket_close_RawSegment:                               [361](1, 7, 39)     ')'
    whitespace_RawSegment:                                  [362](1, 7, 40)     ' '
    code_RawSegment:                                        [363](1, 7, 41)     'AS'
    whitespace_RawSegment:                                  [365](1, 7, 43)     ' '
    code_RawSegment:                                        [366](1, 7, 44)     'after1'
    comma_RawSegment:                                       [372](1, 7, 50)     ','
    newline_RawSegment:                                     [373](1, 7, 51)     '\n'
    whitespace_RawSegment:                                  [374](1, 8, 1)      '    '
    code_RawSegment:                                        [378](1, 8, 5)      'DATE_SUB'
    bracket_open_RawSegment:                                [386](1, 8, 13)     '('
    code_RawSegment:                                        [387](1, 8, 14)     'time2'
    comma_RawSegment:                                       [392](1, 8, 19)     ','
    whitespace_RawSegment:                                  [393](1, 8, 20)     ' '
    code_RawSegment:                                        [394](1, 8, 21)     'INTERVAL'
    whitespace_RawSegment:                                  [402](1, 8, 29)     ' '
    numeric_literal_RawSegment:                             [403](1, 8, 30)     '5'
    whitespace_RawSegment:                                  [404](1, 8, 31)     ' '
    code_RawSegment:                                        [405](1, 8, 32)     'YEAR'
    bracket_close_RawSegment:                               [409](1, 8, 36)     ')'
    whitespace_RawSegment:                                  [410](1, 8, 37)     ' '
    code_RawSegment:                                        [411](1, 8, 38)     'AS'
    whitespace_RawSegment:                                  [413](1, 8, 40)     ' '
    code_RawSegment:                                        [414](1, 8, 41)     'before1'
    newline_RawSegment:                                     [421](1, 8, 48)     '\n'
    code_RawSegment:                                        [422](1, 9, 1)      'FROM'
    whitespace_RawSegment:                                  [426](1, 9, 5)      ' '
    code_RawSegment:                                        [427](1, 9, 6)      'dummy1'
    semicolon_RawSegment:                                   [433](1, 9, 12)     ';'

_________ test__dialect__base_file_parse[bigquery-string_literals.sql] _________

dialect = 'bigquery', file = 'string_literals.sql'

    @pytest.mark.parametrize(
        "dialect,file",
        parse_success_examples
    )
    def test__dialect__base_file_parse(dialect, file):
        """For given test examples, check successful parsing."""
        raw = load_file(dialect, file)
        # Load the right dialect
        config = FluffConfig(overrides=dict(dialect=dialect))
        context = ParseContext.from_config(config)
        fs, lex_vs = FileSegment.from_raw(raw, config=config)
        # From just the initial parse, check we're all there
        assert fs.raw == raw
        # Check we don't have lexing issues
        assert not lex_vs
    
        # Do the parse WITHOUT lots of logging
        # The logs get too long here to be useful. We should use
        # specfic segment tests if we want to debug logs.
        # with caplog.at_level(logging.DEBUG):
        print("Pre-parse structure: {0}".format(fs.to_tuple(show_raw=True)))
        print("Pre-parse structure: {0}".format(fs.stringify()))
>       parsed = fs.parse(parse_context=context)  # Optional: set recurse=1 to limit recursion

test/dialects_test.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/sqlfluff/parser/segments_base.py:456: in parse
    incr='parse_depth', match_depth=0, recurse=True
src/sqlfluff/parser/segments_base.py:688: in expand
    res = stmt.parse(parse_context=parse_context)
src/sqlfluff/parser/segments_base.py:409: in parse
    match_segment=self.__class__.__name__
src/sqlfluff/parser/grammar.py:81: in _match
    m = self.match(segments, parse_context=parse_context)
src/sqlfluff/parser/grammar.py:656: in match
    parse_context=parse_context.copy(incr='match_depth')
src/sqlfluff/parser/grammar.py:81: in _match
    m = self.match(segments, parse_context=parse_context)
src/sqlfluff/parser/grammar.py:580: in match
    parse_context=parse_context.copy(match_segment=self._get_ref()))
src/sqlfluff/parser/segments_base.py:651: in _match
    m = cls.match(segments, parse_context=parse_context)
src/sqlfluff/parser/segments_base.py:614: in match
    m = cls._match_grammar()._match(segments=segments, parse_context=parse_context.copy(incr='match_depth'))
src/sqlfluff/parser/grammar.py:81: in _match
    m = self.match(segments, parse_context=parse_context)
src/sqlfluff/parser/grammar.py:971: in match
    code_only=False)
src/sqlfluff/parser/grammar.py:467: in _bracket_sensitive_look_ahead_match
    code_only=code_only)
src/sqlfluff/parser/grammar.py:275: in _look_ahead_match
    simple_matchers = [m for m in matchers if m.simple(parse_context=parse_context)]
src/sqlfluff/parser/grammar.py:275: in <listcomp>
    simple_matchers = [m for m in matchers if m.simple(parse_context=parse_context)]
src/sqlfluff/parser/grammar.py:524: in simple
    ).simple(parse_context=parse_context)
src/sqlfluff/parser/segments_base.py:232: in simple
    return match_grammar.simple(parse_context=parse_context)
src/sqlfluff/parser/grammar.py:638: in simple
    simple = opt.simple(parse_context=parse_context)
src/sqlfluff/parser/grammar.py:801: in simple
    simple = opt.simple(parse_context=parse_context)
src/sqlfluff/parser/grammar.py:523: in simple
    dialect=parse_context.dialect
src/sqlfluff/parser/grammar.py:542: in _get_elem
    return dialect.ref(self._get_ref())
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Dialect: bigquery>, name = 'UnionKeywordSegment'

    def ref(self, name):
        """Return an object which acts as a late binding reference to the element named.
    
        NB: This requires the dialect to be expanded.
    
        """
        if not self.expanded:
            raise RuntimeError("Dialect must be expanded before use.")
    
        if name in self._library:
            res = self._library[name]
            if res:
                return res
            else:
                raise ValueError(
                    "Unexpected Null response while fetching {0!r} from {1}".format(
                        name, self.name))
        else:
            raise RuntimeError(
                "Grammar refers to {0!r} which was not found in the {1} dialect".format(
>                   name, self.name))
E           RuntimeError: Grammar refers to 'UnionKeywordSegment' which was not found in the bigquery dialect

src/sqlfluff/dialects/base.py:219: RuntimeError
----------------------------- Captured stdout call -----------------------------
Pre-parse structure: ('file', (('comment', '-- Examples from https://cloud.google.com/bigquery/docs/reference/standard-sql/lexical#string_and_bytes_literals'), ('newline', '\n'), ('raw', 'SELECT'), ('newline', '\n'), ('whitespace', '    '), ('raw', '""'), ('comma', ','), ('newline', '\n'), ('whitespace', '    '), ('raw', "''"), ('comma', ','), ('newline', '\n'), ('whitespace', '    '), ('raw', '"abc"'), ('comma', ','), ('newline', '\n'), ('whitespace', '    '), ('raw', '"it\'s"'), ('comma', ','), ('newline', '\n'), ('whitespace', '    '), ('raw', "'it\\'s'"), ('comma', ','), ('newline', '\n'), ('whitespace', '    '), ('raw', '\'Title: "Boy"\''), ('comma', ','), ('newline', '\n'), ('whitespace', '    '), ('raw', '"test \\"escaped\\""'), ('comma', ','), ('newline', '\n'), ('whitespace', '    '), ('raw', "'test \\'escaped\\''"), ('comma', ','), ('newline', '\n'), ('whitespace', '    '), ('raw', '"test \\\\\\"escaped"'), ('comma', ','), ('newline', '\n'), ('whitespace', '    '), ('raw', '"test \\"escaped\\\\\\""'), ('comma', ','), ('newline', '\n'), ('whitespace', '    '), ('raw', 'r""'), ('comma', ','), ('newline', '\n'), ('whitespace', '    '), ('raw', "r''"), ('comma', ','), ('newline', '\n'), ('whitespace', '    '), ('raw', 'r"abc+"'), ('comma', ','), ('newline', '\n'), ('whitespace', '    '), ('raw', 'R"abc+"'), ('comma', ','), ('newline', '\n'), ('whitespace', '    '), ('raw', "r'abc+'"), ('comma', ','), ('newline', '\n'), ('whitespace', '    '), ('raw', "R'abc+'"), ('comma', ','), ('newline', '\n'), ('whitespace', '    '), ('raw', "r'f\\(abc, (.*),def\\)'"), ('comma', ','), ('newline', '\n'), ('whitespace', '    '), ('raw', 'r"f\\(abc, (.*),def\\)"'), ('comma', ','), ('newline', '\n'), ('whitespace', '    '), ('raw', "b'abc'"), ('comma', ','), ('newline', '\n'), ('whitespace', '    '), ('raw', 'B"abc"'), ('comma', ','), ('newline', '\n'), ('whitespace', '    '), ('raw', 'rb"abc*"'), ('comma', ','), ('newline', '\n'), ('whitespace', '    '), ('raw', 'rB"abc*"'), ('comma', ','), ('newline', '\n'), ('whitespace', '    '), ('raw', "Rb'abc*'"), ('comma', ','), ('newline', '\n'), ('whitespace', '    '), ('raw', "br'abc+'"), ('comma', ','), ('newline', '\n'), ('whitespace', '    '), ('raw', 'RB"abc+"'), ('newline', '\n'), ('raw', 'FROM'), ('whitespace', ' '), ('raw', 'dummy1'), ('newline', '\n')))
Pre-parse structure: FileSegment:                                                [0](1, 1, 1)
    inline_comment_RawSegment:                              [0](1, 1, 1)        '-- Examples from https://cloud.google.com/bigquery/docs/reference/standard-sql/lexical#string_and_bytes_literals'
    newline_RawSegment:                                     [112](1, 1, 113)    '\n'
    code_RawSegment:                                        [113](1, 2, 1)      'SELECT'
    newline_RawSegment:                                     [119](1, 2, 7)      '\n'
    whitespace_RawSegment:                                  [120](1, 3, 1)      '    '
    double_quote_RawSegment:                                [124](1, 3, 5)      '""'
    comma_RawSegment:                                       [126](1, 3, 7)      ','
    newline_RawSegment:                                     [127](1, 3, 8)      '\n'
    whitespace_RawSegment:                                  [128](1, 4, 1)      '    '
    single_quote_RawSegment:                                [132](1, 4, 5)      "''"
    comma_RawSegment:                                       [134](1, 4, 7)      ','
    newline_RawSegment:                                     [135](1, 4, 8)      '\n'
    whitespace_RawSegment:                                  [136](1, 5, 1)      '    '
    double_quote_RawSegment:                                [140](1, 5, 5)      '"abc"'
    comma_RawSegment:                                       [145](1, 5, 10)     ','
    newline_RawSegment:                                     [146](1, 5, 11)     '\n'
    whitespace_RawSegment:                                  [147](1, 6, 1)      '    '
    double_quote_RawSegment:                                [151](1, 6, 5)      '"it\'s"'
    comma_RawSegment:                                       [157](1, 6, 11)     ','
    newline_RawSegment:                                     [158](1, 6, 12)     '\n'
    whitespace_RawSegment:                                  [159](1, 7, 1)      '    '
    single_quote_RawSegment:                                [163](1, 7, 5)      "'it\\'s'"
    comma_RawSegment:                                       [170](1, 7, 12)     ','
    newline_RawSegment:                                     [171](1, 7, 13)     '\n'
    whitespace_RawSegment:                                  [172](1, 8, 1)      '    '
    single_quote_RawSegment:                                [176](1, 8, 5)      '\'Title: "Boy"\''
    comma_RawSegment:                                       [190](1, 8, 19)     ','
    newline_RawSegment:                                     [191](1, 8, 20)     '\n'
    whitespace_RawSegment:                                  [192](1, 9, 1)      '    '
    double_quote_RawSegment:                                [196](1, 9, 5)      '"test \\"escaped\\""'
    comma_RawSegment:                                       [214](1, 9, 23)     ','
    newline_RawSegment:                                     [215](1, 9, 24)     '\n'
    whitespace_RawSegment:                                  [216](1, 10, 1)     '    '
    single_quote_RawSegment:                                [220](1, 10, 5)     "'test \\'escaped\\''"
    comma_RawSegment:                                       [238](1, 10, 23)    ','
    newline_RawSegment:                                     [239](1, 10, 24)    '\n'
    whitespace_RawSegment:                                  [240](1, 11, 1)     '    '
    double_quote_RawSegment:                                [244](1, 11, 5)     '"test \\\\\\"escaped"'
    comma_RawSegment:                                       [262](1, 11, 23)    ','
    newline_RawSegment:                                     [263](1, 11, 24)    '\n'
    whitespace_RawSegment:                                  [264](1, 12, 1)     '    '
    double_quote_RawSegment:                                [268](1, 12, 5)     '"test \\"escaped\\\\\\""'
    comma_RawSegment:                                       [288](1, 12, 25)    ','
    newline_RawSegment:                                     [289](1, 12, 26)    '\n'
    whitespace_RawSegment:                                  [290](1, 13, 1)     '    '
    double_quote_RawSegment:                                [294](1, 13, 5)     'r""'
    comma_RawSegment:                                       [297](1, 13, 8)     ','
    newline_RawSegment:                                     [298](1, 13, 9)     '\n'
    whitespace_RawSegment:                                  [299](1, 14, 1)     '    '
    single_quote_RawSegment:                                [303](1, 14, 5)     "r''"
    comma_RawSegment:                                       [306](1, 14, 8)     ','
    newline_RawSegment:                                     [307](1, 14, 9)     '\n'
    whitespace_RawSegment:                                  [308](1, 15, 1)     '    '
    double_quote_RawSegment:                                [312](1, 15, 5)     'r"abc+"'
    comma_RawSegment:                                       [319](1, 15, 12)    ','
    newline_RawSegment:                                     [320](1, 15, 13)    '\n'
    whitespace_RawSegment:                                  [321](1, 16, 1)     '    '
    double_quote_RawSegment:                                [325](1, 16, 5)     'R"abc+"'
    comma_RawSegment:                                       [332](1, 16, 12)    ','
    newline_RawSegment:                                     [333](1, 16, 13)    '\n'
    whitespace_RawSegment:                                  [334](1, 17, 1)     '    '
    single_quote_RawSegment:                                [338](1, 17, 5)     "r'abc+'"
    comma_RawSegment:                                       [345](1, 17, 12)    ','
    newline_RawSegment:                                     [346](1, 17, 13)    '\n'
    whitespace_RawSegment:                                  [347](1, 18, 1)     '    '
    single_quote_RawSegment:                                [351](1, 18, 5)     "R'abc+'"
    comma_RawSegment:                                       [358](1, 18, 12)    ','
    newline_RawSegment:                                     [359](1, 18, 13)    '\n'
    whitespace_RawSegment:                                  [360](1, 19, 1)     '    '
    single_quote_RawSegment:                                [364](1, 19, 5)     "r'f\\(abc, (.*),def\\)'"
    comma_RawSegment:                                       [385](1, 19, 26)    ','
    newline_RawSegment:                                     [386](1, 19, 27)    '\n'
    whitespace_RawSegment:                                  [387](1, 20, 1)     '    '
    double_quote_RawSegment:                                [391](1, 20, 5)     'r"f\\(abc, (.*),def\\)"'
    comma_RawSegment:                                       [412](1, 20, 26)    ','
    newline_RawSegment:                                     [413](1, 20, 27)    '\n'
    whitespace_RawSegment:                                  [414](1, 21, 1)     '    '
    single_quote_RawSegment:                                [418](1, 21, 5)     "b'abc'"
    comma_RawSegment:                                       [424](1, 21, 11)    ','
    newline_RawSegment:                                     [425](1, 21, 12)    '\n'
    whitespace_RawSegment:                                  [426](1, 22, 1)     '    '
    double_quote_RawSegment:                                [430](1, 22, 5)     'B"abc"'
    comma_RawSegment:                                       [436](1, 22, 11)    ','
    newline_RawSegment:                                     [437](1, 22, 12)    '\n'
    whitespace_RawSegment:                                  [438](1, 23, 1)     '    '
    double_quote_RawSegment:                                [442](1, 23, 5)     'rb"abc*"'
    comma_RawSegment:                                       [450](1, 23, 13)    ','
    newline_RawSegment:                                     [451](1, 23, 14)    '\n'
    whitespace_RawSegment:                                  [452](1, 24, 1)     '    '
    double_quote_RawSegment:                                [456](1, 24, 5)     'rB"abc*"'
    comma_RawSegment:                                       [464](1, 24, 13)    ','
    newline_RawSegment:                                     [465](1, 24, 14)    '\n'
    whitespace_RawSegment:                                  [466](1, 25, 1)     '    '
    single_quote_RawSegment:                                [470](1, 25, 5)     "Rb'abc*'"
    comma_RawSegment:                                       [478](1, 25, 13)    ','
    newline_RawSegment:                                     [479](1, 25, 14)    '\n'
    whitespace_RawSegment:                                  [480](1, 26, 1)     '    '
    single_quote_RawSegment:                                [484](1, 26, 5)     "br'abc+'"
    comma_RawSegment:                                       [492](1, 26, 13)    ','
    newline_RawSegment:                                     [493](1, 26, 14)    '\n'
    whitespace_RawSegment:                                  [494](1, 27, 1)     '    '
    double_quote_RawSegment:                                [498](1, 27, 5)     'RB"abc+"'
    newline_RawSegment:                                     [506](1, 27, 13)    '\n'
    code_RawSegment:                                        [507](1, 28, 1)     'FROM'
    whitespace_RawSegment:                                  [511](1, 28, 5)     ' '
    code_RawSegment:                                        [512](1, 28, 6)     'dummy1'
    newline_RawSegment:                                     [518](1, 28, 12)    '\n'

_________ test__dialect__base_file_parse[bigquery-select_quoting.sql] __________

dialect = 'bigquery', file = 'select_quoting.sql'

    @pytest.mark.parametrize(
        "dialect,file",
        parse_success_examples
    )
    def test__dialect__base_file_parse(dialect, file):
        """For given test examples, check successful parsing."""
        raw = load_file(dialect, file)
        # Load the right dialect
        config = FluffConfig(overrides=dict(dialect=dialect))
        context = ParseContext.from_config(config)
        fs, lex_vs = FileSegment.from_raw(raw, config=config)
        # From just the initial parse, check we're all there
        assert fs.raw == raw
        # Check we don't have lexing issues
        assert not lex_vs
    
        # Do the parse WITHOUT lots of logging
        # The logs get too long here to be useful. We should use
        # specfic segment tests if we want to debug logs.
        # with caplog.at_level(logging.DEBUG):
        print("Pre-parse structure: {0}".format(fs.to_tuple(show_raw=True)))
        print("Pre-parse structure: {0}".format(fs.stringify()))
>       parsed = fs.parse(parse_context=context)  # Optional: set recurse=1 to limit recursion

test/dialects_test.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/sqlfluff/parser/segments_base.py:456: in parse
    incr='parse_depth', match_depth=0, recurse=True
src/sqlfluff/parser/segments_base.py:688: in expand
    res = stmt.parse(parse_context=parse_context)
src/sqlfluff/parser/segments_base.py:409: in parse
    match_segment=self.__class__.__name__
src/sqlfluff/parser/grammar.py:81: in _match
    m = self.match(segments, parse_context=parse_context)
src/sqlfluff/parser/grammar.py:656: in match
    parse_context=parse_context.copy(incr='match_depth')
src/sqlfluff/parser/grammar.py:81: in _match
    m = self.match(segments, parse_context=parse_context)
src/sqlfluff/parser/grammar.py:580: in match
    parse_context=parse_context.copy(match_segment=self._get_ref()))
src/sqlfluff/parser/segments_base.py:651: in _match
    m = cls.match(segments, parse_context=parse_context)
src/sqlfluff/parser/segments_base.py:614: in match
    m = cls._match_grammar()._match(segments=segments, parse_context=parse_context.copy(incr='match_depth'))
src/sqlfluff/parser/grammar.py:81: in _match
    m = self.match(segments, parse_context=parse_context)
src/sqlfluff/parser/grammar.py:971: in match
    code_only=False)
src/sqlfluff/parser/grammar.py:467: in _bracket_sensitive_look_ahead_match
    code_only=code_only)
src/sqlfluff/parser/grammar.py:275: in _look_ahead_match
    simple_matchers = [m for m in matchers if m.simple(parse_context=parse_context)]
src/sqlfluff/parser/grammar.py:275: in <listcomp>
    simple_matchers = [m for m in matchers if m.simple(parse_context=parse_context)]
src/sqlfluff/parser/grammar.py:524: in simple
    ).simple(parse_context=parse_context)
src/sqlfluff/parser/segments_base.py:232: in simple
    return match_grammar.simple(parse_context=parse_context)
src/sqlfluff/parser/grammar.py:638: in simple
    simple = opt.simple(parse_context=parse_context)
src/sqlfluff/parser/grammar.py:801: in simple
    simple = opt.simple(parse_context=parse_context)
src/sqlfluff/parser/grammar.py:523: in simple
    dialect=parse_context.dialect
src/sqlfluff/parser/grammar.py:542: in _get_elem
    return dialect.ref(self._get_ref())
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Dialect: bigquery>, name = 'UnionKeywordSegment'

    def ref(self, name):
        """Return an object which acts as a late binding reference to the element named.
    
        NB: This requires the dialect to be expanded.
    
        """
        if not self.expanded:
            raise RuntimeError("Dialect must be expanded before use.")
    
        if name in self._library:
            res = self._library[name]
            if res:
                return res
            else:
                raise ValueError(
                    "Unexpected Null response while fetching {0!r} from {1}".format(
                        name, self.name))
        else:
            raise RuntimeError(
                "Grammar refers to {0!r} which was not found in the {1} dialect".format(
>                   name, self.name))
E           RuntimeError: Grammar refers to 'UnionKeywordSegment' which was not found in the bigquery dialect

src/sqlfluff/dialects/base.py:219: RuntimeError
----------------------------- Captured stdout call -----------------------------
Pre-parse structure: ('file', (('raw', 'SELECT'), ('newline', '\n'), ('whitespace', '    '), ('raw', 'user_id'), ('comma', ','), ('newline', '\n'), ('whitespace', '    '), ('raw', '"some string"'), ('whitespace', ' '), ('raw', 'as'), ('whitespace', ' '), ('raw', 'list_id'), ('newline', '\n'), ('raw', 'FROM'), ('newline', '\n'), ('whitespace', '    '), ('raw', '`database.schema.benchmark_user_map`'), ('newline', '\n'), ('raw', 'WHERE'), ('newline', '\n'), ('whitespace', '    '), ('raw', 'list_id'), ('whitespace', ' '), ('raw', 'IS'), ('whitespace', ' '), ('raw', 'NULL'), ('newline', '\n'), ('whitespace', '    '), ('raw', 'OR'), ('whitespace', ' '), ('raw', 'user_id'), ('whitespace', ' '), ('raw', 'IS'), ('whitespace', ' '), ('raw', 'NULL')))
Pre-parse structure: FileSegment:                                                [0](1, 1, 1)
    code_RawSegment:                                        [0](1, 1, 1)        'SELECT'
    newline_RawSegment:                                     [6](1, 1, 7)        '\n'
    whitespace_RawSegment:                                  [7](1, 2, 1)        '    '
    code_RawSegment:                                        [11](1, 2, 5)       'user_id'
    comma_RawSegment:                                       [18](1, 2, 12)      ','
    newline_RawSegment:                                     [19](1, 2, 13)      '\n'
    whitespace_RawSegment:                                  [20](1, 3, 1)       '    '
    double_quote_RawSegment:                                [24](1, 3, 5)       '"some string"'
    whitespace_RawSegment:                                  [37](1, 3, 18)      ' '
    code_RawSegment:                                        [38](1, 3, 19)      'as'
    whitespace_RawSegment:                                  [40](1, 3, 21)      ' '
    code_RawSegment:                                        [41](1, 3, 22)      'list_id'
    newline_RawSegment:                                     [48](1, 3, 29)      '\n'
    code_RawSegment:                                        [49](1, 4, 1)       'FROM'
    newline_RawSegment:                                     [53](1, 4, 5)       '\n'
    whitespace_RawSegment:                                  [54](1, 5, 1)       '    '
    back_quote_RawSegment:                                  [58](1, 5, 5)       '`database.schema.benchmark_user_map`'
    newline_RawSegment:                                     [94](1, 5, 41)      '\n'
    code_RawSegment:                                        [95](1, 6, 1)       'WHERE'
    newline_RawSegment:                                     [100](1, 6, 6)      '\n'
    whitespace_RawSegment:                                  [101](1, 7, 1)      '    '
    code_RawSegment:                                        [105](1, 7, 5)      'list_id'
    whitespace_RawSegment:                                  [112](1, 7, 12)     ' '
    code_RawSegment:                                        [113](1, 7, 13)     'IS'
    whitespace_RawSegment:                                  [115](1, 7, 15)     ' '
    code_RawSegment:                                        [116](1, 7, 16)     'NULL'
    newline_RawSegment:                                     [120](1, 7, 20)     '\n'
    whitespace_RawSegment:                                  [121](1, 8, 1)      '    '
    code_RawSegment:                                        [125](1, 8, 5)      'OR'
    whitespace_RawSegment:                                  [127](1, 8, 7)      ' '
    code_RawSegment:                                        [128](1, 8, 8)      'user_id'
    whitespace_RawSegment:                                  [135](1, 8, 15)     ' '
    code_RawSegment:                                        [136](1, 8, 16)     'IS'
    whitespace_RawSegment:                                  [138](1, 8, 18)     ' '
    code_RawSegment:                                        [139](1, 8, 19)     'NULL'

_________ test__dialect__base_file_parse[bigquery-select_example.sql] __________

dialect = 'bigquery', file = 'select_example.sql'

    @pytest.mark.parametrize(
        "dialect,file",
        parse_success_examples
    )
    def test__dialect__base_file_parse(dialect, file):
        """For given test examples, check successful parsing."""
        raw = load_file(dialect, file)
        # Load the right dialect
        config = FluffConfig(overrides=dict(dialect=dialect))
        context = ParseContext.from_config(config)
        fs, lex_vs = FileSegment.from_raw(raw, config=config)
        # From just the initial parse, check we're all there
        assert fs.raw == raw
        # Check we don't have lexing issues
        assert not lex_vs
    
        # Do the parse WITHOUT lots of logging
        # The logs get too long here to be useful. We should use
        # specfic segment tests if we want to debug logs.
        # with caplog.at_level(logging.DEBUG):
        print("Pre-parse structure: {0}".format(fs.to_tuple(show_raw=True)))
        print("Pre-parse structure: {0}".format(fs.stringify()))
>       parsed = fs.parse(parse_context=context)  # Optional: set recurse=1 to limit recursion

test/dialects_test.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/sqlfluff/parser/segments_base.py:456: in parse
    incr='parse_depth', match_depth=0, recurse=True
src/sqlfluff/parser/segments_base.py:688: in expand
    res = stmt.parse(parse_context=parse_context)
src/sqlfluff/parser/segments_base.py:409: in parse
    match_segment=self.__class__.__name__
src/sqlfluff/parser/grammar.py:81: in _match
    m = self.match(segments, parse_context=parse_context)
src/sqlfluff/parser/grammar.py:656: in match
    parse_context=parse_context.copy(incr='match_depth')
src/sqlfluff/parser/grammar.py:81: in _match
    m = self.match(segments, parse_context=parse_context)
src/sqlfluff/parser/grammar.py:580: in match
    parse_context=parse_context.copy(match_segment=self._get_ref()))
src/sqlfluff/parser/segments_base.py:651: in _match
    m = cls.match(segments, parse_context=parse_context)
src/sqlfluff/parser/segments_base.py:614: in match
    m = cls._match_grammar()._match(segments=segments, parse_context=parse_context.copy(incr='match_depth'))
src/sqlfluff/parser/grammar.py:81: in _match
    m = self.match(segments, parse_context=parse_context)
src/sqlfluff/parser/grammar.py:971: in match
    code_only=False)
src/sqlfluff/parser/grammar.py:467: in _bracket_sensitive_look_ahead_match
    code_only=code_only)
src/sqlfluff/parser/grammar.py:275: in _look_ahead_match
    simple_matchers = [m for m in matchers if m.simple(parse_context=parse_context)]
src/sqlfluff/parser/grammar.py:275: in <listcomp>
    simple_matchers = [m for m in matchers if m.simple(parse_context=parse_context)]
src/sqlfluff/parser/grammar.py:524: in simple
    ).simple(parse_context=parse_context)
src/sqlfluff/parser/segments_base.py:232: in simple
    return match_grammar.simple(parse_context=parse_context)
src/sqlfluff/parser/grammar.py:638: in simple
    simple = opt.simple(parse_context=parse_context)
src/sqlfluff/parser/grammar.py:801: in simple
    simple = opt.simple(parse_context=parse_context)
src/sqlfluff/parser/grammar.py:523: in simple
    dialect=parse_context.dialect
src/sqlfluff/parser/grammar.py:542: in _get_elem
    return dialect.ref(self._get_ref())
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Dialect: bigquery>, name = 'UnionKeywordSegment'

    def ref(self, name):
        """Return an object which acts as a late binding reference to the element named.
    
        NB: This requires the dialect to be expanded.
    
        """
        if not self.expanded:
            raise RuntimeError("Dialect must be expanded before use.")
    
        if name in self._library:
            res = self._library[name]
            if res:
                return res
            else:
                raise ValueError(
                    "Unexpected Null response while fetching {0!r} from {1}".format(
                        name, self.name))
        else:
            raise RuntimeError(
                "Grammar refers to {0!r} which was not found in the {1} dialect".format(
>                   name, self.name))
E           RuntimeError: Grammar refers to 'UnionKeywordSegment' which was not found in the bigquery dialect

src/sqlfluff/dialects/base.py:219: RuntimeError
----------------------------- Captured stdout call -----------------------------
Pre-parse structure: ('file', (('comment', '-- This query should also parse in ANSI, but as a bigquery example'), ('newline', '\n'), ('comment', '-- it probably lives here. In particular it has an un-bracketed'), ('newline', '\n'), ('comment', '-- select clause within a function, and array notation which'), ('newline', '\n'), ('comment', '-- makes it a useful test case.'), ('newline', '\n'), ('raw', 'WITH'), ('whitespace', ' '), ('raw', 'age_buckets_bit_array'), ('whitespace', ' '), ('raw', 'AS'), ('whitespace', ' '), ('raw', '('), ('newline', '\n'), ('whitespace', '    '), ('raw', 'SELECT'), ('newline', '\n'), ('whitespace', '      '), ('raw', 'bucket_id'), ('comma', ','), ('newline', '\n'), ('whitespace', '      '), ('raw', 'num_ranges'), ('comma', ','), ('newline', '\n'), ('whitespace', '      '), ('raw', 'min_age'), ('comma', ','), ('newline', '\n'), ('whitespace', '      '), ('raw', 'ARRAY'), ('raw', '('), ('raw', 'SELECT'), ('whitespace', ' '), ('raw', 'CAST'), ('raw', '('), ('raw', 'num'), ('whitespace', ' '), ('raw', 'AS'), ('whitespace', ' '), ('raw', 'INT64'), ('raw', ')'), ('whitespace', ' '), ('raw', 'FROM'), ('whitespace', ' '), ('raw', 'UNNEST'), ('raw', '('), ('raw', 'SPLIT'), ('raw', '('), ('raw', 'binary'), ('comma', ','), ('whitespace', ' '), ('raw', "''"), ('raw', ')'), ('raw', ')'), ('whitespace', ' '), ('raw', 'AS'), ('whitespace', ' '), ('raw', 'num'), ('raw', ')'), ('whitespace', ' '), ('raw', 'AS'), ('whitespace', ' '), ('raw', 'bits'), ('comma', ','), ('newline', '\n'), ('whitespace', '      '), ('raw', 'age_label'), ('newline', '\n'), ('whitespace', '    '), ('raw', 'FROM'), ('newline', '\n'), ('whitespace', '      '), ('raw', 'age_buckets'), ('newline', '\n'), ('whitespace', '  '), ('raw', ')'), ('comma', ','), ('newline', '\n'), ('whitespace', '  '), ('raw', 'bucket_abundance'), ('whitespace', ' '), ('raw', 'AS'), ('whitespace', ' '), ('raw', '('), ('newline', '\n'), ('whitespace', '    '), ('raw', 'SELECT'), ('newline', '\n'), ('whitespace', '      '), ('raw', 'bucket_id'), ('newline', '\n'), ('whitespace', '      '), ('raw', '('), ('raw', 'count_18_24'), ('whitespace', ' '), ('raw', '*'), ('whitespace', ' '), ('raw', 'bits'), ('raw', '['), ('raw', 'OFFSET'), ('raw', '('), ('raw', '0'), ('raw', ')'), ('raw', ']'), ('whitespace', ' '), ('raw', '+'), ('whitespace', ' '), ('raw', 'count_25_34'), ('whitespace', ' '), ('raw', '*'), ('whitespace', ' '), ('raw', 'bits'), ('raw', '['), ('raw', 'OFFSET'), ('raw', '('), ('raw', '1'), ('raw', ')'), ('raw', ']'), ('whitespace', ' '), ('raw', '+'), ('newline', '\n'), ('whitespace', '       '), ('raw', 'count_35_44'), ('whitespace', ' '), ('raw', '*'), ('whitespace', ' '), ('raw', 'bits'), ('raw', '['), ('raw', 'OFFSET'), ('raw', '('), ('raw', '2'), ('raw', ')'), ('raw', ']'), ('whitespace', ' '), ('raw', '+'), ('whitespace', ' '), ('raw', 'count_45_54'), ('whitespace', ' '), ('raw', '*'), ('whitespace', ' '), ('raw', 'bits'), ('raw', '['), ('raw', 'OFFSET'), ('raw', '('), ('raw', '3'), ('raw', ')'), ('raw', ']'), ('whitespace', ' '), ('raw', '+'), ('newline', '\n'), ('whitespace', '       '), ('raw', 'count_55_64'), ('whitespace', ' '), ('raw', '*'), ('whitespace', ' '), ('raw', 'bits'), ('raw', '['), ('raw', 'OFFSET'), ('raw', '('), ('raw', '4'), ('raw', ')'), ('raw', ']'), ('whitespace', ' '), ('raw', '+'), ('whitespace', ' '), ('raw', 'count_65_plus'), ('whitespace', ' '), ('raw', '*'), ('whitespace', ' '), ('raw', 'bits'), ('raw', '['), ('raw', 'OFFSET'), ('raw', '('), ('raw', '5'), ('raw', ')'), ('raw', ']'), ('raw', ')'), ('whitespace', ' '), ('raw', '/'), ('whitespace', ' '), ('raw', 'audience_size'), ('whitespace', ' '), ('raw', 'AS'), ('whitespace', ' '), ('raw', 'relative_abundance'), ('newline', '\n'), ('whitespace', '    '), ('raw', 'FROM'), ('newline', '\n'), ('whitespace', '      '), ('raw', 'audience_counts_gender_age'), ('newline', '\n'), ('whitespace', '    '), ('raw', 'CROSS'), ('whitespace', ' '), ('raw', 'JOIN'), ('newline', '\n'), ('whitespace', '      '), ('raw', 'age_buckets_bit_array'), ('newline', '\n'), ('whitespace', '  '), ('raw', ')'), ('newline', '\n'), ('newline', '\n'), ('raw', 'SELECT'), ('newline', '\n'), ('whitespace', '  '), ('raw', '*'), ('newline', '\n'), ('raw', 'FROM'), ('newline', '\n'), ('whitespace', '  '), ('raw', 'age_buckets_bit_array'), ('newline', '\n'), ('raw', 'JOIN'), ('newline', '\n'), ('whitespace', '  '), ('raw', 'bucket_abundance'), ('newline', '\n'), ('raw', 'USING'), ('whitespace', ' '), ('raw', '('), ('raw', 'bucket_id'), ('raw', ')')))
Pre-parse structure: FileSegment:                                                [0](1, 1, 1)
    inline_comment_RawSegment:                              [0](1, 1, 1)        '-- This query should also parse in ANSI, but as a bigquery example'
    newline_RawSegment:                                     [66](1, 1, 67)      '\n'
    inline_comment_RawSegment:                              [67](1, 2, 1)       '-- it probably lives here. In particular it has an un-bracketed'
    newline_RawSegment:                                     [130](1, 2, 64)     '\n'
    inline_comment_RawSegment:                              [131](1, 3, 1)      '-- select clause within a function, and array notation which'
    newline_RawSegment:                                     [191](1, 3, 61)     '\n'
    inline_comment_RawSegment:                              [192](1, 4, 1)      '-- makes it a useful test case.'
    newline_RawSegment:                                     [223](1, 4, 32)     '\n'
    code_RawSegment:                                        [224](1, 5, 1)      'WITH'
    whitespace_RawSegment:                                  [228](1, 5, 5)      ' '
    code_RawSegment:                                        [229](1, 5, 6)      'age_buckets_bit_array'
    whitespace_RawSegment:                                  [250](1, 5, 27)     ' '
    code_RawSegment:                                        [251](1, 5, 28)     'AS'
    whitespace_RawSegment:                                  [253](1, 5, 30)     ' '
    bracket_open_RawSegment:                                [254](1, 5, 31)     '('
    newline_RawSegment:                                     [255](1, 5, 32)     '\n'
    whitespace_RawSegment:                                  [256](1, 6, 1)      '    '
    code_RawSegment:                                        [260](1, 6, 5)      'SELECT'
    newline_RawSegment:                                     [266](1, 6, 11)     '\n'
    whitespace_RawSegment:                                  [267](1, 7, 1)      '      '
    code_RawSegment:                                        [273](1, 7, 7)      'bucket_id'
    comma_RawSegment:                                       [282](1, 7, 16)     ','
    newline_RawSegment:                                     [283](1, 7, 17)     '\n'
    whitespace_RawSegment:                                  [284](1, 8, 1)      '      '
    code_RawSegment:                                        [290](1, 8, 7)      'num_ranges'
    comma_RawSegment:                                       [300](1, 8, 17)     ','
    newline_RawSegment:                                     [301](1, 8, 18)     '\n'
    whitespace_RawSegment:                                  [302](1, 9, 1)      '      '
    code_RawSegment:                                        [308](1, 9, 7)      'min_age'
    comma_RawSegment:                                       [315](1, 9, 14)     ','
    newline_RawSegment:                                     [316](1, 9, 15)     '\n'
    whitespace_RawSegment:                                  [317](1, 10, 1)     '      '
    code_RawSegment:                                        [323](1, 10, 7)     'ARRAY'
    bracket_open_RawSegment:                                [328](1, 10, 12)    '('
    code_RawSegment:                                        [329](1, 10, 13)    'SELECT'
    whitespace_RawSegment:                                  [335](1, 10, 19)    ' '
    code_RawSegment:                                        [336](1, 10, 20)    'CAST'
    bracket_open_RawSegment:                                [340](1, 10, 24)    '('
    code_RawSegment:                                        [341](1, 10, 25)    'num'
    whitespace_RawSegment:                                  [344](1, 10, 28)    ' '
    code_RawSegment:                                        [345](1, 10, 29)    'AS'
    whitespace_RawSegment:                                  [347](1, 10, 31)    ' '
    code_RawSegment:                                        [348](1, 10, 32)    'INT64'
    bracket_close_RawSegment:                               [353](1, 10, 37)    ')'
    whitespace_RawSegment:                                  [354](1, 10, 38)    ' '
    code_RawSegment:                                        [355](1, 10, 39)    'FROM'
    whitespace_RawSegment:                                  [359](1, 10, 43)    ' '
    code_RawSegment:                                        [360](1, 10, 44)    'UNNEST'
    bracket_open_RawSegment:                                [366](1, 10, 50)    '('
    code_RawSegment:                                        [367](1, 10, 51)    'SPLIT'
    bracket_open_RawSegment:                                [372](1, 10, 56)    '('
    code_RawSegment:                                        [373](1, 10, 57)    'binary'
    comma_RawSegment:                                       [379](1, 10, 63)    ','
    whitespace_RawSegment:                                  [380](1, 10, 64)    ' '
    single_quote_RawSegment:                                [381](1, 10, 65)    "''"
    bracket_close_RawSegment:                               [383](1, 10, 67)    ')'
    bracket_close_RawSegment:                               [384](1, 10, 68)    ')'
    whitespace_RawSegment:                                  [385](1, 10, 69)    ' '
    code_RawSegment:                                        [386](1, 10, 70)    'AS'
    whitespace_RawSegment:                                  [388](1, 10, 72)    ' '
    code_RawSegment:                                        [389](1, 10, 73)    'num'
    bracket_close_RawSegment:                               [392](1, 10, 76)    ')'
    whitespace_RawSegment:                                  [393](1, 10, 77)    ' '
    code_RawSegment:                                        [394](1, 10, 78)    'AS'
    whitespace_RawSegment:                                  [396](1, 10, 80)    ' '
    code_RawSegment:                                        [397](1, 10, 81)    'bits'
    comma_RawSegment:                                       [401](1, 10, 85)    ','
    newline_RawSegment:                                     [402](1, 10, 86)    '\n'
    whitespace_RawSegment:                                  [403](1, 11, 1)     '      '
    code_RawSegment:                                        [409](1, 11, 7)     'age_label'
    newline_RawSegment:                                     [418](1, 11, 16)    '\n'
    whitespace_RawSegment:                                  [419](1, 12, 1)     '    '
    code_RawSegment:                                        [423](1, 12, 5)     'FROM'
    newline_RawSegment:                                     [427](1, 12, 9)     '\n'
    whitespace_RawSegment:                                  [428](1, 13, 1)     '      '
    code_RawSegment:                                        [434](1, 13, 7)     'age_buckets'
    newline_RawSegment:                                     [445](1, 13, 18)    '\n'
    whitespace_RawSegment:                                  [446](1, 14, 1)     '  '
    bracket_close_RawSegment:                               [448](1, 14, 3)     ')'
    comma_RawSegment:                                       [449](1, 14, 4)     ','
    newline_RawSegment:                                     [450](1, 14, 5)     '\n'
    whitespace_RawSegment:                                  [451](1, 15, 1)     '  '
    code_RawSegment:                                        [453](1, 15, 3)     'bucket_abundance'
    whitespace_RawSegment:                                  [469](1, 15, 19)    ' '
    code_RawSegment:                                        [470](1, 15, 20)    'AS'
    whitespace_RawSegment:                                  [472](1, 15, 22)    ' '
    bracket_open_RawSegment:                                [473](1, 15, 23)    '('
    newline_RawSegment:                                     [474](1, 15, 24)    '\n'
    whitespace_RawSegment:                                  [475](1, 16, 1)     '    '
    code_RawSegment:                                        [479](1, 16, 5)     'SELECT'
    newline_RawSegment:                                     [485](1, 16, 11)    '\n'
    whitespace_RawSegment:                                  [486](1, 17, 1)     '      '
    code_RawSegment:                                        [492](1, 17, 7)     'bucket_id'
    newline_RawSegment:                                     [501](1, 17, 16)    '\n'
    whitespace_RawSegment:                                  [502](1, 18, 1)     '      '
    bracket_open_RawSegment:                                [508](1, 18, 7)     '('
    code_RawSegment:                                        [509](1, 18, 8)     'count_18_24'
    whitespace_RawSegment:                                  [520](1, 18, 19)    ' '
    star_RawSegment:                                        [521](1, 18, 20)    '*'
    whitespace_RawSegment:                                  [522](1, 18, 21)    ' '
    code_RawSegment:                                        [523](1, 18, 22)    'bits'
    sq_bracket_open_RawSegment:                             [527](1, 18, 26)    '['
    code_RawSegment:                                        [528](1, 18, 27)    'OFFSET'
    bracket_open_RawSegment:                                [534](1, 18, 33)    '('
    numeric_literal_RawSegment:                             [535](1, 18, 34)    '0'
    bracket_close_RawSegment:                               [536](1, 18, 35)    ')'
    sq_bracket_close_RawSegment:                            [537](1, 18, 36)    ']'
    whitespace_RawSegment:                                  [538](1, 18, 37)    ' '
    plus_RawSegment:                                        [539](1, 18, 38)    '+'
    whitespace_RawSegment:                                  [540](1, 18, 39)    ' '
    code_RawSegment:                                        [541](1, 18, 40)    'count_25_34'
    whitespace_RawSegment:                                  [552](1, 18, 51)    ' '
    star_RawSegment:                                        [553](1, 18, 52)    '*'
    whitespace_RawSegment:                                  [554](1, 18, 53)    ' '
    code_RawSegment:                                        [555](1, 18, 54)    'bits'
    sq_bracket_open_RawSegment:                             [559](1, 18, 58)    '['
    code_RawSegment:                                        [560](1, 18, 59)    'OFFSET'
    bracket_open_RawSegment:                                [566](1, 18, 65)    '('
    numeric_literal_RawSegment:                             [567](1, 18, 66)    '1'
    bracket_close_RawSegment:                               [568](1, 18, 67)    ')'
    sq_bracket_close_RawSegment:                            [569](1, 18, 68)    ']'
    whitespace_RawSegment:                                  [570](1, 18, 69)    ' '
    plus_RawSegment:                                        [571](1, 18, 70)    '+'
    newline_RawSegment:                                     [572](1, 18, 71)    '\n'
    whitespace_RawSegment:                                  [573](1, 19, 1)     '       '
    code_RawSegment:                                        [580](1, 19, 8)     'count_35_44'
    whitespace_RawSegment:                                  [591](1, 19, 19)    ' '
    star_RawSegment:                                        [592](1, 19, 20)    '*'
    whitespace_RawSegment:                                  [593](1, 19, 21)    ' '
    code_RawSegment:                                        [594](1, 19, 22)    'bits'
    sq_bracket_open_RawSegment:                             [598](1, 19, 26)    '['
    code_RawSegment:                                        [599](1, 19, 27)    'OFFSET'
    bracket_open_RawSegment:                                [605](1, 19, 33)    '('
    numeric_literal_RawSegment:                             [606](1, 19, 34)    '2'
    bracket_close_RawSegment:                               [607](1, 19, 35)    ')'
    sq_bracket_close_RawSegment:                            [608](1, 19, 36)    ']'
    whitespace_RawSegment:                                  [609](1, 19, 37)    ' '
    plus_RawSegment:                                        [610](1, 19, 38)    '+'
    whitespace_RawSegment:                                  [611](1, 19, 39)    ' '
    code_RawSegment:                                        [612](1, 19, 40)    'count_45_54'
    whitespace_RawSegment:                                  [623](1, 19, 51)    ' '
    star_RawSegment:                                        [624](1, 19, 52)    '*'
    whitespace_RawSegment:                                  [625](1, 19, 53)    ' '
    code_RawSegment:                                        [626](1, 19, 54)    'bits'
    sq_bracket_open_RawSegment:                             [630](1, 19, 58)    '['
    code_RawSegment:                                        [631](1, 19, 59)    'OFFSET'
    bracket_open_RawSegment:                                [637](1, 19, 65)    '('
    numeric_literal_RawSegment:                             [638](1, 19, 66)    '3'
    bracket_close_RawSegment:                               [639](1, 19, 67)    ')'
    sq_bracket_close_RawSegment:                            [640](1, 19, 68)    ']'
    whitespace_RawSegment:                                  [641](1, 19, 69)    ' '
    plus_RawSegment:                                        [642](1, 19, 70)    '+'
    newline_RawSegment:                                     [643](1, 19, 71)    '\n'
    whitespace_RawSegment:                                  [644](1, 20, 1)     '       '
    code_RawSegment:                                        [651](1, 20, 8)     'count_55_64'
    whitespace_RawSegment:                                  [662](1, 20, 19)    ' '
    star_RawSegment:                                        [663](1, 20, 20)    '*'
    whitespace_RawSegment:                                  [664](1, 20, 21)    ' '
    code_RawSegment:                                        [665](1, 20, 22)    'bits'
    sq_bracket_open_RawSegment:                             [669](1, 20, 26)    '['
    code_RawSegment:                                        [670](1, 20, 27)    'OFFSET'
    bracket_open_RawSegment:                                [676](1, 20, 33)    '('
    numeric_literal_RawSegment:                             [677](1, 20, 34)    '4'
    bracket_close_RawSegment:                               [678](1, 20, 35)    ')'
    sq_bracket_close_RawSegment:                            [679](1, 20, 36)    ']'
    whitespace_RawSegment:                                  [680](1, 20, 37)    ' '
    plus_RawSegment:                                        [681](1, 20, 38)    '+'
    whitespace_RawSegment:                                  [682](1, 20, 39)    ' '
    code_RawSegment:                                        [683](1, 20, 40)    'count_65_plus'
    whitespace_RawSegment:                                  [696](1, 20, 53)    ' '
    star_RawSegment:                                        [697](1, 20, 54)    '*'
    whitespace_RawSegment:                                  [698](1, 20, 55)    ' '
    code_RawSegment:                                        [699](1, 20, 56)    'bits'
    sq_bracket_open_RawSegment:                             [703](1, 20, 60)    '['
    code_RawSegment:                                        [704](1, 20, 61)    'OFFSET'
    bracket_open_RawSegment:                                [710](1, 20, 67)    '('
    numeric_literal_RawSegment:                             [711](1, 20, 68)    '5'
    bracket_close_RawSegment:                               [712](1, 20, 69)    ')'
    sq_bracket_close_RawSegment:                            [713](1, 20, 70)    ']'
    bracket_close_RawSegment:                               [714](1, 20, 71)    ')'
    whitespace_RawSegment:                                  [715](1, 20, 72)    ' '
    divide_RawSegment:                                      [716](1, 20, 73)    '/'
    whitespace_RawSegment:                                  [717](1, 20, 74)    ' '
    code_RawSegment:                                        [718](1, 20, 75)    'audience_size'
    whitespace_RawSegment:                                  [731](1, 20, 88)    ' '
    code_RawSegment:                                        [732](1, 20, 89)    'AS'
    whitespace_RawSegment:                                  [734](1, 20, 91)    ' '
    code_RawSegment:                                        [735](1, 20, 92)    'relative_abundance'
    newline_RawSegment:                                     [753](1, 20, 110)   '\n'
    whitespace_RawSegment:                                  [754](1, 21, 1)     '    '
    code_RawSegment:                                        [758](1, 21, 5)     'FROM'
    newline_RawSegment:                                     [762](1, 21, 9)     '\n'
    whitespace_RawSegment:                                  [763](1, 22, 1)     '      '
    code_RawSegment:                                        [769](1, 22, 7)     'audience_counts_gender_age'
    newline_RawSegment:                                     [795](1, 22, 33)    '\n'
    whitespace_RawSegment:                                  [796](1, 23, 1)     '    '
    code_RawSegment:                                        [800](1, 23, 5)     'CROSS'
    whitespace_RawSegment:                                  [805](1, 23, 10)    ' '
    code_RawSegment:                                        [806](1, 23, 11)    'JOIN'
    newline_RawSegment:                                     [810](1, 23, 15)    '\n'
    whitespace_RawSegment:                                  [811](1, 24, 1)     '      '
    code_RawSegment:                                        [817](1, 24, 7)     'age_buckets_bit_array'
    newline_RawSegment:                                     [838](1, 24, 28)    '\n'
    whitespace_RawSegment:                                  [839](1, 25, 1)     '  '
    bracket_close_RawSegment:                               [841](1, 25, 3)     ')'
    newline_RawSegment:                                     [842](1, 25, 4)     '\n'
    newline_RawSegment:                                     [843](1, 26, 1)     '\n'
    code_RawSegment:                                        [844](1, 27, 1)     'SELECT'
    newline_RawSegment:                                     [850](1, 27, 7)     '\n'
    whitespace_RawSegment:                                  [851](1, 28, 1)     '  '
    star_RawSegment:                                        [853](1, 28, 3)     '*'
    newline_RawSegment:                                     [854](1, 28, 4)     '\n'
    code_RawSegment:                                        [855](1, 29, 1)     'FROM'
    newline_RawSegment:                                     [859](1, 29, 5)     '\n'
    whitespace_RawSegment:                                  [860](1, 30, 1)     '  '
    code_RawSegment:                                        [862](1, 30, 3)     'age_buckets_bit_array'
    newline_RawSegment:                                     [883](1, 30, 24)    '\n'
    code_RawSegment:                                        [884](1, 31, 1)     'JOIN'
    newline_RawSegment:                                     [888](1, 31, 5)     '\n'
    whitespace_RawSegment:                                  [889](1, 32, 1)     '  '
    code_RawSegment:                                        [891](1, 32, 3)     'bucket_abundance'
    newline_RawSegment:                                     [907](1, 32, 19)    '\n'
    code_RawSegment:                                        [908](1, 33, 1)     'USING'
    whitespace_RawSegment:                                  [913](1, 33, 6)     ' '
    bracket_open_RawSegment:                                [914](1, 33, 7)     '('
    code_RawSegment:                                        [915](1, 33, 8)     'bucket_id'
    bracket_close_RawSegment:                               [924](1, 33, 17)    ')'

___ test__std_fix_auto[bigquery-001_L003L006L009_templating-L003,L006,L009] ____

dialect = 'bigquery', folder = '001_L003L006L009_templating'
rules = 'L003,L006,L009'

    @pytest.mark.parametrize(
        "dialect,folder,rules",
        test_cases
    )
    def test__std_fix_auto(dialect, folder, rules):
        """Automated Fixing Tests."""
>       auto_fix_test(rules=rules, dialect=dialect, folder=folder)

test/rules_std_fix_auto_test.py:138: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
test/rules_std_fix_auto_test.py:116: in auto_fix_test
    res = do_fixes(lnt, paths=[filepath])
src/sqlfluff/cli/commands.py:173: in do_fixes
    result = lnt.lint_paths(paths, fix=True)
src/sqlfluff/linter.py:760: in lint_paths
    result.add(self.lint_path(path, verbosity=verbosity, fix=fix))
src/sqlfluff/linter.py:747: in lint_path
    fix=fix, config=config))
src/sqlfluff/linter.py:606: in lint_string
    parsed, vs, time_dict = self.parse_string(s=s, fname=fname, verbosity=verbosity, config=config)
src/sqlfluff/linter.py:577: in parse_string
    parsed = file_segment.parse(parse_context=context)
src/sqlfluff/parser/segments_base.py:456: in parse
    incr='parse_depth', match_depth=0, recurse=True
src/sqlfluff/parser/segments_base.py:688: in expand
    res = stmt.parse(parse_context=parse_context)
src/sqlfluff/parser/segments_base.py:409: in parse
    match_segment=self.__class__.__name__
src/sqlfluff/parser/grammar.py:81: in _match
    m = self.match(segments, parse_context=parse_context)
src/sqlfluff/parser/grammar.py:656: in match
    parse_context=parse_context.copy(incr='match_depth')
src/sqlfluff/parser/grammar.py:81: in _match
    m = self.match(segments, parse_context=parse_context)
src/sqlfluff/parser/grammar.py:580: in match
    parse_context=parse_context.copy(match_segment=self._get_ref()))
src/sqlfluff/parser/segments_base.py:651: in _match
    m = cls.match(segments, parse_context=parse_context)
src/sqlfluff/parser/segments_base.py:614: in match
    m = cls._match_grammar()._match(segments=segments, parse_context=parse_context.copy(incr='match_depth'))
src/sqlfluff/parser/grammar.py:81: in _match
    m = self.match(segments, parse_context=parse_context)
src/sqlfluff/parser/grammar.py:971: in match
    code_only=False)
src/sqlfluff/parser/grammar.py:467: in _bracket_sensitive_look_ahead_match
    code_only=code_only)
src/sqlfluff/parser/grammar.py:275: in _look_ahead_match
    simple_matchers = [m for m in matchers if m.simple(parse_context=parse_context)]
src/sqlfluff/parser/grammar.py:275: in <listcomp>
    simple_matchers = [m for m in matchers if m.simple(parse_context=parse_context)]
src/sqlfluff/parser/grammar.py:524: in simple
    ).simple(parse_context=parse_context)
src/sqlfluff/parser/segments_base.py:232: in simple
    return match_grammar.simple(parse_context=parse_context)
src/sqlfluff/parser/grammar.py:638: in simple
    simple = opt.simple(parse_context=parse_context)
src/sqlfluff/parser/grammar.py:801: in simple
    simple = opt.simple(parse_context=parse_context)
src/sqlfluff/parser/grammar.py:523: in simple
    dialect=parse_context.dialect
src/sqlfluff/parser/grammar.py:542: in _get_elem
    return dialect.ref(self._get_ref())
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Dialect: bigquery>, name = 'UnionKeywordSegment'

    def ref(self, name):
        """Return an object which acts as a late binding reference to the element named.
    
        NB: This requires the dialect to be expanded.
    
        """
        if not self.expanded:
            raise RuntimeError("Dialect must be expanded before use.")
    
        if name in self._library:
            res = self._library[name]
            if res:
                return res
            else:
                raise ValueError(
                    "Unexpected Null response while fetching {0!r} from {1}".format(
                        name, self.name))
        else:
            raise RuntimeError(
                "Grammar refers to {0!r} which was not found in the {1} dialect".format(
>                   name, self.name))
E           RuntimeError: Grammar refers to 'UnionKeywordSegment' which was not found in the bigquery dialect

src/sqlfluff/dialects/base.py:219: RuntimeError
----------------------------- Captured stdout call -----------------------------
## Input file:
select *
from  `{{project}}.{{dataset}}.user_labels_with_probs`
where prob_max >={{label_prob_threshold}}
--- only focus on 3 segments
and label_str not in ('marketing_maven', 'growth_services')
- generated xml file: /Users/jh186076/Documents/03_Privat/sqlfluff/.test-reports/junit.xml -

---------- coverage: platform darwin, python 3.7.2-final-0 -----------
Coverage XML written to file coverage.xml

=========================== short test summary info ============================
FAILED test/dialects_test.py::test__dialect__base_file_parse[teradata-select_stmt.sql]
FAILED test/dialects_test.py::test__dialect__base_file_parse[teradata-create_table_stmt_3.sql]
FAILED test/dialects_test.py::test__dialect__base_file_parse[teradata-create_table_stmt_2.sql]
FAILED test/dialects_test.py::test__dialect__base_file_parse[teradata-create_table_stmt.sql]
FAILED test/dialects_test.py::test__dialect__base_file_parse[teradata-bteq_stmt.sql]
FAILED test/dialects_test.py::test__dialect__base_file_parse[teradata-collect_stats.sql]
FAILED test/dialects_test.py::test__dialect__base_file_parse[teradata-update_from.sql]
FAILED test/dialects_test.py::test__dialect__base_file_parse[teradata-select_stmt_cast.sql]
FAILED test/dialects_test.py::test__dialect__base_file_parse[bigquery-interval_function.sql]
FAILED test/dialects_test.py::test__dialect__base_file_parse[bigquery-string_literals.sql]
FAILED test/dialects_test.py::test__dialect__base_file_parse[bigquery-select_quoting.sql]
FAILED test/dialects_test.py::test__dialect__base_file_parse[bigquery-select_example.sql]
FAILED test/rules_std_fix_auto_test.py::test__std_fix_auto[bigquery-001_L003L006L009_templating-L003,L006,L009]
======================= 13 failed, 330 passed in 25.77s ========================
ERROR: InvocationError for command /Users/jh186076/Documents/03_Privat/sqlfluff/.tox/py37/bin/pytest -vv --cov --cov-report=xml --junitxml=.test-reports/junit.xml (exited with code 1)
cov-report develop-inst-noop: /Users/jh186076/Documents/03_Privat/sqlfluff
cov-report installed: bench-it==1.0.1,click==7.1.1,colorama==0.4.3,configparser==5.0.0,coverage==5.1,diff-cover==2.6.1,importlib-metadata==1.6.0,inflect==4.1.0,Jinja2==2.11.2,jinja2-pluralize==0.3.0,MarkupSafe==1.1.1,oyaml==0.9,pluggy==0.13.1,Pygments==2.6.1,PyYAML==5.3.1,six==1.14.0,-e git+https://github.com/Katzmann1983/sqlfluff.git@47c6bd2839ba731a7856a926801a7b4ab4126dd4#egg=sqlfluff,zipp==3.1.0
cov-report run-test-pre: PYTHONHASHSEED='3219088205'
cov-report run-test: commands[0] | coverage combine
cov-report run-test: commands[1] | coverage report
Name                                        Stmts   Miss  Cover
---------------------------------------------------------------
src/sqlfluff/__init__.py                        5      0   100%
src/sqlfluff/__main__.py                        3      0   100%
src/sqlfluff/cli/__init__.py                    0      0   100%
src/sqlfluff/cli/commands.py                  204     35    83%
src/sqlfluff/cli/formatters.py                 96      3    97%
src/sqlfluff/cli/helpers.py                    74      1    99%
src/sqlfluff/config.py                        180      6    97%
src/sqlfluff/dialects/__init__.py              11      0   100%
src/sqlfluff/dialects/ansi_keywords.py          2      0   100%
src/sqlfluff/dialects/base.py                  96     17    82%
src/sqlfluff/dialects/dialect_ansi.py         216      0   100%
src/sqlfluff/dialects/dialect_bigquery.py      12      0   100%
src/sqlfluff/dialects/dialect_mysql.py          3      0   100%
src/sqlfluff/dialects/dialect_teradata.py      73      0   100%
src/sqlfluff/diff_quality_plugin.py            21      0   100%
src/sqlfluff/errors.py                         80      4    95%
src/sqlfluff/linter.py                        394     67    83%
src/sqlfluff/parser/__init__.py                 6      0   100%
src/sqlfluff/parser/grammar.py                555     65    88%
src/sqlfluff/parser/lexer.py                  140      4    97%
src/sqlfluff/parser/markers.py                 25      0   100%
src/sqlfluff/parser/match.py                   63      9    86%
src/sqlfluff/parser/segments_base.py          450     66    85%
src/sqlfluff/parser/segments_common.py        129     15    88%
src/sqlfluff/parser/segments_file.py           14      1    93%
src/sqlfluff/rules/__init__.py                  4      0   100%
src/sqlfluff/rules/base.py                    136     16    88%
src/sqlfluff/rules/std.py                     688     57    92%
src/sqlfluff/templaters.py                     83      0   100%
---------------------------------------------------------------
TOTAL                                        3763    366    90%
linting develop-inst-noop: /Users/jh186076/Documents/03_Privat/sqlfluff
linting installed: bench-it==1.0.1,click==7.1.1,colorama==0.4.3,configparser==5.0.0,diff-cover==2.6.1,entrypoints==0.3,flake8==3.7.9,flake8-docstrings==1.5.0,importlib-metadata==1.6.0,inflect==4.1.0,Jinja2==2.11.2,jinja2-pluralize==0.3.0,MarkupSafe==1.1.1,mccabe==0.6.1,oyaml==0.9,pluggy==0.13.1,pycodestyle==2.5.0,pydocstyle==5.0.2,pyflakes==2.1.1,Pygments==2.6.1,PyYAML==5.3.1,six==1.14.0,snowballstemmer==2.0.0,-e git+https://github.com/Katzmann1983/sqlfluff.git@47c6bd2839ba731a7856a926801a7b4ab4126dd4#egg=sqlfluff,zipp==3.1.0
linting run-test-pre: PYTHONHASHSEED='3219088205'
linting run-test: commands[0] | flake8
./src/sqlfluff/dialects/dialect_ansi.py:19:1: F401 '.base.SetDialectModule' imported but unused
./src/sqlfluff/dialects/dialect_bigquery.py:36:1: E303 too many blank lines (3)
./src/sqlfluff/dialects/dialect_bigquery.py:36:6: E211 whitespace before '('
./src/sqlfluff/dialects/base.py:61:1: D200 One-line docstring should fit on one line with quotes
./src/sqlfluff/dialects/base.py:61:1: D415 First line should end with a period, question mark, or exclamation point
ERROR: InvocationError for command /Users/jh186076/Documents/03_Privat/sqlfluff/.tox/linting/bin/flake8 (exited with code 1)
___________________________________ summary ____________________________________
  cov-init: commands succeeded
ERROR:   py37: commands failed
  cov-report: commands succeeded
ERROR:   linting: commands failed
